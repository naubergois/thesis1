

@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	

@inproceedings{Piel2010,
author = {Piel, {\'{E}}ric and Gonz{\'{a}}lez-Sanchez, Alberto and Gro{\ss}, Hans-Gerhard},
doi = {10.1007/978-3-642-16573-3},
file = {:Users/naubergois/Downloads/rbtcg{\_}preprint.pdf:pdf},
isbn = {978-3-642-16572-6},
journal = {Ictss},
number = {October},
pages = {79--94},
title = {{Testing Software and Systems}},
url = {http://dblp.uni-trier.de/db/conf/pts/ictss2010.html{\#}PielGG10},
volume = {6435},
year = {2010}
}


@book{Havelund2006,
author = {Havelund, Klaus and N{\'{u}}{\~{n}}ez, Manuel and Roşu, Grigore and Wolff, Burkhart},
booktitle = {Serious Games Development and Applications},
file = {:Users/naubergois/Downloads/Deterministic{\_}dynamic{\_}monitors{\_}for{\_}linea.pdf:pdf},
isbn = {9783642238338},
pages = {155},
title = {{Formal Approaches to Software Testing and Runtime Verification}},
url = {http://www.ulb.tu-darmstadt.de/tocs/79304567.pdf},
year = {2006}
}


@article{Blum2003,
abstract = {The emergence of metaheuristics for solving difficult combinatorial optimization problems is one of the most notable achievements of the last two decades in operations research. This paper provides an account of the most recent developments in the field and identifies some common issues and trends. Examples of applications are also reported for vehicle routing and scheduling problems.},
author = {Blum, C. and Roli, A.},
doi = {10.1007/s10479-005-3971-7},
file = {:Users/naubergois/Downloads/blum{\_}roli{\_}metaheuristics-preprint.pdf:pdf},
isbn = {0254-5330},
issn = {02545330},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Metaheuristics,Unifying framework,Vehicle routing},
number = {3},
pages = {189--213},
title = {{Metaheuristics in combinatorial optimization: overview and conceptual comparison}},
volume = {35},
year = {2003}
}

@article{Aleti2016,
author = {Aleti, Aldeida and Moser, I. and Grunske, Lars},
doi = {10.1007/s10515-016-0197-7},
file = {:Users/naubergois/Downloads/JASE2016.pdf:pdf},
isbn = {1051501601},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Fitness landscape characterisation,Genetic algorithms,Test data generation},
pages = {1--19},
title = {{Analysing the fitness landscape of search-based software testing problems}},
year = {2016}
}

@book{Hasan,
author = {Hasan, Tahsin},
file = {:Users/naubergois/Documents/Tahsin Hasan OpenCart 1.4 Template Design Cookbook.pdf:pdf},
isbn = {9781849514309},
title = {{OpenCart Template Design Cookbook}}
}
    


@article{ManuelLopez-IbanezJeremieDubois-LacosteLesliePerezCaceresMauroBirattari2016,
author = {{Manuel L{\'{o}}pez-Ib{\'{a}}{\~{n}}ez, J{\'{e}}r{\'{e}}mie Dubois-Lacoste, Leslie P{\'{e}}rez C{\'{a}}ceres, Mauro Birattari}, Thomas St{\"{u}}tzle},
doi = {10.1016/j.orp.2016.09.002},
file = {:Users/naubergois/Documents/1-s2.0-S2214716015300270-main.pdf:pdf},
issn = {22147160},
journal = {Operations Research Perspectives},
keywords = {Automatic algorithm configuration,Parameter tuning,Racing},
pages = {43--58},
title = {{The irace package: Iterated racing for automatic algorithm configuration}},
volume = {3},
year = {2016}
}


@inproceedings{Meinke2010,
abstract = {We present an application of learning-based testing to the problem of automated test case generation (ATCG) for numerical software. Our approach uses n-dimensional polynomial models as an algorithmically learned abstraction of the SUT which supports n-wise testing. Test cases are iteratively generated by applying a satisfiability algorithm to first-order program specifications over real closed fields and iteratively refined piecewise polynomial models. We benchmark the performance of our iterative ATCG algorithm against iterative random testing, and empirically analyse its performance in finding injected errors in numerical codes. Our results show that for software with small errors, or long mean time to failure, learning-based testing is increasingly more efficient than iterative random testing. {\textcopyright} 2010 IFIP International Federation for Information Processing.},
author = {Meinke, Karl and Niu, Fei},
doi = {10.1007/978-3-642-16573-3_16},
file = {:Users/naubergois/Downloads/64350220.pdf:pdf},
isbn = {3642165729},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {221--235},
title = {{A learning-based approach to unit testing of numerical software}},
volume = {6435 LNCS},
year = {2010}
}


@inproceedings{Kamali2007,
abstract = {In traditional optimal control and design problems, the control gains and design parameters are usually derived to minimize a cost function reflecting the system performance and control effort. One major challenge of such approaches is the selection of weighting matrices in the cost function, which are usually determined via trial-and-error and human intuition. While various techniques have been proposed to automate the weight selection process, they either can not address complex design problems or suffer from slow convergence rate and high computational costs. We propose a layered approach based on Q-learning, a reinforcement learning technique, on top of genetic algorithms (GA) to determine the best weightings for optimal control and design problems. The layered approach allows for reuse of knowledge. Knowledge obtained via Q-learning in a design problem can be used to speed up the convergence rate of a similar design problem. Moreover, the layered approach allows for solving optimizations that cannot be solved by GA alone. To test the proposed method, we perform numerical experiments on a sample active-passive hybrid vibration control problem, namely adaptive structures with active-passive hybrid piezoelectric networks. These numerical experiments show that the proposed Q-learning scheme is a promising approach for automation of weight selection for complex design problems. (27 References).},
author = {Kamali, Kaivan and Jiang, L. J. and Yen, John and Wang, K. W.},
doi = {10.1115/1.2739502},
file = {:Users/naubergois/Downloads/kamali2007.pdf:pdf},
isbn = {0-7918-4739-X},
issn = {15309827},
journal = {Journal of Computing and Information Science in Engineering},
keywords = {genetic algorithms,optimal control,q-learning},
number = {December 2007},
pages = {302},
title = {{Using Q-Learning and Genetic Algorithms to Improve the Efficiency of Weight Adjustments for Optimal Control and Design Problems}},
volume = {7},
year = {2007}
}

	
@inproceedings{sato2015automatic,
  title={Automatic Generation of Specification-Based Test Cases by Applying Genetic Algorithms in Reinforcement Learning},
  author={Sato, Yuji and Sugihara, Taku},
  booktitle={International Workshop on Structured Object-Oriented Formal Language and Method},
  pages={59--71},
  year={2015},
  organization={Springer}
}	
	
@inproceedings{Boyan2000,
abstract = {This paper describes algorithms that learn to improve search performance on large-scale optimization tasks. The main algorithm, STAGE, works by learning an evaluation function that predicts the outcome of a local search algorithm, such as hillclimbing or Walksat, from features of states visited during search. The learned evaluation function is then used to bias future search trajectories toward better optima on the same problem. Another algorithm, X-STAGE, transfers previously learned evaluation functions to new, similar optimization problems. Empirical results are provided on seven large-scale optimization domains: bin-packing, channel routing, Bayesian network structure-finding, radiotherapy treatment planning, cartogram design, Boolean satisfiability, and Boggle board setup.},
author = {Boyan, Justin A. and Moore, Andrew W.},
file = {:Users/naubergois/Downloads/boyan00a.pdf:pdf},
issn = {1533-7928},
journal = {Journal of Machine Learning Research},
pages = {77--112},
title = {{Learning Evaluation Functions to Improve Local Search}},
url = {http://citeseer.nj.nec.com/boyan00learning.html},
volume = {1},
year = {2000}
}


@book{talbi2009metaheuristics,
  title={Metaheuristics: from design to implementation},
  author={Talbi, El-Ghazali},
  volume={74},
  year={2009},
  publisher={John Wiley \& Sons}
}

@book{Battiti2009,
abstract = {This book is about learning for problem solving. [...] Human problem solving is strongly connected to learning. Learning takes places when the problem at hand is not well known at the beginning, and its structure becomes more and more clear when more experience with the problem is available. [...] What is critical for men is critical also in many human-developed problem solving strategies. It is not surprising that many methods for solving problems in Artificial Intelligence, Operations Research and related areas, follow the search scheme [...] We aim at giving the main principles and at developing some fresh intuition for the approaches. We like mathematics but we also think that hiding the underlying motivations and sources of inspiration takes some color out of the scientific work [...]. On the other hand, pictures and hand-waving can be very dangerous in isolation and we try to avoid these pitfalls by giving also the basic equations when possible, or by at least directing the reader to the bibliographic references for deepening a topic. The point of view of the book is to look at the zoo of different optimization beasts to underline opportunities for learning and self-tuning strategies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Battiti, Roberto and Brunato, Mauro and Mascia, Franco},
booktitle = {Operations Research/ Computer Science Interfaces Series},
doi = {10.1007/978-0-387-09624-7},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/book{\_}reactive{\_}search{\_}and{\_}iIntelligent{\_} optimization.pdf:pdf},
isbn = {9780387096230},
issn = {1387666X},
pmid = {25246403},
title = {{Reactive search and intelligent optimization}},
volume = {45},
year = {2009}
}


@inproceedings{Smith2002,
author = {Smith, C.U. and Williams, L.G.},
file = {:Users/naubergois/Downloads/24fe255149e4fc0d7e1e8924c243a85dd676.pdf:pdf},
journal = {Cmg-Conference-},
pages = {797--806},
title = {{Software Performance AntiPatterns; Common Performance Problems and their Solutions}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.6968{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {2002}
}

@inproceedings{Bennett2006,
abstract = {The fields of machine learning and mathematical programming are increasingly intertwined. Optimization problems lie at the heart of most machine learning approaches. The Special Topic on Machine Learning and Large Scale Optimization examines this interplay. Machine learning researchers have embraced the advances in mathematical programming allowing new types of models to be pursued. The special topic includes models using quadratic, linear, second-order cone, semi-definite, and semi-infinite programs. We observe that the qualities of good optimization algorithms from the machine learning and optimization perspectives can be quite different. Mathematical programming puts a premium on accuracy, speed, and robustness. Since generalization is the bottom line in machine learning and training is normally done off-line, accuracy and small speed improvements are of little concern in machine learning. Machine learning prefers simpler algorithms that work in reasonable computational time for specific classes of problems. Reducing machine learning problems to well-explored mathematical programming classes with robust general purpose optimization codes allows machine learning researchers to rapidly develop new techniques. In turn, machine learning presents new challenges to mathematical programming. The special issue include papers from two primary themes: novel machine learning models and novel optimization approaches for existing models. Many papers blend both themes, making small changes in the underlying core mathematical program that enable the develop of effective new algorithms.},
archivePrefix = {arXiv},
arxivId = {math/0601771},
author = {Bennett, Kristin P},
doi = {10.1051/ps},
eprint = {0601771},
file = {:Users/naubergois/Downloads/MLOPT-intro06a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {convex optimization,machine learning,mathematical programming},
number = {November},
pages = {1265--1281},
primaryClass = {math},
title = {{The Interplay of Optimization and Machine Learning Research}},
url = {http://portal.acm.org/citation.cfm?id=1248593},
volume = {7},
year = {2006}
}


@inproceedings{Gambardella1995,
author = {Gambardella, Luca M and Dorigo, Marco},
file = {:Users/naubergois/Downloads/gambardella95-icml (1).pdf:pdf},
pages = {252--260},
title = {{Ant-Q : A Reinforcement Learning approach to the traveling salesman problem}},
volume = {5625},
year = {1995}
}

@inproceedings{Matsuura2015,
author = {Matsuura, Jackson and Bianchi, Reinaldo A C},
file = {:Users/naubergois/Downloads/sbia2815.pdf:pdf},
number = {March},
title = {{Heuristically Accelerated Q – Learning : a new approach to speed up Reinforcement Learning}},
year = {2015}
}




@inproceedings{Wang2013,
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
doi = {10.1080/02533839.2012.726028},
file = {:Users/naubergois/Downloads/wang2013.pdf:pdf},
issn = {0253-3839},
journal = {Journal of the Chinese Institute of Engineers},
keywords = {Model Based Test,Stress testing,load testing,markov chains,usage model},
number = {1},
pages = {74--86},
title = {{Model-based load testing of web applications}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02533839.2012.726028},
volume = {36},
year = {2013}
}


@inproceedings{Baars2011,
abstract = {The Future Internet will be a complex interconnection$\backslash$nof services, applications, content and media, on which$\backslash$nour society will become increasingly dependent. Time to$\backslash$nmarket is crucial in Internet applications and hence$\backslash$nrelease cycles grow ever shorter. This, coupled with$\backslash$nthe highly dynamic nature of the Future Internet will$\backslash$nplace new demands on software testing. Search-Based$\backslash$nTesting is ideally placed to address these emerging$\backslash$nchallenges. Its techniques are highly flexible and$\backslash$nrobust to only partially observable systems. This paper$\backslash$npresents an overview of Search-Based Testing and$\backslash$ndiscusses some of the open challenges remaining to make$\backslash$nsearch-based techniques applicable to the Future$\backslash$nInternet.},
author = {Baars, Arthur I and Lakhotia, Kiran and Vos, Tanja E J and Wegener, Joachim},
file = {:Users/naubergois/Downloads/fedcsis11.pdf:pdf},
isbn = {9788360810392},
journal = {Federated Conference on Computer Science and Information Systems (FedCSIS 2011)},
keywords = {Evolutionary computation,Internet,Optimisation,SBSE,Search Based Test,Search problems,Software,Testing,evolutionary testing,future Internet testing,genetic algorithms,genetic programming,search-based testing,software testing,time to market},
pages = {917--923},
title = {{Search-based testing, the underlying engine of Future Internet testing}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=6078178},
year = {2011}
}


@inproceedings{Brown2003,
author = {Brown, Matthew a and Tapolcsanyi, Eli},
file = {:Users/naubergois/Downloads/Brown-mock-objects.pdf:pdf},
journal = {Matrix},
pages = {1--17},
title = {{Mock Object Patterns}},
year = {2003}
}


@inproceedings{Hunt2002,
author = {Hunt, Editors Andy and Thomas, Dave and Pragmatic, I The and Hunt, Andy and Mackinnon, Tim and Freeman, Steve},
doi = {10.1109/MS.2004.1259177},
file = {:Users/naubergois/Downloads/may{\_}02{\_}mock.pdf:pdf},
issn = {0740-7459},
journal = {Ieee Software},
number = {June},
pages = {22--24},
title = {{Software Construction}},
year = {2002}
}

@inproceedings{Bertolino2008,
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
year = {2008}
}

@book{GendreauMichelandPotvin2010,
author = {{Gendreau, Michel and Potvin}, Jean-Yves},
doi = {10.1007/978-1-4614-1900-6},
file = {:Users/naubergois/Downloads/Artificial{\_}Immune{\_}Systems.pdf:pdf},
isbn = {9781441979605},
title = {{Handbook of Metaheuristics}},
volume = {157},
year = {2010}
}




@inproceedings{Mackinnon2001,
abstract = {Unit testing is a fundamental practice in Extreme Programming, but most non-trivial code is difficult to test in isolation. It is hard to avoid writing test suites that are complex, incomplete, and difficult to maintain and interpret. Using Mock Objects for unit testing improves both domain code and test suites. They allow unit tests to be written for everything, simplify test structure, and avoid polluting domain code with testing infrastructure.},
author = {Mackinnon, Tim and Freeman, Steve and Craig, Philip},
file = {:Users/naubergois/Downloads/mockobjects.pdf:pdf},
isbn = {0201710404},
journal = {Extreme programming examined},
keywords = {extreme programming,mock objects,stubs,unit testing},
pages = {287--301},
title = {{Endo-Testing : Unit Testing with Mock Objects}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3214{\&}rep=rep1{\&}type=pdf},
year = {2001}
}



@inproceedings{Wert2013a,
abstract = {Performance problems pose a significant risk to software vendors. If left undetected, they can lead to lost customers, increased operational costs, and damaged reputation. Despite all efforts, software engineers cannot fully prevent performance problems being introduced into an application. Detecting and resolving such problems as early as possible with minimal effort is still an open challenge in software performance engineering. In this paper, we present a novel approach for Performance Problem Diagnostics (PPD) that systematically searches for well-known performance problems (also called performance antipatterns) within an application. PPD automatically isolates the problem's root cause, hence facilitating problem solving. We applied PPD to a well established transactional web e-Commerce benchmark (TPC-W) in two deployment scenarios. PPD automatically identified four performance problems in the benchmark implementation and its deployment environment. By fixing the problems, we increased the maximum throughput of the benchmark from 1800 requests per second to more than 3500.},
author = {Wert, Alexander and Happe, Jens and Happe, Lucia},
doi = {10.1109/ICSE.2013.6606601},
file = {:Users/naubergois/Downloads/ICSE-2013-PerformanceProblemDiagnostics.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {measurement,performance,problem detection},
number = {May},
pages = {552--561},
title = {{Supporting swift reaction: Automatically uncovering performance problems by systematic experiments}},
year = {2013}
}

@inproceedings{Smith2003,
abstract = {Performance antipatterns document common software performance problems as well as their solutions. These problems are often introduced during the architectural or design phases of software development, but not detected until later in testing or deployment. Solutions usually require software changes as opposed to system tuning changes. This paper presents three new performance antipatterns and gives examples to illustrate them. These antipatterns will help developers and performance engineers avoid common perfor- mance problems. 1.0},
author = {Smith, Connie U and Williams, Lloyd G},
file = {:Users/naubergois/Downloads/moreanti.pdf:pdf},
journal = {Computer Measurement Group Conference},
pages = {717--725},
title = {{More New Software Performance AntiPatterns: EvenMore Ways to Shoot Yourself in the Foot}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.4517{\&}rep=rep1{\&}type=pdf},
year = {2003}
}



@inproceedings{Glover1986,
abstract = {Tabu Search is a meta-heuristic that guides a local heuristic search procedure to explore the solution space beyond local optimality. One of the main components of Tabu Search of Tabu Search is its use of adaptive memory, which creates a more flexible search behavior.},
author = {Glover, Fred and Mart{\'{i}}, Rafael},
file = {:Users/naubergois/Downloads/ts2.pdf:pdf},
journal = {Tabu Search},
pages = {1--16},
title = {{Tabu Search}},
year = {1986}
}

@inproceedings{Gay,
author = {Gay, Gregory},
file = {:Users/naubergois/Downloads/16mockito.pdf:pdf},
keywords = {automated unit test generation,real faults,search-based testing},
pages = {1--6},
title = {{Challenges in Using Search-Based Test Generation to Identify Real Faults in Mockito}}
}


@inproceedings{Wert2014,
abstract = {Performance problems such as high response times in software applications have a significant effect on the customer's satisfaction. In enterprise applications, performance problems are frequently manifested in inefficient or unnecessary communication patterns between software components originating from poor architectural design or implementation. Due to high manual effort, thorough performance analysis is often neglected, in practice. In order to overcome this problem, automated engineering approaches are required for the detection of performance problems. In this paper, we introduce several heuristics for measurement-based detection of well-known performance anti-patterns in inter-component communications. The detection heuristics comprise load and instrumentation descriptions for performance tests as well as corresponding detection rules. We integrate these heuristics with Dynamic Spotter, a framework for automatic detection of performance problems. We evaluate our heuristics on four evaluation scenarios based on an e-commerce benchmark (TPC-W) where the heuristics detect the expected communication performance anti-patterns and pinpoint their root causes. Copyright {\&}copy; 2014 ACM 978-1-4503-2577-6/14/06 ...{\$}15.00.},
author = {Wert, Alexander and Oehler, Marius and Heger, Christoph and Farahbod, Roozbeh},
doi = {10.1145/2602576.2602579},
file = {:Users/naubergois/Downloads/2014-qosa-messaging.pdf:pdf},
isbn = {9781450325776},
journal = {QoSA 2014 - Proceedings of the 10th International ACM SIGSOFT Conference on Quality of Software Architectures (Part of CompArch 2014)},
keywords = {Application programs;Customer satisfaction;},
pages = {3--12},
title = {{Automatic detection of performance anti-patterns in inter-component communications}},
url = {http://dx.doi.org/10.1145/2602576.2602579},
year = {2014}
}

@inproceedings{Arcelli2012,
abstract = {Identifying and removing the causes of poor performance in software systems are complex problems due to a variety of factors to take into account. Nowadays these problems are usually tackled after the software deployment only with human-based means, which frequently boil down to developer skills and previous experiences. Performance antipatterns can be used to cope with these problems since they capture typical design patterns that are known leading to performance problems, as well as refactoring actions that can be taken to remove them. The goal of this paper is to introduce an approach that allows the refactoring of architectural models, based on antipatterns, that aims at providing performance improvement. To this end, we use a Role-Based Modeling Language to represent: (i) antipattern problems as Source Role Models (SRMs), and (ii) antipattern solutions as Target Role Models (TRMs). Hence, SRM-TRM pairs represent new instruments in the hands of developers to achieve architectural model refactorings aimed at removing sources of performance problems. Model refactoring for antipattern removal can be in fact obtained by replacing an SRM with the corresponding TRM. This approach has been applied to a case study in the e-commerce domain, whose experimental results demonstrate its effectiveness. Copyright {\textcopyright} 2012 ACM.},
author = {Arcelli, Davide and Cortellessa, Vittorio and Trubiani, Catia},
doi = {10.1145/2304696.2304704},
file = {:Users/naubergois/Downloads/antipatterns-QoSA-2012.pdf:pdf},
isbn = {9781450313469},
journal = {Proceedings of the 8th international ACM SIGSOFT conference on Quality of Software Architectures (QoSA '12)},
keywords = {model refactoring,performance an-,software performance},
pages = {33--42},
title = {{Antipattern-Based Model Refactoring for Software Performance Improvement}},
url = {http://doi.acm.org/10.1145/2304696.2304704},
year = {2012}
}

@inproceedings{Cortellessa2007,
author = {Cortellessa, Vittorio and Frittella, Laurento},
file = {:Users/naubergois/Downloads/10.1007@978-3-540-75211-013.pdf:pdf},
keywords = {architectural,feedback,layered queueing networks,performance indices,software performance},
pages = {171--185},
title = {{A Framework for Automated Generation of Architectural Feedback from Software Performance Analysis}},
year = {2007}
}

@inproceedings{Smith2000,
author = {Smith, Connie U. and Williams, Lloyd G.},
doi = {10.1145/350391.350420},
file = {:Users/naubergois/Downloads/antipat.pdf:pdf},
isbn = {158113195X},
journal = {Proceedings of the second international workshop on Software and performance  - WOSP '00},
pages = {127--136},
title = {{Software performance antipatterns}},
url = {http://portal.acm.org/citation.cfm?doid=350391.350420},
year = {2000}
}



@book{Halili2008,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Halili, Emily H.},
booktitle = {PACKT Publishing},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {jmeter},
pmid = {25246403},
title = {{Apache JMeter: A practical beginner's guide to automated testing and performance measurement for your websites.}},
year = {2008}
}

@inproceedings{Aleti2016,
author = {Aleti, Aldeida and Moser, I. and Grunske, Lars},
doi = {10.1007/s10515-016-0197-7},
isbn = {1051501601},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Fitness landscape characterisation,Genetic algorithms,Test data generation},
pages = {1--19},
title = {{Analysing the fitness landscape of search-based software testing problems}},
year = {2016}
}


@book{Jaziri2008,
author = {Jaziri, Wassim},
isbn = {9783902613349},
pages = {294},
title = {{Local Search Techniques: Focus on Tabu Search}},
year = {2008}
}


@inproceedings{Blum2003,
abstract = {The emergence of metaheuristics for solving difficult combinatorial optimization problems is one of the most notable achievements of the last two decades in operations research. This paper provides an account of the most recent developments in the field and identifies some common issues and trends. Examples of applications are also reported for vehicle routing and scheduling problems.},
author = {Blum, C. and Roli, A.},
doi = {10.1007/s10479-005-3971-7},
isbn = {0254-5330},
issn = {02545330},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Metaheuristics,Unifying framework,Vehicle routing},
number = {3},
pages = {189--213},
title = {{Metaheuristics in combinatorial optimization: overview and conceptual comparison}},
volume = {35},
year = {2003}
}


@incollection{raidl2010metaheuristic,
  title={Metaheuristic hybrids},
  author={Raidl, G{\"u}nther R and Puchinger, Jakob and Blum, Christian},
  booktitle={Handbook of metaheuristics},
  pages={469--496},
  year={2010},
  publisher={Springer}
}

@inproceedings{DiAlesio2014,
		author = {Di Alesio, Stefano and Nejati, Shiva and Briand, Lionel and Gotlieb, Arnaud},
	journal = {Principles and Practice of Constraint Programming},
	pages = {813--830},
	  year={2014},
	Title = {{Worst-Case Scheduling of Software Tasks -- A Constraint Optimization Model to Support Performance Testing}}
	}

@inproceedings{DiAlesio2013,
	Abstract = {Safety-critical Real Time Embedded Systems (RT-ESs) are usually subject to strict timing and performance requirements that must be satisfied for the system to be deemed safe. In this paper, we use effective search strategies whose goal is finding worst case scenarios with respect to deadline misses. Such scenarios can in turn be used to test the target RTES and ensure that it satisfies its timing requirements even under worst case conditions. Specifically, we develop an approach based on Constraint Programming (CP) to automate the generation of test cases that reveal, or are likely to, task deadline misses. We evaluate it through a comparison with a state-of-the-art approach based on Genetic Algorithms (GA). In particular, we compare CP and GA in five case studies for efficiency, effectiveness, and scalability. Our experimental results show that, on the largest and more complex case studies, CP performs significantly better than GA. Furthermore, CP offers some advantages over GA, such as it guarantees a complete search when there is sufficient time, and, being deterministic, it doesn't rely on parameters that potentially have a significant effect on the search and therefore need to be tuned. Hence, we conclude that our results are encouraging and suggest this is an advantageous approach for stress testing of RTESs with respect to timing constraints.},
	Author = {{Di Alesio}, S and Nejati, S and Briand, L and Gotlieb, A},
	Doi = {10.1109/ISSRE.2013.6698915},
	File = {:Users/naubergois/Documents/10.0000@www.computer.org@generic-DD33B05EC8B4.pdf:pdf},
	Isbn = {9781479923663},
	Journal = {IEEE Xplore},
	Keywords = {constraint pro-,real-time systems,stress testing},
	Pages = {158--167},
	Title = {{Stress testing of task deadlines: A constraint programming approach}},
	Year = {2013}}

@inproceedings{Alesio2015,
	Author = {Alesio, Stefano D I and Briand, Lionel C and Nejati, Shiva and Gotlieb, Arnaud},
	File = {:Users/naubergois/Documents/a4-dialesio.pdf:pdf},
	Journal = {ACM Transactions on Software Engineering and Methodology},
	Number = {1},
	Title = {{Combining Genetic Algorithms and Constraint Programming}},
	Volume = {25},
	Year = {2015}}

@inproceedings{Raidl2006,
	Author = {Raidl, R},
	Isbn = {9783540463849},
	Issn = {03029743},
	Journal = {Hybrid Metaheuristics (LNCS 4030)},
	Pages = {1--12},
	Title = {{A Unified View on Hybrid Metaheuristics}},
	Year = {2006}}

@inproceedings{Pohlheim2005,
	Abstract = {Whereas the verification of non-safety-related embedded software typically focuses on demonstrating that the implementation fulfills its functional requirements, this is not sufficient for safety-relevant systems. In this case, the control software must also meet application- specific safety requirements.Safety requirements typically arise from the application of hazard and/or safety analysis techniques, e.g., FMEA, FTA or SHARD. During the downstream development process it must be shown that these requirements cannot be violated. This can be achieved utilizing different techniques. One way of providing evidence that violations of the safety properties identified cannot occur is to thoroughly test each of the safety requirements.This paper introduces Evolutionary Safety Testing (EST), a fully automated procedure for the safety testing of embedded control software. EST employs extended evolutionary algorithms in an optimization process which aggressively tries to find test data sequences that cause the test object to violate a given safety requirement.A compact description formalism for input sequences for safety testing is presented, which is compatible with description techniques used during other test process stages. This compact description allows 1) an efficient application of evolutionary algorithms (and other optimization techniques) and 2) the description of long test sequences necessary for the adequate stimulation of real-world systems. The objective function is designed in such a way that optimal values represent test data sequences which violate a given safety requirement. By means of repeated input sequence generation, software execution and the subsequent evaluation of the objective function each safety requirement is extensively tested.The use of EST for the safety testing of automotive control software is demonstrated using safety requirements of an adaptive cruise control (ACC) system.The EST approach can easily be integrated into an overall software test strategy which combines different test design techniques with specific test objectives.},
	Author = {Pohlheim, Hartmut and Conrad, Mirko and Griep, Arne},
	Doi = {10.4271/2005-01-0750},
	Journal = {Analysis},
	Number = {724},
	Pages = {804----814},
	Title = {{Evolutionary Safety Testing of Embedded Control Software by Automatically Generating Compact Test Data Sequences}},
	Year = {2005}}

@inproceedings{Gross2000,
	Abstract = {Software architecture design approaches typically treat architecture as an abstraction of the implemented system. However, doing so means that the concepts, languages, notations, and tools for architecture are much more closely related to those of detailed design and implementation than to those of software requirements. Thus the gap between requirements and architecture represents a paradigm shift, while that between architecture and detailed design does not. Global Analysis, which is part of the Siemens Four Views architecture design approach, is a set of activities that serves to reduce the magnitude of this gap by guiding the architecture design process, capturing design rationale, and supporting traceability between requirements and architecture. In this paper Global Analysis is re-examined in light of five years of teaching it, reflecting on it, comparing it to other approaches, and examining how it was applied in four new systems. This experience confirms the value of the Global Analysis activities and the importance of capturing its results. In some cases the benefit went beyond that envisioned, and in other cases Global Analysis was not applied as expected. Because the templates that are provided for Global Analysis results have such a strong influence on how the activities were performed, this will be the focus of future changes},
	Author = {Gross, Hg and Jones, Bryan F and Eyres, David E},
	Doi = {10.1049/ip-sen},
	File = {:Users/naubergois/Documents/gross2000.pdf:pdf},
	Isbn = {0818669101},
	Issn = {14625970},
	Journal = {Software, IEE Proceedings-},
	Number = {2},
	Pages = {25--30},
	Pmid = {18015135},
	Title = {{Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems}},
	Volume = {147},
	Year = {2000}}

@inproceedings{Smeral2014,
	Author = {\v{S}meral, Ron},
	File = {:Users/naubergois/Dropbox/dp.pdf:pdf},
	Title = {{Modern Performance Tools Applied}},
	Year = {2014}}

@inproceedings{Puchinger2005,
	Abstract = {In this survey we discuss different state-of-the-art approaches of combining exact algorithms and metaheuristics to solve combinatorial optimization problems. Some of these hybrids mainly aim at providing optimal solutions in shorter time, while others primarily focus on getting better heuristic solutions. The two main categories in which we divide the approaches are collaborative versus integrative combinations.We further classify the different techniques in a hierarchical way. Altogether, the surveyed work on combinations of exact algorithms and metaheuristics documents the usefulness and strong potential of this research direction.},
	Author = {Puchinger, Jakob and Raidl, R},
	Doi = {10.1007/11499305\_5},
	File = {:Users/naubergois/Documents/puchinger-05.pdf:pdf},
	Isbn = {9783540263197},
	Issn = {03029743},
	Journal = {Artificial Intelligence and Knowledge Engineering Applications a Bioinspired Approach},
	Pages = {41--53},
	Title = {{Combining Metaheuristics and Exact Algorithms in Combinatorial Optimization : A Survey and Classification}},
	Volume = {3562},
	Year = {2005}}

@inproceedings{Blum2012,
	Abstract = {Research in metaheuristics for combinatorial optimization problems has lately experienced a noteworthy shift towards the hybridization of metaheuristics with other techniques for optimization. At the same time, the focus of research has changed from being rather algorithm-oriented to being more problem-oriented. Nowadays the focus is on solving the problem at hand in the best way possible, rather than promoting a certain metaheuristic. This has led to an enormously fruitful cross-fertilization of different areas of optimization. This cross-fertilization is documented by a multitude of powerful hybrid algorithms that were obtained by combining components from several different optimization techniques. Hereby, hybridization is not restricted to the combination of different metaheuristics but includes, for example, the combination of exact algorithms and metaheuristics. In this work we provide a survey of some of the most important lines of hybridization. The literature review is accompanied by the presentation of illustrative examples. {\copyright} 2010 Elsevier B.V. All rights reserved.},
	Author = {Blum, Christian},
	Doi = {10.1007/978-3-642-33860-1\_1},
	File = {:Users/naubergois/Documents/blum-11.pdf:pdf},
	Isbn = {9783642338595},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Keywords = {combinatorial optimization,hybrid metaheuristics},
	Number = {6},
	Pages = {1--10},
	Publisher = {Elsevier B.V.},
	Title = {{Hybrid metaheuristics in combinatorial optimization: A tutorial}},
	Volume = {7505 LNCS},
	Year = {2012}}

@inproceedings{Wang2010,
	Author = {Wang, Xingen and Zhou, Bo and Li, Wei},
	Doi = {10.1109/ISPA.2010.24},
	File = {:Users/naubergois/Dropbox/WangXingen-ISPA2010.pdf:pdf},
	Isbn = {978-1-4244-8095-1},
	Journal = {International Symposium on Parallel and Distributed Processing with Applications},
	Keywords = {load model,load testing,markov chains,model,performance engineering,usage},
	Pages = {483--490},
	Title = {{Model Based Load Testing of Web Applications}},
	Year = {2010}}

@book{Smith:2012qr,
	Author = {Smith, J.~M. and Jones, A.~B.},
	Edition = {7th},
	Publisher = {Publisher},
	Title = {{B}ook {T}itle},
	Year = {2012}}

@inproceedings{Smith:2013jd,
	Author = {Jones, A.~B. and Smith, J.~M.},
	Journal = {{J}ournal {T}itle},
	Month = {March},
	Number = {52},
	Pages = {123-456},
	Publisher = {Publisher},
	Title = {{A}rticle {T}itle},
	Volume = {13},
	Year = {2013}}

@inproceedings{Tlili1917,
	Author = {Tlili, Marouane and Wappler, Stefan and Sthamer, Harmen},
	Isbn = {1595931864},
	Journal = {Technology},
	Keywords = {daimler-,harmen,sthamer},
	Pages = {1917--1924},
	Title = {{Improving Evolutionary Real-Time Testing}},
	Year = {1917}}

@phdthesis{Jiang2010,
	Author = {Jiang, ZM},
	Booktitle = {\ldots symposium on Software testing and analysis},
	Title = {{Automated analysis of load testing results}},
	Url = {http://dl.acm.org/citation.cfm?id=1831726},
	Year = {2010}}

@inproceedings{Jiang2009,
	Abstract = {The goal of a load test is to uncover functional and per- formance problems of a system under load. Performance problems refer to the situations where a system suffers from unexpectedly high response time or low throughput. It is difficult to detect performance problems in a load test due to the absence of formally-defined performance objectives and the large amount of data that must be examined. In this paper, we present an approach which automati- cally analyzes the execution logs of a load test for perfor- mance problems. We first derive the system's performance baseline from previous runs. Then we perform an in-depth performance comparison against the derived performance baseline. Case studies show that our approach produces few false alarms (with a precision of 77\%) and scales well to large industrial systems.},
	Author = {Jiang, ZM and Hassan, AE},
	Journal = {\ldots , 2009. ICSM 2009. IEEE \ldots},
	Title = {{Automated performance analysis of load tests}},
	Year = {2009}}

@inproceedings{Afzal2009a,
	Abstract = {Search-based software testing is the application of metaheuristic search techniques to generate software tests. The test adequacy criterion is transformed into a fitness function and a set of solutions in the search space are evaluated with respect to the fitness function using a metaheuristic search technique. The application of metaheuristic search techniques for testing is promising due to the fact that exhaustive testing is infeasible considering the size and complexity of software under test. Search-based software testing has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional) and grey-box (combination of structural and functional) testing. In addition, metaheuristic search techniques have also been applied to test non-functional properties. The overall objective of undertaking this systematic review is to examine existing work into non-functional search-based software testing (NFSBST). We are interested in types of non-functional testing targeted using metaheuristic search techniques, different fitness functions used in different types of search-based non-functional testing and challenges in the application of these techniques. The systematic review is based on a comprehensive set of 35 articles obtained after a multi-stage selection process and have been published in the time span 1996-2007. The results of the review show that metaheuristic search techniques have been applied for non-functional testing of execution time, quality of service, security, usability and safety. A variety of metaheuristic search techniques are found to be applicable for non-functional testing including simulated annealing, tabu search, genetic algorithms, ant colony methods, grammatical evolution, genetic programming (and its variants including linear genetic programming) and swarm intelligence methods. The review reports on different fitness functions used to guide the search for each of the categories of execution time, safety, usability, quality of service and security; along with a discussion of possible challenges in the application of metaheuristic search techniques. ?? 2009 Elsevier B.V. All rights reserved.},
	Author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
	Doi = {10.1016/j.infsof.2008.12.005},
	File = {:Users/naubergois/Dropbox/X12-searchbased-testing-afzal-ist09.pdf:pdf},
	Isbn = {0950-5849},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Non-functional system properties,Search-based software testing,Systematic review},
	Number = {6},
	Pages = {957--976},
	Publisher = {Elsevier B.V.},
	Title = {{A systematic review of search-based testing for non-functional system properties}},
	Volume = {51},
	Year = {2009}}

@inproceedings{Stations,
	Author = {{Wegener, Joachim and Pitschinetz, Roman and Sthamer}, Harmen},
	Journal = {Proceedings of the 1st International Workshop on Automated Program Analysis, Testing and Verification (WAPATV'00)},
	Title = {{Automated Testing of Real-Time Tasks}},
	Year = {2000}}

@inproceedings{Nevedrov2007,
	Author = {Nevedrov, Dmitri},
	Pages = {1--11},
	Title = {{Using JMeter to Performance Test Web Services}},
	Year = {2007}}

@book{Molyneaux2009,
	Author = {Molyneaux, Ian},
	Isbn = {9780596551056},
	Keywords = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Language = {en},
	Mendeley-Tags = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Month = jan,
	Pages = {159},
	Publisher = {"O'Reilly Media, Inc."},
	Shorttitle = {The Art of Application Performance Testing},
	Title = {{The Art of Application Performance Testing: Help for Programmers and Quality Assurance}},
	Year = {2009},
	edition  = {1st}}

@inproceedings{Sullivan,
	Author = {Sullivan, Michael O and V\"{o}ssner, Siegfried and Wegener, Joachim and Ag, Daimler-benz},
	File = {:Users/naubergois/Dropbox/eurostar1998.pdf:pdf},
	Pages = {1--20},
    Year = {1998},
	Title = {{Testing Temporal Correctness of Real-Time Systems --- A New Approach Using Genetic Algorithms and Cluster Analysis ---}}}

@inproceedings{Draheim2006b,
	Author = {Draheim, D. and Grundy, J. and Hosking, J. and Lutteroth, C. and Weber, G.},
	Booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
	Doi = {10.1109/CSMR.2006.43},
	Isbn = {0-7695-2536-9},
	Issn = {1052-8725},
	Title = {{Realistic load testing of Web applications}},
	Year = {2006}}


@inproceedings{Vetoio2011,
author = {Vetoio, Via},
file = {:Users/naubergois/Downloads/PhDThesis-CatiaTrubiani.pdf:pdf},
journal = {Language},
title = {{PhD Thesis in Computer Science Automated generation of architectural feedback from software performance analysis results Catia Trubiani}},
year = {2011}
}

	
	
@book{brown1998antipatterns,
  title={AntiPatterns: refactoring software, architectures, and projects in crisis},
  author={Brown, William H and Malveau, Raphael C and McCormick, Hays W and Mowbray, Thomas J},
  year={1998},
  publisher={John Wiley \& Sons, Inc.}
}
	
@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	
	

@phdthesis{Luiz2011,
	Author = {Luiz, Artur and Freitas, Cunha and Prof, Orientadora and Vieira, Renata},
	School = {Pontif{\'\i}cia Universidade Cat{\'o}lica do Rio Grande do Sul},
	Title = {{Ontologias para Teste de Desempenho de Software}},
	Year = {2011}}

@inproceedings{Fe2004,
	Author = {F\'{e}, Iure De Sousa and dos Santos, Pedro de Alc\^{a}ntara},
	Title = {{Os custos dos Testes de Desempenho e Estresse}},
	Year = {2004}}

@inproceedings{Babbar2011,
	Author = {Babbar, C and Bajpai, N and Sarmah, Dk},
	Title = {{Web Application Performance Analysis based on Component Load Testing}},
	Isbn = {9789380544007},
	Journal = {International Journal of Technology},
	Shorttitle= {Web Application Performance Analysis based on Component Load Testing}, 
	Year = {2011}}

@inproceedings{Avritzer1995,
	Author = {Avritzer, A. and Weyuker, E.J.},
	Issn = {0098-5589},
	Journal = {Software Engineering, IEEE \ldots},
	Keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Mendeley-Tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Number = {9},
	Pages = {705--716},
	Title = {{The automatic generation of load test suites and the assessment of the resulting software}},
	Volume = {21},
	Year = {1995}}

@inproceedings{Garousi2010,
	Author = {Garousi, Vahid},
	Doi = {10.1109/TSE.2010.5},
	Issn = {0098-5589},
	Journal = {IEEE Transactions on Software Engineering},
	Keywords = {empirical analysis,genetic algorithms,search-based testing,stress testing,test automation,test tools},
	Month = nov,
	Number = {6},
	Pages = {778--797},
	Title = {{A Genetic Algorithm-Based Stress Test Requirements Generator Tool and Its Empirical Evaluation}},
	Volume = {36},
	Year = {2010}}

@inproceedings{Avritzer1993d,
	Address = {New York, NY, USA},
	Annote = {From Duplicate 1 ( },
	Author = {Avritzer, Alberto and Larson, Brian},
	Booktitle = {ACM SIGSOFT Software Engineering Notes},
	Doi = {10.1145/154183.154244},
	Isbn = {0-89791-608-5},
	Pages = {82--88},
	Publisher = {ACM},
	Series = {ISSTA '93},
	Title = {{Load Testing Software Using Deterministic State Testing}},
	Year = {1993}}

@inproceedings{Avritzer1994,
	Address = {New York, New York, USA},
	Author = {Avritzer, Alberto and Weyuker, EJ},
	Doi = {10.1145/186258.186507},
	Isbn = {0897916832},
	Journal = {\ldots international symposium on Software testing \ldots},
	Pages = {44--57},
	Publisher = {ACM Press},
	Title = {{Generating test suites for software load testing}},
	Year = {1994}}

@inproceedings{Garousi2006,
	Author = {Garousi, Vahid},
	Isbn = {9780494262252},
	Number = {August},
	Title = {{Traffic-aware Stress Testing of Distributed Real-Time Systems based on UML Models using Genetic Algorithms}},
	Year = {2006}}

@inproceedings{Santos2011,
	Author = {Santos, I de Sousa and Santos, AR and Neto, PA dos Santos},
	Journal = {SEKE},
	Keywords = {- software testing,data generation,experimental study,however,limitations in,non-functional,of performance and stress,requirements,scripts,scripts from functional testing,testing,tool enabled the generation},
	Title = {{Reusing Functional Testing in order to Decrease Performance and Stress Testing Costs.}},
	Year = {2011}}

@book{bernard2012foundations,
	Author = {Bernard, Pierre},
	Publisher = {Van Haren},
	Title = {Foundations of ITIL},
	Year = {2012}}

@inproceedings{Abu-nimeh2001,
	Author = {Abu-nimeh, Saeed and Nair, Suku and Marchetti, Marco},
	Keywords = {bandwidth throttle,denial of service,ramp-up time,response time,stress-testing,think,time,ttfb,ttlb},
	Title = {{Avoiding Denial of Service via Stress Testing}},
	Year = {2001}}

@inproceedings{Garousi2008,
	Author = {Garousi, Vahid},
	Doi = {10.1145/1389095.1389433},
	Isbn = {9781605581309},
	Journal = {Proceedings of the 10th annual conference on Genetic and evolutionary computation - GECCO '08},
	Keywords = {empirical analysis,genetic algorithms,stress testing},
	Pages = {1743},
	Title = {{Empirical analysis of a genetic algorithm-based stress test technique}},
	Year = {2008}}

@inproceedings{Chakravarty2010,
	Author = {Chakravarty, A},
	Journal = {Information Technology: New Generations ( \ldots},
	Title = {{Stress testing an ai based web service: A case study}},
	Year = {2010}}

@inproceedings{Acharya2009,
	Author = {Acharya, Mithun and Kommineni, Vamshidhar},
	Doi = {10.1109/ASE.2009.95},
	Isbn = {9780769538914},
	Issn = {1527-1366},
	Journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
	Pages = {409--420},
	Title = {{Mining health models for performance monitoring of services}},
	Year = {2009}}

@inproceedings{Catelani2011,
	Doi = {10.1016/j.csi.2010.06.006},
	File = {:Users/naubergois/Dropbox/1-s2.0-S092054891000084X-main.pdf:pdf},
	Isbn = {09205489 (ISSN)},
	Issn = {09205489},
	Journal = {Computer Standards and Interfaces},
	Keywords = {Mean time to overflow,Quality in use,Software automated testing,Software reliability},
	Number = {2},
	Pages = {152--158},
	Publisher = {Elsevier B.V.},
	Title = {{Software automated testing: A solution to maximize the test plan coverage and to increase software reliability and quality in use}},
	Volume = {33},
	Year = {2011}}

@inproceedings{Wegener1997,
	Abstract = {The development of real-time systems is an essential industrial activity whose importance is increasing. The most important analytical method to assure the quality of real-time systems is dynamic testing. Testing is the only method which examines the actual run-time behaviour of real-time software, based on an execution in the real application environment. Dynamic aspects like the duration of computations, the memory actually needed, or the synchronization of parallel processes are of major importance for the correct function of real-time systems and have to be tested. A comprehensive investigation of existing software test methods shows that they mostly concentrate on testing for functional correctness. They are not suited for an examination of temporal correctness which is essential to real-time systems. Very small systems show a wide range of different execution times. Therefore, existing test procedures must be supplemented by new methods, which concentrate on determining whether the system violates its specified timing constraints. In general, this means that outputs are produced too early or their computation takes too long. The task of the tester is to find the inputs with the longest or shortest execution times to check whether they produce a temporal error. If the search for such inputs is interpreted as a problem of optimization, genetic algorithms can be used to find the inputs with the longest or shortest execution times automatically. The fitness function is the execution time measured in processor cycles. Experiments using genetic algorithms on a number of programs with up to 1511 LOC and 843 integer input parameters have successfully identified new longer and shorter paths than had been found using random testing or systematic testing. Genetic algorithms are able therefore to check large programs and they show considerable promise in establishing the validity of the temporal behaviour of real-time software.},
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Doi = {10.1023/A:1018551716639},
	Issn = {0963-9314, 1573-1367},
	Journal = {Software Quality Journal},
	Keywords = {embedded systems,genetic algorithms,real time systems,temporal behaviour,testing},
	Number = {2},
	Pages = {127--135},
	Title = {{Testing real-time systems using genetic algorithms}},
	Url = {http://www.springerlink.com/index/uh26067rt3516765.pdf},
	Volume = {6},
	Year = {1997}}

@inproceedings{Alander,
	Abstract = {In this work we are studying possibilities to test software using genetic algorithm search. The idea is to produce test cases in order to find problematic situations like processing time extremes. The proposed test method comes under the heading of automated dynamic stress testing. Keywords: genetic algorithms, software engineering, dynamic stress testing 1 Introduction Real-time software is increasingly applied to products in which failure may have severe consequences, thus the requirements for correctness and reliability are getting higher, too. In very reliable sequential programs, the rate of errors should be less than 10 errors/1000 lines of code, to avoid functional failure. Achieving this level is very labourious, because the amount of program testing work grows exponentially with code size. Testing software manually is slow, expensive and demands inventiveness. Automated testing can reduce both the time and costs needed for performing tests. Exhaustive test data generation is...},
	Annote = {From Duplicate 1 ( },
	Author = {Alander, Jarmo T. JT and Mantere, Timo and Turunen, Pekka},
	Booktitle = {Neural Nets and Genetic Algorithms},
	Date-Modified = {2015-12-05 06:11:49 +0000},
	Title = {{Genetic Algorithm Based Software Testing}},
	Year = {1998}}

@inproceedings{Barros2007,
	Author = {Barros, Marcelo De and Shiau, Jing},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barros, Shiau - 2007 - Web services wind tunnel On performance testing large-scale stateful web services.pdf:pdf},
	Journal = {\ldots and Networks, 2007. \ldots},
	Title = {{Web services wind tunnel: On performance testing large-scale stateful web services}},
	Year = {2007}}

@inproceedings{Weyuker2000,
	Abstract = {An approach to software performance testing is discussed. A case study describing the experience of using this approach for testing the performance of a system used as a gateway in a large industrial client/server transaction processing application is presented.},
	Author = {Weyuker, EJ and Vokolos, FI},
	Doi = {10.1109/32.888628},
	Issn = {0098-5589},
	Journal = {IEEE transactions on software engineering},
	Keywords = {Software performance testing,performance testing.,program testing,software testing},
	Mendeley-Tags = {Software performance testing,performance testing.,program testing,software testing},
	Number = {12},
	Pages = {1147--1156},
	Shorttitle = {Experience with Performance Testing of Software Sy},
	Title = {{Experience with performance testing of software systems: issues, an approach, and case study}},
	Volume = {26},
	Year = {2000}}

@inproceedings{Raiha2010,
	Abstract = {This survey investigates search-based approaches to software design. The basics of the most popular meta-heuristic algorithms are presented as background to the search-based viewpoint. Software design is considered from a wide viewpoint, including topics that can also be categorized as software maintenance or re-engineering. Search-based approaches have been used in research from the high architecture design level to software clustering and finally software refactoring. Enhancing and predicting software quality with search-based methods is also taken into account as a part of the design process. The background for the underlying software engineering problems is discussed, after which search-based approaches are presented. Summarizing remarks and tables collecting the fundamental issues of approaches for each type of problem are given. The choices regarding critical decisions, such as representation and fitness function, when used in meta-heuristic search algorithms, are emphasized and discussed in detail. Ideas for future research directions are also given. {\copyright} 2010 Elsevier Inc.},
	Author = {R\"{a}ih\"{a}, Outi},
	Doi = {10.1016/j.cosrev.2010.06.001},
	Isbn = {15740137},
	Issn = {15740137},
	Journal = {Computer Science Review},
	Keywords = {Search algorithms,Search-based software engineering,Software design,Software quality},
	Number = {4},
	Pages = {203--249},
	Publisher = {Elsevier Inc.},
	Title = {{A survey on search-based software design}},
	Volume = {4},
	Year = {2010}}

@inproceedings{Mohamed2012,
	Abstract = {With the recent rapid development of mobile devices in terms of processing power, memory and storage capabilities coupled with the advancements of wireless technology in terms of higher data transmission rates such as 3G and 4G, it has now become feasible to host Web services on mobile devices. In this paper we propose a lightweight framework for hosting Web services on mobile devices. We further evaluate and provide a comparative analysis for hosting RESTful Web services versus SOAP-based Web services on our framework. Our experimental results and analysis indicate that RESTful Web services are less resource-consuming and more efficient for the implementation and provisioning of Web services from resource-constrained mobile devices. ?? 2012 Published by Elsevier Ltd.},
	Author = {Mohamed, KamalEldin and Wijesekera, Duminda},
	Doi = {10.1016/j.procs.2012.06.095},
	Isbn = {1877-0509},
	Issn = {18770509},
	Journal = {Procedia Computer Science},
	Keywords = {Lightweight framework,Mobile web server,REST,SOAP,Web services},
	Pages = {744--751},
	Publisher = {Duminda Wijesekera},
	Title = {{Performance analysis of web services on mobile devices}},
	Volume = {10},
	Year = {2012}}

@book{reeves1993modern,
	Author = {Reeves, Colin R},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {Modern heuristic techniques for combinatorial problems},
	Year = {1993}}

@inproceedings{Sandler2004,
	Abstract = {The classic, landmark work on software testingThe hardware and software of computing have changed markedly in the three decades since the first edition of The Art of Software Testing, but this book's powerful underlying analysis has stood the test of time. Whereas most books on software testing target particular development techniques, languages, or testing methods, The Art of Software Testing, Third Edition provides a brief but powerful and comprehensive presentation of time-proven software testing approaches. If your software development project is mission critical, this book is an investment that will pay for itself with the first bug you find.The new Third Edition explains how to apply the book's classic principles to today's hot topics including:Testing apps for iPhones, iPads, BlackBerrys, Androids, and other mobile devicesCollaborative (user) programming and testingTesting for Internet applications, e-commerce, and agile programming environmentsWhether you're a student looking for a testing guide you'll use for the rest of your career, or an IT manager overseeing a software development team, The Art of Software Testing, Third Edition is an expensive book that will pay for itself many times over.},
	Author = {Sandler, Corey and Badgett, Tom and Thomas, TM},
	File = {:Users/naubergois/Downloads/The Art of Software Testing, 3rd Edition.pdf:pdf},
	Isbn = {9781118133156},
	Keywords = {Business \& Economics / Reference,Computers / Information Technology},
	Language = {en},
	Mendeley-Tags = {Business \& Economics / Reference,Computers / Information Technology},
	Month = sep,
	Pages = {200},
	Publisher = {John Wiley \& Sons},
	Title = {{The Art of Software Testing}},
	Year = {2004}}

@book{Erinle2013,
	Author = {Erinle, Bayo},
	File = {:Users/naubergois/Dropbox/OPR/papers/performance-testing-with-jmeter-2-9.pdf:pdf},
	Isbn = {9781782165842},
	Title = {{Performance Testing With JMeter 2.9}},
	Year = {2013}}

@misc{Corporation2007,
	Abstract = {Performance Testing Guidance for Web Applications provides an end-to-end approach for implementing performance testing. Whether you are new to performance testing or looking for ways to improve your current performance-testing approach, you will gain insights that you can tailor to your specific scenarios.},
	Address = {United States?},
	Author = {Corporation, Microsoft},
	Edition = {1 edition},
	Isbn = {9780735625709},
	Language = {English},
	Month = nov,
	Pages = {288},
	Publisher = {Microsoft Press},
	Title = {{Performance Testing Guidance for Web Applications}},
	Url = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700 http://msdn.microsoft.com/en-us/library/bb924375.aspx},
	Year = {2007},
	Bdsk-Url-1 = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700%20http://msdn.microsoft.com/en-us/library/bb924375.aspx}}

@inproceedings{Snellman,
	Author = {Snellman, Niclas and Ashraf, Adnan and Porres, Ivan},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Snellman, Ashraf, Porres - Unknown - Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud(2).pdf:pdf},
	Keywords = {-performance testing,a flat performance curve,application should ideally maintain,cloud computing,intended maximum load level,rich in-,scalability testing,ternet applications,until it reaches its},
	Title = {{Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud}}}

@inproceedings{Cohen2004,
	Abstract = {This paper studies the use of statistical induction techniques as a basis for automated performance diagnosis and performance management. The goal of the work is to develop and evaluate tools for offline and online analysis of system metrics gathered from instrumentation in Internet server platforms. We use a promising class of probabilistic models (Tree-Augmented Bayesian Networks or TANs) to identify combinations of system-level metrics and threshold values that correlate with high-level with Service Level Objectives (SLOs) for average-case response timein a three-tier Web service under a variety of conditions. Experimental results from a testbed show that TAN models involving small subsets of metrics capture patterns of performance behavior in a way that is accurate and yields insights into the causes of observed performance effects. TANs are extremely efficient to represent and evaluate, and they have interpretability properties that make them excellent candidates for automated diagnosis and control. We explore the use of TAN models for offline forensic diagnosis, and in a limited online setting for performance forecasting with stable workloads.},
	Author = {Cohen, Ira and Goldszmidt, Moises and Kelly, Terence and Symons, Julie and Chase, Jeffrey S},
	File = {:Users/naubergois/Dropbox/HPL-2004-183.pdf:pdf},
	Journal = {Small},
	Number = {December},
	Pages = {6--8},
	Title = {{Correlating instrumentation data to system states : A building block for automated diagnosis and control performance forecasting automated performance diagnosis and performance management . The goal of the work is to develop and evaluate tools for offline}},
	Year = {2004}}

@inproceedings{Biolchini2005,
	Author = {Biolchini, Jorge and Mian, Paula Gomes and Candida, Ana and Natali, Cruz},
	Doi = {10.1007/978-3-540-70621-2},
	Isbn = {9783540706199},
	Issn = {18650929},
	Journal = {System Engineering and Computer Science Department COPPE/UFRJ, Technical Report ES},
	Number = {May},
	Pages = {165--176},
	Title = {{Systematic Review in Software Engineering}},
	Volume = {679},
	Year = {2005}}

@inproceedings{Goncalves2014,
	Author = {Gon\c{c}alves, Marcelo Can\'{a}rio},
	Title = {{Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplica\c{c}\~{o}es na Nuvem Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplica\c{c}\~{o}es na Nuvem}},
	Year = {2014}}

@book{Feitelson2013,
	Author = {Feitelson, Dror G},
	File = {:Users/naubergois/Dropbox/wlmod.pdf:pdf},
	Publisher = {Cambridge University Press},
	Title = {{Workload Modeling for Computer Systems Performance Evaluation}},
	Year = {2013}}

@inproceedings{Malik2010b,
	Author = {Malik, Haroon},
	Doi = {10.1145/1810295.1810408},
	File = {:Users/naubergois/Downloads/icse2010\_malik.pdf:pdf},
	Institution = {Queen's University, Kingston, ON, Canada},
	Isbn = {978-1-60558-719-6},
	Issn = {0270-5257},
	Journal = {Software Engineering, 2010 ACM/IEEE 32nd \ldots},
	Keywords = {automation,counters,load test,performance counters,principal component analysis},
	Pages = {421--424},
	Publisher = {IEEE},
	Title = {{A methodology to support load test analysis}},
	Volume = {2},
	Year = {2010}}

@inproceedings{Kuhn1997,
	Abstract = {What makes a distributed system reliable? A study of failures in
the US public switched telephone network (PSTN) shows that human
intervention is one key to this large system's reliability. Software is
not the weak link in the PSTN system's dependability. Extensive use of
built-in self-test and recovery mechanisms in major system components
(switches) contributed to software dependability and are significant
design features in the PSTN. The network's high dependability indicates
that the trade-off between dependability gains and complexity introduced
by built-in self-test and recovery mechanisms can be positive. Likewise,
the tradeoff between complex interactions and the loose coupling of
system components has been positive, permitting quick human intervention
in most system failures and resulting in an extremely reliable system
},
	Author = {Kuhn, D. Richard},
	Doi = {10.1109/2.585151},
	File = {:Users/naubergois/Dropbox/kuhn-97-pstn-failures.pdf:pdf},
	Issn = {00189162},
	Journal = {Computer},
	Number = {4},
	Pages = {31--36},
	Pmid = {150},
	Title = {{Sources of failure in the public switched telephone network}},
	Volume = {30},
	Year = {1997}}

@inproceedings{McMinn2004,
	Author = {McMinn, Philip and Court, Regent and Testing, Software and Street, Portobello},
	Doi = {10.1002/stvr.294},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/McMinn - 2004 - Search-based software test data generation a survey.pdf:pdf},
	Isbn = {1099-1689},
	Issn = {09600833},
	Journal = {Software testing, Verification and reliability},
	Keywords = {Automated software test data generation,Evolutionary algorithms,Evolutionary testing,Metaheuristic search,Search-based software engineering,Simulated annealing,algorithms,automated software test,automated software test data generation,data generation,evolutionary,evolutionary algorithms,evolutionary testing,metaheuristic search,search-based software engineering,simulated annealing},
	Pages = {1--58},
	Title = {{Search-based software test data generation: a survey}},
	Volume = {14},
	Year = {2004}}

@inproceedings{DiLucca2006,
	Author = {{Di Lucca}, Giuseppe a. and Fasolino, Anna Rita},
	Doi = {10.1016/j.infsof.2006.06.006},
	Isbn = {0-7695-2413-3},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Software testing,Web application testing,Web engineering},
	Pages = {1172--1186},
	Title = {{Testing Web-based applications: The state of the art and future trends}},
	Volume = {48},
	Year = {2006}}
	
@inproceedings{Harman2015,
abstract = {Search Based Software Testing (SBST) formulates testing as an optimisation problem, which can be attacked using computational search techniques from the field of Search Based Software Engineering (SBSE). We present an analysis of the SBST research agenda1, focusing on the open problems and chal- lenges of testing non-functional properties, in particular a topic we call ‘Search Based Energy Testing' (SBET), Multi-objective SBST and SBST for Test Strategy Identification. We conclude with a vision of FIFIVERIFY tools, which would automatically find faults, fix them and verify the fixes. We explain why we think such FIFIVERIFY tools constitute an exciting challenge for the SBSE community that already could be within its reach.},
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
isbn = {9781479971251},
journal = {8th IEEE International Conference on Software Testing, Verification and Validation (ICST)},
number = {Icst},
title = {{Achievements , open problems and challenges for search based software testing}},
url = {http://www0.cs.ucl.ac.uk/staff/mharman/icst15.pdf},
year = {2015}
}
	

@inproceedings{Anand2013,
	Author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
	Doi = {10.1016/j.jss.2013.02.061},
	Issn = {01641212},
	Journal = {Journal of Systems and Software},
	Keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
	Pages = {1978--2001},
	Title = {{An orchestrated survey of methodologies for automated software test case generation}},
	Volume = {86},
	Year = {2013}}

@inproceedings{Penta2007,
	Author = {Penta, Massimiliano Di and Canfora, Gerardo and Esposito, Gianpiero},
	Booktitle = {Proceedings of the 9th annual conference on Genetic and evolutionary computation},
	Isbn = {9781595936974},
	Keywords = {quality of,search-based testing,service level agreement},
	Pages = {1090--1097},
	Title = {{Search-based testing of service level agreements}},
	Year = {2007}}

@inproceedings{Barber1999,
	Author = {Barber, Scott},
	File = {:Users/naubergois/Dropbox/ucml\_1.1.pdf:pdf},
	Pages = {1--9},
	Title = {{User Community Modeling Language ( UCML {\texttrademark} ) v1 . 1 for Performance Test Workloads UCML {\texttrademark} Overview}},
	Year = {1999}}

@inproceedings{Silveira2011,
	Author = {da Silveira, MB and Rodrigues, EM and Zorzo, AF},
	Journal = {SEKE},
	Keywords = {- model-based testing,performance testing,software product line},
	Title = {{Generation of Scripts for Performance Testing Based on UML Models.}},
	Year = {2011}}

@inproceedings{Grechanik2012,
	Author = {Grechanik, Mark and Fu, Chen and Xie, Qing},
	Doi = {10.1109/ICSE.2012.6227197},
	Isbn = {978-1-4673-1067-3},
	Journal = {2012 34th International Conference on Software Engineering (ICSE)},
	Month = jun,
	Pages = {156--166},
	Publisher = {Ieee},
	Title = {{Automatically finding performance problems with feedback-directed learning software testing}},
	Year = {2012}}

@inproceedings{Barna2011,
	Author = {Barna, Cornel and Litoiu, M and Ghanbari, H},
	Isbn = {9781450306072},
	Journal = {International conference on Autonomi},
	Keywords = {autonomic system,performance,performance testing},
	Pages = {91--100},
	Title = {{Autonomic load-testing framework}},
	Year = {2011}}

@book{Everett2007,
	Author = {Everett, Gerald D and Jr., Raymond McLeod},
	Isbn = {9780471793717},
	Title = {{Software Testing: Testing Across the Entire Software Development Life Cycle}},
	Year = {2007}}

@inproceedings{Chen,
	Author = {Chen, Feifei},
	File = {:Users/naubergois/Downloads/13113010195260.pdf:pdf},
	Journal = {chinacloud.cn},
	Keywords = {as it requires,cloud computing,cost,effectiveness before the deployment,energy,however,of cloud systems,performance engineering,this is not a,trade-off analysis,trivial task},
	Title = {{Generating a Performance Test-bed for Cloud Computing Systems}}}
	
@misc{dean2003managing,
  title={Managing Software Requirements: A Use Case Approach},
  author={Dean, Leffingwell and Don, Widrig},
  year={2003},
  publisher={Addison Wesley}
}	

@inproceedings{Alba2008,
abstract = {In this paper we analyze the application of parallel and sequential evolutionary algorithms (EAs) to the automatic test data generation problem. The problem consists of automatically creating a set of input data to test a program. This is a fundamental step in software development and a time consuming task in existing software companies. Canonical sequential EAs have been used in the past for this task. We explore here the use of parallel EAs. Evidence of greater efficiency, larger diversity maintenance, additional availability of memory/CPU, and multi-solution capabilities of the parallel approach, reinforce the importance of the advances in research with these algorithms. We describe in this work how canonical genetic algorithms (GAs) and evolutionary strategies (ESs) can help in software testing, and what the advantages are (if any) of using decentralized populations in these techniques. In addition, we study the influence of some parameters of the proposed test data generator in the results. For the experiments we use a large benchmark composed of twelve programs that includes fundamental algorithms in computer science. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Alba, Enrique and Chicano, Francisco},
doi = {10.1016/j.cor.2007.01.016},
file = {:Users/naubergois/Downloads/testing-cor-sbse.pdf:pdf},
isbn = {0305-0548},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Evolutionary algorithms,Evolutionary testing,Parallel evolutionary algorithms,Software testing},
number = {10},
pages = {3161--3183},
title = {{Observations in using parallel and sequential evolutionary algorithms for automatic software testing}},
volume = {35},
year = {2008}
}

@inproceedings{Harman2010,
abstract = {Search-based optimization techniques have been applied to structural software test data generation since 1992, with a recent upsurge in interest and activity within this area. However, despite the large number of recent studies on the applicability of different search-based optimization approaches, there has been very little theoretical analysis of the types of testing problem for which these techniques are well suited. There are also few empirical studies that present results for larger programs. This paper presents a theoretical exploration of the most widely studied approach, the global search technique embodied by Genetic Algorithms. It also presents results from a large empirical study that compares the behavior of both global and local search-based optimization on real-world programs. The results of this study reveal that cases exist of test data generation problem that suit each algorithm, thereby suggesting that a hybrid global-local search (a Memetic Algorithm) may be appropriate. The paper presents a Memetic Algorithm along with further empirical results studying its performance.},
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/naubergois/Downloads/Software engineering IEEE.Vol.36.Iss.2.A.6.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Artificial intelligence,Automated test data generation,Evolutionary testing,Genetic algorithms,Hill climbing,Problem solving,Royal road,Schema theory,Search-based software engineering,Search-based testing,Testing and debugging,Testing tools},
number = {2},
pages = {226--247},
title = {{A theoretical and empirical study of search-based testing: Local, global, and hybrid search}},
volume = {36},
year = {2010}
}

@book{MohammadS.Obaidat,
author = {{Mohammad S. Obaidat}, Petros Nicopolitidis and Faouzi Zarai},
file = {:Users/naubergois/Downloads/Mohammad S. Obaidat, Faouzi Zarai, Petros Nicopolitidis-Modeling and Simulation of Computer Networks and Systems{\_} Methodologies and Applications-Morgan Kaufmann (2015).pdf:pdf},
isbn = {9780128008874},
title = {{Modeling and Simulation of Computer Networks and Systems Methodologies and Applications}}
}

@book{Tobergte2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Raidl, Gunther R and Puchinger, Jakob and Blum}, Christian},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid Metaheuristics{\_} An Emerging Approach to Optimization.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Hybrid Metaheuristics An Emerging Approach}},
volume = {53},
year = {2013}
}

@book{Talbi2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Metaheuristics.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Metaheuristics: From Design to Implementation}},
volume = {53},
year = {2013}
}

@inproceedings{Greenwald2003,
abstract = {Bowling named two desiderata for multiagent learning algorithms: rationality and convergence. This paper introduces co{\~{}}elated-Q learning, a natural generaliza- tion of Nash-Q NashoQ converge. FF-Q satisfies convergence, but in general it is not rational. Correlated-Q satisfies rationality by construction. This papers demonstrates the empirical convergence of correlated-Q on a standard testbed of general-sum Markov games. satisfies rationality, but in general it does not and FF-Q that satisfies these criteria.},
author = {Greenwald, Amy and Hall, Keith and Serrano, R},
file = {:Users/naubergois/Downloads/SS02-02-012.pdf:pdf},
journal = {Icml},
number = {3},
pages = {84--89},
title = {{Correlated Q-learning}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-02/SS02-02-012.pdf},
year = {2003}
}

@inproceedings{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@inproceedings{Hierons2009,
abstract = {Formal methods and testing are two important approaches that assist in the development of high-quality software.While traditionally these approaches have been seen as rivals, in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.},
author = {Hierons, Robert M and Bogdanov, Kirill and Bowen, Jonathan P and Cleaveland, Rance and Derrick, John and Dick, Jeremy and Gheorghe, Marian and Harman, Mark and Kapoor, Kalpesh and Krause, Paul and L{\"{u}}ttgen, Gerald and Simons, Anthony J H and Vilkomir, Sergiy and Woodward, Martin R and Zedan, Hussein},
doi = {http://doi.acm.org/10.1145/1459352.1459354},
file = {:Users/naubergois/Downloads/hierons2009.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
number = {2},
pages = {1--76},
title = {{Using formal specifications to support testing}},
volume = {41},
year = {2009}
}

@phdthesis{shousha2003performance,
  title={Performance Stress Testing of Real-Time Systems Using Genetic Algorithms},
  author={Shousha, Marwa},
  year={2003},
  school={Carleton University Ottawa}
}

@inproceedings{hong2000simultaneously,
  title={Simultaneously applying multiple mutation operators in genetic algorithms},
  author={Hong, Tzung-Pei and Wang, Hong-Shung and Chen, Wei-Chou},
  journal={Journal of heuristics},
  volume={6},
  number={4},
  pages={439--455},
  year={2000},
  publisher={Springer}
}

@inproceedings{Vogele2016,
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.},
author = {Vogele, Christian and van Hoorn, Andr{\'{e}} and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
doi = {10.1007/s10270-016-0566-5},
file = {:Users/naubergois/Downloads/VoegelevanHoornSchulzHasselbringKrcmar2016WESSBAS-SoSyM.pdf:pdf},
issn = {16191374},
journal = {Software and Systems Modeling},
keywords = {Load testing,Performance models,Performance prediction,Workload specifications},
number = {October},
pages = {1--35},
publisher = {Springer Berlin Heidelberg},
title = {{WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction???a model-driven approach for session-based application systems}},
url = {"http://dx.doi.org/10.1007/s10270-016-0566-5},
year = {2016}
}


@inproceedings{Menasce2002a,
author = {Menasc{\'{e}}, Daniel A and Mason, George},
file = {:Users/naubergois/Downloads/10.1.1.468.8603.pdf:pdf},
number = {June},
pages = {1--6},
title = {{TPC-W : A Benchmark for E-commerce}},
year = {2002}
}


@inproceedings{Sutton2012,
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, Richard S. and Barto, Andrew G.},
doi = {10.1109/MED.2013.6608833},
eprint = {1603.02199},
isbn = {0262193981},
issn = {18726240},
journal = {Learning},
number = {9},
pages = {322},
pmid = {18255791},
title = {Reinforcement learning},
volume = {3},
year = {2012}
}

@inproceedings{Szepesvari2010,
abstract = {Reinforcement learning is a learning paradigm concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective.What distin- guishes reinforcement learning from supervised learning is that only partial feedback is given to the learner about the learner's predictions. Further, the predictions may have long term effects through influencing the future state of the controlled system. Thus, time plays a special role. The goal in reinforcement learning is to develop efficient learning algorithms, as well as to understand the al- gorithms' merits and limitations. Reinforcement learning is of great interest because of the large number of practical applications that it can be used to address, ranging from problems in artificial intelligence to operations research or control engineering. In this book,we focus on those algorithms of reinforcement learning that build on the powerful theory of dynamic programming.We give a fairly comprehensive catalog of learning problems, describe the core ideas, note a large number of state of the art algorithms, followed by the discussion of their theoretical properties and limitations.},
author = {Szepesv{\'{a}}ri, Csaba and Bartok, Gabor},
doi = {10.2200/S00268ED1V01Y201005AIM009},
file = {:Users/naubergois/Downloads/RLAlgsInMDPs-lecture.pdf:pdf},
isbn = {9781608454921},
issn = {1939-4608},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
number = {x},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
volume = {4},
year = {2010}
}



@inproceedings{Bertolino2008,
abstract = {A Web Service is commonly not an independent software entity, but plays a role in some business process. Hence, it depends on the services provided by external Web Services, to provide its own service. While developing and testing a Web Service, such external services are not always available, or their usage comes along with unwanted side effects like, e.g., utilization fees or database modifications. We present a model-based approach to generate stubs for Web Services which respect both an extra-functional contract expressed via a Service Level Agree- ment (SLA), and a functional contract modeled via a state machine. These stubs allow a developer to set up a testbed over the target plat- form, in which the extra-functional and functional behavior of a Web Service under development can be tested before its publication.},
author = {Bertolino, Antonia and Angelis, Guglielmo De},
doi = {10.1007/978-3-540-68524-1_19},
file = {:Users/naubergois/Downloads/BAFP08.pdf:pdf},
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-68524-1{\_}19},
year = {2008}
}

@inproceedings{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@inproceedings{Trent1995,
author = {Trent, G and Sake, M},
file = {:Users/naubergois/Downloads/WebSTONE{\_}The{\_}First{\_}Generation{\_}in{\_}HTTP{\_}Se.pdf:pdf},
journal = {WWW Conference'95},
title = {{WebSTONE: The first generation in {\{}HTTP{\}} server benchmarking}},
year = {1995}
}

@inproceedings{Luo2015,
abstract = {A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster in order to automatically find performance bottlenecks in applications. We propose FOREPOST, a novel solution, for automatically finding performance bottlenecks in applications using black-box software testing. Our solution is an adaptive, feedback-directed learning testing system that learns rules from execution traces of applications. Theses rules are then used to automatically select test input data for performance testing. We hypothesize that FOREPOST can find more performance bottlenecks as compared to random testing. We have implemented our solution and applied it to a medium-size industrial application at a major insurance company and to two open-source applications. Performance bottlenecks were found automatically and confirmed by experienced testers and developers. We also thoroughly studied the factors (or independent variables) that impact the results of FOREPOST. {\&}copy; 2015 Springer Science+Business Media New York},
author = {Luo, Qi and Nair, Aswathy and Grechanik, Mark and Poshyvanyk, Denys},
doi = {10.1007/s10664-015-9413-5},
file = {:Users/naubergois/Downloads/10.1.1.699.7944.pdf:pdf},
isbn = {1066401594},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Feedback-directed learning system,Performance testing},
pages = {1--51},
title = {{FOREPOST: finding performance problems automatically with feedback-directed learning software testing}},
year = {2015}
}



@book{Talbi2012,
abstract = {The main goal of this book is to provide a state of the art of hybrid metaheuristics. The book provides a complete background that enables readers to design and implement hybrid metaheuristics to solve complex optimization problems (continuous/discrete, mono-objective/multi-objective, optimization under uncertainty) in a diverse range of application domains. Readers learn to solve large scale problems quickly and efficiently combining metaheuristics with complementary metaheuristics, mathematical programming, constraint programming and machine learning. Numerous real-world examples of problems and solutions demonstrate how hybrid metaheuristics are applied in such fields as networks, logistics and transportation, bio-medical, engineering design, scheduling.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
doi = {10.1007/978-3-642-30671-6},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid{\_}Metaheuristics{\_}An{\_}Introduction.pdf:pdf},
isbn = {9783642306709},
issn = {1098-6596},
keywords = {learning,neighborhood search,online and offline tuning,project scheduling,stochastic local search},
number = {December 2016},
pages = {19--35},
pmid = {25246403},
title = {{Hybrid Metaheuristics}},
volume = {2},
year = {2012}
}




@inproceedings{Mendoza2005a,
	Author = {Mendoza, Valerie and Novick, Dg},
	Doi = {10.1145/1085313.1085348},
	Isbn = {9157475725},
	Journal = {SIGDOC '05 Proceedings of the 23rd annual international conference on Design of communication: documenting \& designing for pervasive information},
	Keywords = {training,usability},
	Pages = {151--158},
	Title = {{Usability over time}},
	Year = {2005}}

@inproceedings{Glover1989,
	Abstract = {This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programming problems are then described, providing connections also to certain nonlinear programming applications. Finally, the paper concludes with a brief survey of new applications of tabu search that have occurred since the developments reported in Part I. Together with additional comparisons with other methods on a wide body of problems, these include results of parallel processing implementations and the use of tabu search in settings ranging from telecommunications to neural networks.},
	Author = {Glover, Fred},
	Doi = {10.1287/ijoc.2.1.4},
	Isbn = {079239965X},
	Issn = {0899-1499},
	Journal = {ORSA journal on Computing},
	Number = {3},
	Pages = {4--32},
	Pmid = {2758},
	Title = {{Tabu Search - Part II}},
	Volume = {2 1},
	Year = {1989}}

@inproceedings{Kirkpatrick2007,
	Author = {Kirkpatrick},
	Doi = {10.1126/science.220.4598.671},
	Issn = {0036-8075},
	Number = {4598},
	Pages = {671--680},
	Pmid = {17813860},
	Title = {{Optimization by SA}},
	Volume = {220},
	Year = {2007}}

@inproceedings{Goffe1994,
	Abstract = {Many statistical methods rely on numerical optimization to estimate a model's parameters. Unfortunately, conventional algorithms sometimes fail. Even when they do converge, there is no assurance that they have found the global, rather than a local, optimum. We test a new optimization algorithm, simulated annealing, on four econometric problems and compare it to three common conventional algorithms. Not only can simulated annealing find the global optimum, it is also less likely to fail on difficult functions because it is a very robust algorithm. The promise of simulated annealing is demonstrated on the four econometric problems.},
	Author = {Goffe, William L. and Ferrier, Gary D. and Rogers, John},
	Doi = {10.1016/0304-4076(94)90038-8},
	Isbn = {0304-4076},
	Issn = {03044076},
	Journal = {Journal of Econometrics},
	Keywords = {simulated},
	Number = {1-2},
	Pages = {65--99},
	Title = {{Global optimization of statistical functions with simulated annealing}},
	Volume = {60},
	Year = {1994}}

@phdthesis{tracey2000search,
	Author = {Tracey, Nigel James},
	School = {Citeseer},
	Title = {A search-based automated test-data generation framework for safety-critical software},
	Year = {2000}}

@inproceedings{alander1996ga,
	Author = {Alander, Jarmo T and Mantere, Pekka Turunen and Virolainen, Jari},
	Publisher = {Citeseer},
	Title = {GA in program testing},
	Year = {1996}}

@inproceedings{Tracey1998,
	Abstract = {One of the major costs in a software project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. The framework can incorporate a number of testing criteria, for both functional and non-functional properties. Application of the optimisation framework to testing specification failures and exception conditions is illustrated. The results of a number of small case studies are presented and show the efficiency and effectiveness of this dynamic optimisation-based approach to generating test-data},
	Author = {Tracey, N J and Clark, J a and Mander, K C},
	Keywords = {QA 76 Software, computer programming,},
	Title = {{Automated Programme Flaw Finding using Simulated Annealing}},
	Year = {1998}}

@inproceedings{Wegener1999,
	Abstract = {For real-time systems, correct system functionality depends on
logical as well as on temporal correctness. Static analysis alone is not
sufficient to verify the temporal behavior of real-time systems. Since
existing test methods are not specialized for the verification of
temporal correctness, we have developed a new testing method, namely
evolutionary testing. This paper illustrates results of the first
industrial application of the evolutionary test},
	Author = {Wegener, J. and Sthamer, H. and Pohlheim, H.},
	Doi = {10.1109/REAL.1999.818852},
	Isbn = {0-7695-0475-2},
	Issn = {1052-8725},
	Journal = {Proceedings 20th IEEE Real-Time Systems Symposium (Cat. No.99CB37054)},
	Title = {{Testing the temporal behavior of real-time tasks using extended evolutionary algorithms}},
	Year = {1999}}

@inproceedings{Mueller1998,
	Abstract = {The paper contrasts two methods to verify timing constraints of
real-time applications. The method of static analysis predicts the
worst-case and best-case execution times of a task's code by analyzing
execution paths and simulating processor characteristics without ever
executing the program or requiring the program's input. Evolutionary
testing is an iterative testing procedure, which approximates the
extreme execution times within several generations. By executing the
test object dynamically and measuring the execution times the inputs are
guided yielding gradually tighter predictions of the extreme execution
times. The authors examined both approaches on a number of real world
examples. The results show that static analysis and evolutionary testing
are complementary methods, which together provide upper and lower bounds
for both worst-case and best-case execution times},
	Author = {Mueller, F. and Wegener, J.},
	Doi = {10.1109/RTTAS.1998.683198},
	File = {:Users/naubergois/Dropbox/rtas98.pdf:pdf},
	Isbn = {0-8186-8569-7},
	Journal = {Proceedings. Fourth IEEE Real-Time Technology and Applications Symposium (Cat. No.98TB100245)},
	Title = {{A comparison of static analysis and evolutionary testing for the verification of timing constraints}},
	Year = {1998}}

@inproceedings{Puschner1998,
	Abstract = {Analytically derived worst case execution time (WCET) bounds are
prone to errors, because they often rely on information provided by the
user. The paper presents a method for testing the results of static WCET
analysis. The proposed test method is a blackbox test method that uses a
genetic algorithm (GA) for test case generation. Important properties of
the method are: (a) that it requires minimal information about possible
impact data from the user and (b) that the GA guides data generation
into directions that have a good chance to yield the real WCET of the
program under test. Experimental results show that GA based testing
produces results of high quality},
	Author = {Puschner, P. and Nossal, R.},
	Doi = {10.1109/REAL.1998.739738},
	Isbn = {0-8186-9212-X},
	Issn = {1052-8725},
	Journal = {Proceedings 19th IEEE Real-Time Systems Symposium (Cat. No.98CB36279)},
	Title = {{Testing the results of static worst-case execution-time analysis}},
	Year = {1998}}

@inproceedings{J.WegenerK.GrimmM.GrochtmannH.Sthamer1996,
	Author = {{J. Wegener, K. Grimm, M. Grochtmann, H. Sthamer}, B. Jones},
	File = {:Users/naubergois/Dropbox/eurostar1996.pdf:pdf},
	Journal = {EuroSTAR'96: Proceedings of the Fourth International Conference on Software Testing Analysis and Review},
	Title = {{Systematic testing of real-time systems}},
	Year = {1996}}

@inproceedings{Gro,
	Author = {Gro, Hans-Gerhard},
	Publisher = {Citeseer},
	Title = {A prediction system for dynamic optimisation-based execution time analysis},
	Year = {2001}}

@misc{Gross2003,
	Author = {Gross, Hg},
	Booktitle = {Proceedings of the International Conference on Information Technology: Prospects and Challenges in the 21st Century},
	File = {:Users/naubergois/Dropbox/grossITPC03\_RealTime.pdf:pdf},
	Title = {{An evaluation of dynamic, optimisation-based worst-case execution time analysis}},
	Year = {2003}}

@inproceedings{Briand2005,
	Author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
	Doi = {10.1145/1068009.1068183},
	Isbn = {1595930108},
	Journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
	Keywords = {genetic algorithms,schedulability theory},
	Pages = {1021},
	Title = {{Stress testing real-time systems with genetic algorithms}},
	Year = {2005}}

@inproceedings{Canfora,
	Author = {Canfora, Gerardo and Penta, Massimiliano Di and Esposito, Raffaele and Villani, Maria Luisa},
	Isbn = {1595930108},
	Keywords = {oriented software engineering,qos,service},
	Year = {2005},
	Title = {{An approach for QoS-aware service composition based on genetic algorithms}}}

@inproceedings{gross2000structural,
	Author = {Gross, H-G and Jones, Bryan F and Eyres, David E},
	Journal = {IEE Proceedings-Software},
	Number = {2},
	Pages = {25--30},
	Publisher = {IET},
	Title = {Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems},
	Volume = {147},
	Year = {2000}}

@inproceedings{goldberg1989messy,
	Author = {Goldberg, David E and Korb, Bradley and Deb, Kalyanmoy},
	Journal = {Complex systems},
	Number = {5},
	Pages = {493--530},
	Publisher = {Complex Systems Publications, Champaign, IL, USA},
	Title = {Messy genetic algorithms: Motivation, analysis, and first results},
	Volume = {3},
	Year = {1989}}

@inproceedings{wegener1998verifying,
	Author = {Wegener, Joachim and Grochtmann, Matthias},
	Journal = {Real-Time Systems},
	Number = {3},
	Pages = {275--298},
	Publisher = {Springer},
	Title = {Verifying timing constraints of real-time systems by means of evolutionary testing},
	Volume = {15},
	Year = {1998}}

@inproceedings{alander1998searching,
	Author = {Alander, Jarmo T and Mantere, Timo and Moghadampour, Ghodrat and Matila, Jukka},
	Journal = {Electric Power Systems Research},
	Number = {3},
	Pages = {229--233},
	Publisher = {Elsevier},
	Title = {Searching protection relay response time extremes using genetic algorithm---software quality by optimization},
	Volume = {46},
	Year = {1998}}

@inproceedings{Wegener1998,
	Abstract = {Many industrial products are based on the use of embedded computer systems. Usually, these systems have to fulfil real-time requirements, and correct system functionality depends on their logical correctness as well as on their temporal correctness. in order to verify the temporal behavior of real-time systems, previous scientific work has, to a large extent, concentrated on static analysis techniques. Although these techniques offer the possibility of providing safe estimates of temporal behavior for certain cases, there are a number of cases in practice for which static analysis can not be easily applied. Furthermore, no commercial tools for timing analysis of real-world programs are available. Therefore, the developed systems have to be thoroughly tested in order to detect existing deficiencies in temporal behavior, as well as to strengthen the confidence in temporal correctness. An investigation of existing test methods shows that they mostly concentrate on testing for logical correctness. They are nor specialised in the examination of temporal correctness which is also essential to real-rime systems. For this reason, existing test procedures must be supplemented by new methods which concentrate on determining whether the system violates its specified timing constraints. Normally, a violation means that outputs are produced too early, or their computation takes too long. The task of the tester therefore is to find the input situations with the longest or shortest execution limes, in order to check whether they produce a temporal error. If the starch for such inputs is interpreted as a problem of optimization, evolutionary computation can be used to automatically find the inputs with the longest or shortest execution rimes. This automatic search for accurate test data by means of evolutionary computation is called evolutionary testing. Experiments using evolutionary testing on a number of programs with up to 1511 LOC and 5000 input parameters have successfully identified new longer and shorter execution times than had been found using other testing techniques. Evolutionary testing, therefore, seems to be a promising approach for the verification of timing constraints. A combination of evolutionary testing and systematic testing offers further opportunities to improve the test quality, and could lead to an effective test strategy for real-time systems.},
	Author = {Wegener, J and Grochtmann, M},
	Doi = {Doi 10.1023/A:1008096431840},
	Isbn = {0922-6443},
	Issn = {0922-6443},
	Journal = {Real-Time Systems},
	Keywords = {evolutionary algorithm,evolutionary optimization,evolutionary testing,genetic algorithms,real-time systems,temporal behavior,temporal correctness,test strategy,testing,validation,verification},
	Number = {3},
	Pages = {275--298},
	Title = {{Verifying timing constraints of real-time systems by means of evolutionary testing}},
	Volume = {15},
	Year = {1998}}

@book{Halili2008,
	Abstract = {"This book introduces you to JMeter (version 2.3) and test automation, providing a step-by-step guide to testing with JMeter. You will learn how to measure the performance of a website using JMeter. While it discusses test automation generally, the bulk of this book gives specific, vivid, and easy-to-understand walkthroughs of JMeter's testing tools showing what they can do, and when and how to use them. Learn to load-test your website, test its functional behaviour, and measure its performance by implementing the features of Jmeter"--Resource description p.},
	Author = {Halili, Emily H},
	Isbn = {9786611737528 6611737529 9781847192967 1847192963 1847192955 9781847192950},
	Title = {{Apache JMeter a practical beginner's guide to automated testing and performance measurement for your websites}},
	Year = {2008}}

@inproceedings{wegener1997testing,
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Journal = {Software Quality Journal},
	Number = {2},
	Pages = {127--135},
	Publisher = {Springer},
	Title = {Testing real-time systems using genetic algorithms},
	Volume = {6},
	Year = {1997}}
	
	@book{Lewis2005,
abstract = {It is often assumed that software testing is based on clearly defined requirements and software development standards. However, testing is typically performed against changing, and sometimes inaccurate, requirements. The third edition of a bestseller, Software Testing and Continuous Quality Improvement, Third Edition provides a continuous quality framework for the software testing process within traditionally structured and unstructured environments. This framework aids in creating meaningful test cases for systems with evolving requirements. This completely revised reference provides a comprehensive look at software testing as part of the project management process, emphasizing testing and quality goals early on in development. Building on the success of previous editions, the text explains testing in a Service Orientated Architecture (SOA) environment, the building blocks of a Testing Center of Excellence (COE), and how to test in an agile development. Fully updated, the sections on test effort estimation provide greater emphasis on testing metrics. The book also examines all aspects of functional testing and looks at the relation between changing business strategies and changes to applications in development. Includes New Chapters on Process, Application, and Organizational Metrics All IT organizations face software testing issues, but most are unprepared to manage them. Software Testing and Continuous Quality Improvement, Third Editionis enhanced with an up-to-date listing of free software tools and a question-and-answer checklist for choosing the best tools for your organization. It equips you with everything you need to effectively address testing issues in the most beneficial way for your business.},
author = {Lewis, William E. and Dobbs, David and Veerapillai, Gunasekaran},
file = {:Users/naubergois/Downloads/2005 Software.Testing.and.Continuous.Quality.Improvement.2nd.Ed{\_}bagus.pdf:pdf},
isbn = {1420080733},
pages = {688},
title = {{Software testing and continuous quality improvement}},
url = {http://books.google.com/books?id=fgaBDd0TfT8C{\&}pgis=1},
year = {2005}
}


@preamble{ "\newcommand{\noopsort}[1]{} "
	# "\newcommand{\printfirst}[2]{#1} "
	# "\newcommand{\singleletter}[1]{#1} "
	# "\newcommand{\switchargs}[2]{#2#1} " }

@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	

@article{Piel2010,
author = {Piel, {\'{E}}ric and Gonz{\'{a}}lez-Sanchez, Alberto and Gro{\ss}, Hans-Gerhard},
doi = {10.1007/978-3-642-16573-3},
file = {:Users/naubergois/Downloads/rbtcg{\_}preprint.pdf:pdf},
isbn = {978-3-642-16572-6},
journal = {Ictss},
number = {October},
pages = {79--94},
title = {{Testing Software and Systems}},
url = {http://dblp.uni-trier.de/db/conf/pts/ictss2010.html{\#}PielGG10},
volume = {6435},
year = {2010}
}


@phdthesis{Ganapathi2009,
abstract = {The complexity of modern computer systems makes performance modeling an invaluable resource for guiding crucial decisions such as workload management, conﬁguration management, and resource provisioning. With continually evolving systems, it is diﬃcult to obtain ground truth about system behavior. Moreover, system management policies must adapt to changes in workload and conﬁguration to continue making eﬃcient decisions. Thus, we require data-driven modeling techniques that auto-extract relationships between a system's input workload, its conﬁguration parameters, and consequent performance. This dissertation argues that statistical machine learning (SML) techniques are a powerful asset to system performance modeling. We present an SML-based methodology that extracts correlations between a workload's pre-execution characteristics or conﬁguration parameters, and post-execution performance observations. We leverage these correlations for performance prediction and optimization. We present three success stories that validate the usefulness of our methodology on storage and compute based parallel systems. In all three scenarios, we outperform state of the art alternatives. Our results strongly suggest the use of SML-based performance modeling to improve the quality of system management decisions.},
author = {Ganapathi, As},
booktitle = {UC Berkeley},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Ganapathi - 2009 - Predicting and optimizing system utilization and performance via statistical machine learning(20).pdf:pdf},
isbn = {8888888888888},
number = {UCB/EECS-2009-181},
pages = {97},
title = {{Predicting and optimizing system utilization and performance via statistical machine learning}},
url = {http://escholarship.org/uc/item/9b92g2pz.pdf http://www.mendeley.com/research/predicting-optimizing-system-utilization-performance-via-statistical-machine-learning/{\%}5Cnhttp://www.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-181.pdf},
year = {2009}
}

@article{Kiran2015,
abstract = {Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges {\&} experiences to identify an appropriate solution for conducting performance testing on such web application.},
author = {Kiran, Sandhya and Mohapatra, Akshyansu and Swamy, Rajashekara},
doi = {10.1109/ISTMET.2015.7359004},
file = {:Users/naubergois/Downloads/kiran2015.pdf:pdf},
isbn = {9781479917235},
journal = {2nd International Symposium on Technology Management and Emerging Technologies, ISTMET 2015 - Proceeding},
keywords = {Jmeter,Performance Testing,Single Sign-On,Unified Authentication Platform},
pages = {74--78},
title = {{Experiences in performance testing of web applications with Unified Authentication platform using Jmeter}},
year = {2015}
}


@article{White2010,
abstract = {Virtualization has rapidly become a go-to technology for increasing efficiency in the data center. With virtualization technologies providing tremendous flexibility, even disparate architectures may be deployed on a single machine without interference. Awareness of limitations and requirements of physical hosts to be used for virtualization is important. This paper reviews the present virtualization methods, virtual computing software, and provides a brief analysis of the performance issues inherent to each. In the end we present testing results of KVM-QEMU on two current Multi-Core CPU Architectures and System Configurations.},
archivePrefix = {arXiv},
arxivId = {1010.3233},
author = {White, Joshua and Pilbeam, Adam},
doi = {10.1.1.74.371},
eprint = {1010.3233},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/White, Pilbeam - 2010 - A Survey of Virtualization Technologies With Performance Testing.pdf:pdf},
keywords = {-virtual computing,isolation,security},
pages = {6},
title = {{A Survey of Virtualization Technologies With Performance Testing}},
url = {http://arxiv.org/abs/1010.3233},
year = {2010}
}

@inproceedings{Nivas2011,
author = {Nivas, Tuli and Csallner, Cristoph},
booktitle = {European Conference on Software Engineering / Foundations of Software Engineering},
file = {::},
title = {{Managing Performance Testing With Release Certification and Data Correlation}},
year = {2011}
}
    
@article{Geiger,
abstract = {The purpose of this case study is to evaluate how and which performance testing tools which can be used in continuous integration (CI) environments. By doing so, developers can see the effects of changes immediately and react against performance problems of their applications. This will help companies to eliminate performance issues which the media is reporting about more often every day. CI provides the reference platform for executing the performance tests and the performance testing tools provide metrics like response time and percentage of errors. These metrics can be combined through CI plugins. The results of this combination can be visualized in form of graphs and tables. Through this case study, we give a short market overview of current CI servers and performance testing tools. In respect of the requirements by adesso AG, we will only evaluate performance testing tools, which can be integrated into the Atlassian Bamboo or Jenkins CI. We evaluated six performance testing tools of which four were integratable into the CI servers. Based on the results of our evaluation we will give a recommendation.},
author = {Geiger, Chris},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Geiger - 2014 - Performance Testing in Continuous Integration Environments(6).pdf:pdf},
keywords = {continuous integration environment,performance testing},
title = {{Performance Testing in Continuous Integration Environments}},
url = {ftp://ftp.informatik.uni-stuttgart.de/pub/library/medoc.ustuttgart{\_}fi/FACH-0188/FACH-0188.pdf},
year = {2014}
}


@inproceedings{Alebrahim,
abstract = {Performance as one of the critical quality requirements for the success of a software system must be integrated into software development from the beginning to prevent performance problems. Analyzing and modeling performance demands knowledge of performance experts and analysts. In order to integrate performance analysis into software analysis and design methods, performance-specific properties known as domain knowledge have to be identified, analyzed, and documented properly. In this paper, we propose the performance analysis method PoPeRA to guide the requirements engineer in dealing with performance problems as early as possible in requirements analysis. Our structured method provides support for identifying potential performance problems using performance-specific domain knowledge attached to the requirement models. To deal with identified performance problems, we make use of performance analysis patterns to be applied to the requirement models in the requirements engineering phase. To show the application of our approach, we illustrate it with the case study CoCoME, a trading system to be deployed in supermarkets for handling sales.},
author = {Alebrahim, Azadeh and Heisel, Maritta},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2855321.2855357},
isbn = {978-1-4503-3847-9},
keywords = {Computational linguistics,Requirements engineering},
title = {{Applying performance patterns for requirements analysis}},
url = {http://dx.doi.org/10.1145/2855321.2855357},
volume = {08-12-July},
year = {2015}
}
    
    
@inproceedings{Gias2014,
abstract = {In case of large scale web-based systems, scripts for performance testing are updated iteratively. In each script, multiple URLs of the system are considered depending on intuitions that those URLs will expose the performance bugs. This paper proposes a Bayesian approach for including a URL to a test script based on its probability of being time intensive. As the testing goes on the scheme adaptively updates its knowledge regarding a URL. The comparison with existing methods shows that the proposed technique performs similar in guiding applications towards intensive tasks, which helps to expose performance bugs.},
author = {Gias, Alim Ul and Sakib, Kazi},
booktitle = {Proceedings of the 28th international conference on Software engineering},
doi = {10.1145/2591062.2591139},
file = {::},
isbn = {9781450327688},
keywords = {bayesian learning,performance testing,web-based sys-},
number = {undefined},
pages = {608--609},
title = {{An adaptive bayesian approach for URL selection to test performance of large scale web-based systems}},
url = {http://dx.doi.org/10.1145/2591062.2591139},
volume = {undefined},
year = {2014}
}

@article{Lutteroth2008,
author = {Lutteroth, Christof and Weber, Gerald},
doi = {10.1109/EDOC.2008.40},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Lutteroth, Weber - 2008 - Modeling a Realistic Workload for Performance Testing.pdf:pdf},
isbn = {978-0-7695-3373-5},
journal = {2008 12th International IEEE Enterprise Distributed Object Computing Conference},
month = {sep},
pages = {149--158},
publisher = {Ieee},
title = {{Modeling a Realistic Workload for Performance Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4634766},
year = {2008}
}


@article{Aguilera2003,
abstract = {Many interesting large-scale systems are distributed systems of multiple communicating components. Such systems can be very hard to debug, especially when they exhibit poor performance. The problem becomes much harder when systems are composed of "black-box" components: software from many different (perhaps competing) vendors, usually without source code available. Typical solutions-provider employees are not always skilled or experienced enough to debug these systems efficiently. Our goal is to design tools that enable modestly-skilled programmers (and experts, too) to isolate performance bottlenecks in distributed systems composed of black-box nodes.We approach this problem by obtaining message-level traces of system activity, as passively as possible and without any knowledge of node internals or message semantics. We have developed two very different algorithms for inferring the dominant causal paths through a distributed system from these traces. One uses timing information from RPC messages to infer inter-call causality; the other uses signal-processing techniques. Our algorithms can ascribe delay to specific nodes on specific causal paths. Unlike previous approaches to similar problems, our approach requires no modifications to applications, middleware, or messages.},
author = {Aguilera, Marcos K. and Mogul, Jeffrey C. and Wiener, Janet L. and Reynolds, Patrick and Muthitacharoen, Athicha},
doi = {10.1145/1165389.945454},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Aguilera et al. - 2003 - Performance debugging for distributed systems of black boxes.pdf:pdf},
isbn = {1581137575},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {black box systems,distributed systems,performance analysis,performance debugging},
pages = {74},
title = {{Performance debugging for distributed systems of black boxes}},
volume = {37},
year = {2003}
}


@article{Bazilinskyy2013,
author = {Bazilinskyy, Pavlo and Brunner, Markus},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Bazilinskyy, Brunner - 2013 - Performance Engineering and Testing.pdf:pdf},
journal = {Student Conference on Optimisation of Software},
keywords = {perfomance engineering,performance,software metrics,software optimisation,testing},
title = {{Performance engineering and testing: The challenges on mobile platforms}},
url = {http://www0.cs.ucl.ac.uk/staff/Yuanyuan.Zhang/StuConOS2013/stuconos2013{\_}submission{\_}3.pdf},
year = {2013}
}

    


@book{Oliner2011,
abstract = {This thesis is concerned with understanding the behavior of complex systems, particularly in the common case where instrumentation data is noisy or incomplete. We begin with an empirical study of logs from production systems, which characterizes the content of those logs and the challenges associated with analyzing them automatically, and present an algorithm for identifying surprising messages in such logs. The principal contribution is a method, called influence, that identifies relationships among components---even when the underlying mechanism of interaction is unknown---by looking for correlated surprise. Two components are said to share an influence if they tend to exhibit surprising behavior that is correlated in time. We represent the behavior of components as surprise (deviation from typical or expected behavior) over time and use signal-processing techniques to find correlations. The method makes few assumptions about the underlying systems or the data they generate, so it is applicable to a variety of unmodified production systems, including supercomputers, clusters, and autonomous vehicles. We then extend the idea of influence by presenting a query language and online implementation, which allow the method to scale to systems with hundreds of thousands of signals. In collaboration with system administrators, we applied these tools to real systems and discovered correlated problems, failure cascades, skewed clocks, and performance bugs. According to the administrators, it also generated information useful for diagnosing and fixing these issues.},
author = {Oliner, Adam Jamison},
language = {en},
mendeley-groups = {Zotero - Zotero Library},
pages = {153},
publisher = {Stanford University},
title = {{Using Influence to Understand Complex Systems}},
url = {http://books.google.com.br/books?id=bynaAuMtiSAC},
year = {2011}
}


@article{Fritzsche2007,
abstract = {The increase in the use of parallel distributed architectures in order to solve large-scale scientific problems has generated the need for performance prediction for both deterministic applications and non-deterministic applications. The development of a new prediction methodology to estimate the execution time of a hard data-dependent parallel application that solves the traveling salesman problem (TSP) is the primary target of this study. The prediction methodology is an analytical process designed to explore a group of cities in search of patterns and/or relationships between these cities, and then to validate performance prediction for new cities sets by applying the detected patterns. The TSP problem is of considerable importance not only from a theoretical point of view. There are important cases of practical problems that can be formulated as TSP problems and many other problems are generalizations of this problem. Therefore, there is a tremendous need for TSP algorithms and still more for knowing their performance values. Three different parallel algorithms of the Euclidean TSP are used to apply the proposed methodology. The experimental results are quite promising; the capacity of prediction is greater than 75{\%}.},
author = {Fritzsche, P.C. and Rexachs, D. and Luque, E.},
doi = {10.1109/IDAACS.2007.4488453},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Fritzsche, Rexachs, Luque - 2007 - TSP Performance Prediction Using Data Mining.pdf:pdf},
isbn = {978-1-4244-1347-8},
journal = {2007 4th IEEE Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications},
keywords = {Data mining,Performance prediction,Traveling salesman problem},
title = {{TSP Performance Prediction Using Data Mining}},
year = {2007}
}


@article{Deb2011,
abstract = {As the name suggests, multi-objective optimization involves optimizing a number of objectives si- multaneously. The problem becomes challenging when the objectives are of conflict to each other, that is, the optimal solution of an objective function is different from that of the other. In solving such problems, with or without the presence of constraints, these problems give rise to a set of trade-off opti- mal solutions, popularly known as Pareto-optimal solutions. Due to the multiplicity in solutions, these problems were proposed to be solved suitably using evolutionary algorithms which use a population ap- proach in its search procedure. Starting with parameterized procedures in early nineties, the so-called evolutionary multi-objective optimization (EMO) algorithms is now an established field of research and application with many dedicated texts and edited books, commercial softwares and numerous freely downloadable codes, a biannual conference series running successfully since 2001, special sessions and workshops held at all major evolutionary computing conferences, and full-time researchers from uni- versities and industries from all around the globe. In this chapter, we provide a brief introduction to its operating principles and outline the current research and application studies of EMO.},
author = {Deb, Kalyanmoy},
doi = {2011003},
file = {:Users/naubergois/k2011003.pdf:pdf},
isbn = {0-471-87339-X},
journal = {Multi-objective evolutionary optimisation for product design and manufacturing},
pages = {1--24},
title = {{Multi-objective optimization using evolutionary algorithms: an introduction}},
year = {2011}
}

@book{Dustin1999,
abstract = {"Automated Software Testing is a comprehensive, step-by-step guide to the most effective tools, techniques, and methods for automated testing. Using numerous case studies of successful industry implementations, this book presents everything you need to know to successfully incorporate automated testing into the development process."-BOOK JACKET. "In particular, this book focuses on the Automated Test Lifecycle Methodology (ATLM), a structured process for designing and executing testing that parallels the Rapid Application Development methodology commonly used today. Automated Software Testing is designed to lead you through each step of this structured program, from the initial decision to implement automated software testing through test planning, execution, and reporting. Included are test automation and test management guidance for: acquiring management support; test tool evaluation and selection; the automated testing introduction process; test effort and test team sizing; test team composition, recruiting, and management; test planning and preparation; test procedure development guidelines; automation reuse analysis and reuse library; and best practices for test automation."-BOOK JACKET.},
author = {Dustin, Elfriede and Rashka, Jeff and Paul, John},
booktitle = {Addison-Wesley Professional},
file = {:Users/naubergois/Downloads/Elfriede Dustin, Jeff Rashka, John Paul-Automated Software Testing{\_} Introduction, Management, and Performance-Addison-Wesley Professional (1999).pdf:pdf},
isbn = {0201432870},
pages = {575},
title = {{Automated Software Testing: Introduction, Management, and Performance}},
year = {1999}
}

@book{Perry2004,
author = {Perry, William E.},
booktitle = {Jhon Wiley {\&} Sons},
doi = {10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C},
file = {:Users/naubergois/Downloads/EMFST.pdf:pdf},
isbn = {9780764598371},
issn = {14337851},
title = {{Effective methods for software testing}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract$\backslash$nhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Effective+Methods+for+Software+Testing{\#}2$\backslash$nhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Effective+methods+for},
year = {2004}
}

@book{Kaczanowski2012,
abstract = {1782},
author = {Kaczanowski, Tomasz},
file = {:Users/naubergois/Downloads/Practical-Unit-Testing-with-JUnit-and-Mockito{\_}2013-04{\_}Tomek.Kaczanowsk.pdf:pdf},
isbn = {9788393489305},
pages = {426},
title = {{Practical unit testing with testNG and Mockito}},
year = {2012}
}

@article{Acharya2009,
abstract = {Online services such as search and live applications rely on large infrastructures in data centers, consisting of both stateless servers (e.g., web servers) and stateful servers (e.g., database servers). Acceptable performance of such infrastructures, and hence the availability of online services, rely on a very large number of parameters such as per-process resources and configurable system/application parameters. These parameters are available for collection as performance counters distributed across various machines, but services have had a hard time determining which performance counters to monitor and what thresholds to use for performance alarms in a production environment. In this paper, we present a novel framework called PerfAnalyzer, a storage-efficient and pro-active performance monitoring framework for correlating service health with performance counters. PerfAnalyzer automatically infers and builds health models for any service by running the standard suite of predeployment tests for the service and data mining the resulting performance counter data-set. A filtered set of performance counters and thresholds of alarms are produced by our framework. The health model inferred by our framework can then be used to detect performance degradation and collect detailed data for root-cause analysis in a production environment. We have applied PerfAnalyzer on five simple stress scenarios - CPU, memory, I/O, disk, and network, and two real system - Microsoft's SQL Server 2005 and IIS 7.0 Web Server, with promising results.},
author = {Acharya, Mithun and Kommineni, Vamshidhar},
doi = {10.1109/ASE.2009.95},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Acharya, Kommineni - 2009 - Mining health models for performance monitoring of services.pdf:pdf},
isbn = {9780769538914},
issn = {1527-1366},
journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
keywords = {Performance Monitoring,Performance evaluation},
mendeley-tags = {Performance Monitoring,Performance evaluation},
pages = {409--420},
title = {{Mining health models for performance monitoring of services}},
year = {2009}
}

@incollection{Avritzer2012a,
abstract = {Performance degradation and/or irregularity are often indicators of system instability. By applying the principle that average performance measures vary little under constant load in a stable system without periodic behavior, we can use performance metrics to anticipate instability within the system. We describe how to use that information to isolate the cause of observed instability and how to structure load tests to identify scenarios in which system instability is likely to occur. We discuss resilience assessment based on performance measurements. Specifically, we present our experience generating load tests and analyzing the performance testing results. We discuss how we have used these results for security, reliability and performance assessment. We discuss the conditions required for system stability and identify some of the causes for system instability, such as security attacks, quality problems, and queuing for system resources. We present a metric that can be used to assess some dimensions of system security, reliability and performance using data obtained from the execution of performance testing. In addition, we present the associated testing activities that are required to collect data for the required modeling and analysis activities, and to help track system security, reliability and performance. We illustrate the presented methodology with empirical results obtained by testing for security, reliability, and performance.},
author = {Avritzer, Alberto and Bondi, Andre B.},
booktitle = {Resilience Assessment and Evaluation of Computing Systems},
pages = {305--322},
title = {{Resilience Assessment Based on Performance Testing}},
year = {2012}
}

@inproceedings{Jiang2008b,
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags {\&}lt; 0.01{\%} of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.},
author = {Jiang, Zhen Ming ZM and Hassan, Ahmed E. AE and Hamann, Gilbert and Flora, Parminder},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Jiang et al. - 2008 - Automatic identification of load testing problems(2).pdf:pdf},
pages = {307--316},
title = {{Automatic identification of load testing problems}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=4658079{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4658079 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4658079},
year = {2008}
}

@inproceedings{Yu2010a,
abstract = {Testing-as-a-service (TaaS) is a new model to provide testing capabilities to end users. Users save the cost of complicated maintenance and upgrade effort, and service providers can upgrade their services without impact on the end-users. Due to uneven volumes of concurrent requests, it is important to address the elasticity of TaaS platform in a cloud environment. Scheduling and dispatching algorithms are developed to improve the utilization of computing resources. We develop a prototype of TaaS over cloud, and evaluate the scalability of the platform by increasing the test task load, analyze the distribution of computing time on test task scheduling and test task processing over the cloud, and examine the performance of proposed algorithms by comparing others.},
author = {Yu, Lian and Tsai, Wei Tek and Chen, Xiangji and Liu, Linqing and Zhao, Yan and Tang, Liangjie and Zhao, Wei},
booktitle = {Proceedings - 5th IEEE International Symposium on Service-Oriented System Engineering, SOSE 2010},
doi = {10.1109/SOSE.2010.36},
isbn = {9780769540818},
keywords = {Cloud,Cloud computing,Ontology,SaaS (Software as a Service),Scheduling and dispatching,TaaS (Testing as a Service),Testing as Service},
mendeley-tags = {Cloud,Testing as Service},
pages = {181--188},
title = {{Testing as a service over cloud}},
year = {2010}
}

@article{Yang1996,
author = {Yang, Cheer-Sun D and Pollock, Lori L},
doi = {10.1145/226295.226318},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
keywords = {Load Testing,Structural Test},
mendeley-tags = {Load Testing,Structural Test},
number = {3},
pages = {201--208},
title = {{Towards a Structural Load Testing Tool}},
url = {http://dl.acm.org/citation.cfm?id=226318 http://doi.acm.org/10.1145/226295.226318},
volume = {21},
year = {1996}
}

@article{El-far2001,
author = {El-far, Ibrahim K and Whittaker, James a},
doi = {10.1002/0471028959.sof207},
isbn = {9780471028956},
journal = {Encyclopedia of Software Engineering},
keywords = {finite state machines,grammars,markov chains,software behavior models,statecharts,test automation,test case generation,unified modeling language},
pages = {1--22},
title = {Model Based Software Testing},
year = {2001}
}


@article{Dumitrescu2004,
abstract = {We present DiPerF, a distributed performance-testing framework, aimed at simplifying and automating service performance evaluation. DiPerF coordinates a pool of machines that test a target service, collects and aggregates performance metrics, and generates performance statistics. The aggregate data collected provide information on service throughput, on service fairness' when serving multiple clients concurrently, and on the impact of network latency on service performance. Furthermore, using this data, it is possible to build predictive models that estimate a service performance given the service load. We have tested DiPerF on 100+machines on two testbeds, Grid3 and PlanetLab, and explored the performance of job submission services (pre-WS GRAM and WS GRAM) included with Globus Toolkit{\&}reg; 3.2.},
archivePrefix = {arXiv},
arxivId = {cs/0410012},
author = {Dumitrescu, Catalin and Raicu, Ioan and Ripeanu, Matei and Foster, Ian},
doi = {10.1109/GRID.2004.21},
eprint = {0410012},
isbn = {0769522564},
issn = {15505510},
journal = {Proceedings - IEEE/ACM International Workshop on Grid Computing},
pages = {289--296},
primaryClass = {cs},
title = {{DiPerF: An automated distributed Performance testing framework}},
year = {2004}
}

@article{Cai2007,
abstract = {Accurate web application performance testing relies on the use of loading tests based on a realistic client behaviour load model. Unfortunately developing such load models and associated test plans and scripts is tedious and error-prone with most existing web performance testing tools providing limited client load modelling capabilities. We describe a new approach and toolset that we have developed, MaramaMTE+, which improves the ability to model realistic web client load behaviour, automatically generates complex web application testing plans and scripts, and integrates load behaviour modelling with a generic performance engineering tool. MaramaMTE+ uses a stochastic form chart as its client loading model. A 3rd party web crawler application extracts structural information from a target web site, aggregating the collected data into a crawler database that is then used for form chart model generation. The performance engineer then augments this synthesized form probabilities. Realistic web loading tests for a 3rd party web load testing tool are then automatically generated from this resultant stochastic form chart client load model. We chart with client loading describe the development of our MaramaMTE+ environment, example usage of the tool, and compare and contrast the results obtained from our generated performance load tests against hand-built 3rd party tool load tests.},
author = {Cai, Yuhong and Grundy, John and Hosking, John},
doi = {10.1145/1321631.1321684},
isbn = {9781595938824},
journal = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering - ASE '07},
pages = {353},
title = {{Synthesizing client load models for performance engineering via web crawling}},
url = {http://portal.acm.org/citation.cfm?doid=1321631.1321684},
year = {2007}
}

@article{Bayan2008,
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags {\&}lt; 0.01{\%} of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.},
author = {Bayan, Mohamad and Cangussu, Jo{\~{a}}o W.},
doi = {10.1145/1363686.1363847},
file = {:Users/naubergois/Downloads/bayan2008.pdf:pdf},
isbn = {9781595937537},
issn = {1063-6773},
journal = {Proceedings of the 2008 ACM symposium on Applied computing - SAC '08},
pages = {661},
title = {{Automatic feedback, control-based, stress and load testing}},
url = {http://portal.acm.org/citation.cfm?doid=1363686.1363847},
year = {2008}
}

@article{Nguyen2011,
abstract = {Load testing is an important phase in the software development process.$\backslash$nIt is very time consuming but there is usually little time for it.$\backslash$nAs a solution to the tight testing schedule, software companies automate$\backslash$ntheir testing procedures. However, existing automation only reduces$\backslash$nthe time required to run load tests. The analysis of the test results$\backslash$nis still performed manually. A typical load test outputs thousands$\backslash$nof performance counters. Analyzing these counters manually requires$\backslash$ntime and tacit knowledge of the system-under-test from the performance$\backslash$nengineers. The goal of this study is to derive an approach to automatically$\backslash$nverify load tests results. We propose an approach based on a statistical$\backslash$nquality control technique called control charts. Our approach can$\backslash$na) automatically determine if a test run passes or fails and b) identify$\backslash$nthe subsystem where performance problem originated. We conduct two$\backslash$ncase studies on a large commercial telecommunication software and$\backslash$nan open-source software system to evaluate our approach. Our results$\backslash$nwarrant further development of control chart based techniques in$\backslash$nperformance verification. {\&}copy; 2011 IEEE.},
author = {Nguyen, Thanh H D and Adams, Bram and Jiang, Zhen Ming and Hassan, Ahmed E. and Nasser, Mohamed and Flora, Parminder},
doi = {10.1109/APSEC.2011.59},
isbn = {9780769546094},
issn = {15301362},
journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
keywords = {Load Testing,Mining software repository,Performance Testing},
pages = {282--289},
title = {{Automated verification of load tests using control charts}},
year = {2011}
}


@article{Shoaib2011,
abstract = {In this paper, a Layered Queueing Network (LQN) performance model is used for studying an Apache-PHP web application with PostgreSQL backend-database. Performance evaluation is done by obtaining load test measurements and by solving the LQN model. Model validation is performed by comparing the model results with the load test results. With average error of 3.77{\%} for throughput and 12.15{\%} for response times the model is shown to capture the web application's performance. Furthermore, performance analysis is done to determine the system configuration which would ease the identified bottleneck resource. ?? 2011 Elsevier B.V.},
author = {Shoaib, Yasir and Das, Olivia},
doi = {10.1016/j.entcs.2011.09.009},
file = {::},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Layered Queueing Networks,Load Testing,PHP,Performance measurement,Performance modeling and validation,Software Performance Engineering},
pages = {123--142},
publisher = {Elsevier B.V.},
title = {{Web Application Performance Modeling Using Layered Queueing Networks}},
url = {http://dx.doi.org/10.1016/j.entcs.2011.09.009},
volume = {275},
year = {2011}
}


@article{Zhang2011,
abstract = {Load tests aim to validate whether system performance is acceptable under peak conditions. Existing test generation techniques induce load by increasing the size or rate of the input. Ignoring the particular input values, however, may lead to test suites that grossly mischaracterize a system's performance. To address this limitation we introduce a mixed symbolic execution based approach that is unique in how it 1) favors program paths associated with a performance measure of interest, 2) operates in an iterative-deepening beam-search fashion to discard paths that are unlikely to lead to high-load tests, and 3) generates a test suite of a given size and level of diversity. An assessment of the approach shows it generates test suites that induce program response times and memory consumption several times worse than the compared alternatives, it scales to large and complex inputs, and it exposes a diversity of resource consuming program behavior.},
author = {Zhang, Pingyu and Elbaum, Sebastian and Dwyer, Matthew B},
doi = {10.1109/ASE.2011.6100093},
isbn = {978-1-4577-1638-6},
issn = {1938-4300},
journal = {Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
keywords = {-load testing,symbolic execution},
pages = {43--52},
title = {{Automatic generation of load tests}},
url = {http://dl.acm.org/citation.cfm?id=2190151 http://dx.doi.org/10.1109/ASE.2011.6100093},
year = {2011}
}

@article{Yan2012,
author = {Yan, Minzhi and Sun, Hailong and Wang, Xu and Liu, Xudong},
doi = {10.1109/CLUSTER.2012.20},
isbn = {978-0-7695-4807-4},
journal = {2012 IEEE International Conference on Cluster Computing},
keywords = {-web services,Load Testing,WebService,cloud computing,load testing,testing},
mendeley-tags = {Load Testing,WebService},
number = {2},
pages = {576--579},
title = {{Building a TaaS Platform for Web Service Load Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6337826},
year = {2012}
}


@article{Vasar2012,
abstract = {By allowing resources to be acquired on-demand and in variable amounts, cloud computing provides an appealing environment for deploying pilot projects and for performance testing of Web applications and services. However, setting up cloud environments for performance testing still requires a significant amount of manual effort. To aid performance engineers in this task, we developed a framework that integrates several common benchmarking and monitoring tools. The framework helps performance engineers to test applications under various configurations and loads. Furthermore, the framework supports dynamic server allocation based on incoming load using a response-time-aware heuristics. We validated the framework by deploying and stress-testing the MediaWiki application. An experimental evaluation was conducted aimed at comparing the response-time-aware heuristics against Amazon Auto-Scale. Copyright 2012 ACM.},
author = {Vasar, Martti and Srirama, Satish Narayana and Dumas, Marlon},
doi = {10.1145/2361999.2362008},
isbn = {9781450315685},
journal = {Proceedings of the WICSA/ECSA 2012 Companion Volume on - WICSA/ECSA '12},
keywords = {Cloud computing,Software architecture,World Wide W,World Wide Web},
pages = {53},
title = {{Framework for monitoring and testing web application scalability on the cloud}},
url = {http://dx.doi.org/10.1145/2361999.2362008$\backslash$nhttp://dl.acm.org/citation.cfm?doid=2361999.2362008},
year = {2012}
}

@article{Malik2013a,
author = {Malik, Haroon and Hemmati, Hadi and Hassan, Ahmed E},
isbn = {9781467330749},
pages = {1012--1021},
title = {{Automatic Detection of Performance Deviations in the Load Testing of Large Scale Systems}},
year = {2013}
}

@article{Barna2013,
author = {Barna, Cornel and Shtern, Mark and Smit, Michael and Tzerpos, Vassilios and Litoiu, Marin},
doi = {10.1145/0000000.0000000},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barna et al. - 2013 - Mitigating DoS Attacks using Performance Model-driven Adaptive Algorithms.pdf:pdf},
number = {February},
title = {{Mitigating DoS Attacks using Performance Model-driven Adaptive Algorithms}},
volume = {X},
year = {2013}
}

@article{Jiang2015,
author = {Jiang, Zhen Ming and Hassan, Ahmed},
doi = {10.1109/TSE.2015.2445340},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {1--1},
title = {{A Survey on Load Testing of Large-Scale Software Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7123673},
volume = {5589},
year = {2015}
}

@phdthesis{Shousha2003,
author = {Shousha, Marwa},
file = {:Users/naubergois/Downloads/shousha-performancestresstestingofrealtimesystems.pdf:pdf},
school = {Carleton University},
title = {{Performance Stress Testing of Real-Time Systems Using Genetic-Algorithms}},
year = {2003}
}


@article{Avritzer1995,
abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
author = {Avritzer, A. and Weyuker, E.J.},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Weyuker - 1995 - The automatic generation of load test suites and the assessment of the resulting software.html:html},
issn = {0098-5589},
journal = {Software Engineering, IEEE {\ldots}},
keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
mendeley-tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
number = {9},
pages = {705--716},
title = {{The automatic generation of load test suites and the assessment of the resulting software}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=464549{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549},
volume = {21},
year = {1995}
}

@incollection{Mayo2013,
abstract = {A novel framework for predicting regression test failures is proposed. The basic principle embodied in the framework is to use performance analysis tools to capture the runtime behaviour of a program as it executes each test in a regression suite. The performance information is then used to build a dynamically predictive model of test outcomes. Our framework is evaluated using a genetic algorithm for dynamic metric selection in combination with state-of-the-art machine learning classifiers. We show that if a program is modified and some tests subsequently fail, then it is possible to predict with considerable accuracy which of the remaining tests will also fail which can be used to help prioritise tests in time constrained testing environments.},
annote = {From Duplicate 2 ( 

Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics

- Mayo, Michael; Spacey, Simon )



Mayo presents a novel framework for predicting regression test failures.The framework use a performance analysis tools to capture runtime behaviour of a program},
author = {Mayo, Michael and Spacey, Simon},
editor = {Ruhe, G{\"{u}}nther and Zhang, Yuanyuan},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Mayo, Spacey - 2013 - Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics.pdf:pdf},
isbn = {978-3-642-39741-7, 978-3-642-39742-4},
keywords = {Algorithm Analysis and Problem Complexity,Computation by Abstract Devices,Pattern Recognition,Programming Languages- Compilers- Interpreters,Programming Techniques,Software Engineering,genetic metric selection,machine learning,program analysis,regression testing,test failure prediction},
mendeley-tags = {Algorithm Analysis and Problem Complexity,Computation by Abstract Devices,Pattern Recognition,Programming Languages- Compilers- Interpreters,Programming Techniques,Software Engineering,genetic metric selection,machine learning,program analysis,regression testing,test failure prediction},
month = {jan},
pages = {158--171},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-39742-4{\_}13},
year = {2013}
}

@article{Barber2004,
author = {Barber, S},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barber - 2004 - Creating effective load models for performance testing with incomplete empirical data.pdf:pdf},
journal = {{\ldots} Energy Conference, 2004. INTELEC 2004. 26th {\ldots}},
pages = {1--13},
title = {{Creating effective load models for performance testing with incomplete empirical data}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1410995},
year = {2004}
}

@article{Ag2006,
author = {Ag, Daimler Chrysler and Berlin, D- and Wappler, Stefan},
file = {:Users/naubergois/Downloads/tlili2006.pdf:pdf},
isbn = {1595931864},
journal = {Proceedings of the 8th annual conference on Genetic and evolutionary computation},
keywords = {Execution Time Testing,Software Tools,Software engineering,Stress testing},
pages = {1917--1924},
title = {{Improving Evolutionary Real-Time Testing Categories and Subject Descriptors}},
year = {2006}
}

@article{Afzal2008,
abstract = {Automated software test generation has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional), grey-box (combination of structural and functional) and non-functional testing. In this paper, we undertake a systematic mapping study to present a broad review of primary studies on the application of search-based optimization techniques to non-functional testing. The motivation is to identify the evidence available on the topic and to identify gaps in the application of search-based optimization techniques to different types of non-functional testing. The study is based on a comprehensive set of 35 papers obtained after using a multi-stage selection criteria and are published in workshops, conferences and journals in the time span 1996-2007. We conclude that the search-based software testing community needs to do more and broader studies on non-functional search-based software testing (NFSBST) and the results from our systematic map can help direct such efforts.},
author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
isbn = {1891706225},
journal = {Proceedings of the Twentieth International Conference on Software Engineering {\&} Knowledge Engineering (SEKE'2008)},
keywords = {Search-Based Test,Stress testing,Systematic Review},
mendeley-tags = {Search-Based Test,Stress testing,Systematic Review},
number = {October 2015},
pages = {488--493},
title = {{A systematic mapping study on non-functional search-based software testing}},
url = {http://richard.torkar.googlepages.com/a{\_}systematic{\_}mapping{\_}study{\_}on{\_}non-fu.pdf},
year = {2008}
}


@article{Jiang2009a,
abstract = {The goal of a load test is to uncover functional and per- formance problems of a system under load. Performance problems refer to the situations where a system suffers from unexpectedly high response time or low throughput. It is difficult to detect performance problems in a load test due to the absence of formally-defined performance objectives and the large amount of data that must be examined. In this paper, we present an approach which automati- cally analyzes the execution logs of a load test for perfor- mance problems. We first derive the systems performance baseline from previous runs. Then we perform an in-depth performance comparison against the derived performance baseline. Case studies show that our approach produces few false alarms (with a precision of 77{\%}) and scales well to large industrial systems.},
author = {Jiang, Zhen Ming and Hassan, Ahmed E and Hamann, Gilbert and Flora, Parminder},
doi = {10.1109/ICSM.2009.5306331},
isbn = {9781424448975},
issn = {1063-6773},
journal = {2009 IEEE International Conference on Software Maintenance},
pages = {125--134},
title = {{Automated performance analysis of load tests}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5306331},
year = {2009}
}




@article{Avritzer1995,
abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
author = {Avritzer, A. and Weyuker, E.J.},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Weyuker - 1995 - The automatic generation of load test suites and the assessment of the resulting software.html:html},
issn = {0098-5589},
journal = {Software Engineering, IEEE {\ldots}},
keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
mendeley-tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
number = {9},
pages = {705--716},
title = {{The automatic generation of load test suites and the assessment of the resulting software}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=464549{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549},
volume = {21},
year = {1995}
}


@book{Havelund2006,
author = {Havelund, Klaus and N{\'{u}}{\~{n}}ez, Manuel and Roşu, Grigore and Wolff, Burkhart},
booktitle = {Serious Games Development and Applications},
file = {:Users/naubergois/Downloads/Deterministic{\_}dynamic{\_}monitors{\_}for{\_}linea.pdf:pdf},
isbn = {9783642238338},
pages = {155},
title = {{Formal Approaches to Software Testing and Runtime Verification}},
url = {http://www.ulb.tu-darmstadt.de/tocs/79304567.pdf},
year = {2006}
}

@article{Meinke2010,
abstract = {We present an application of learning-based testing to the problem of automated test case generation (ATCG) for numerical software. Our approach uses n-dimensional polynomial models as an algorithmically learned abstraction of the SUT which supports n-wise testing. Test cases are iteratively generated by applying a satisfiability algorithm to first-order program specifications over real closed fields and iteratively refined piecewise polynomial models. We benchmark the performance of our iterative ATCG algorithm against iterative random testing, and empirically analyse its performance in finding injected errors in numerical codes. Our results show that for software with small errors, or long mean time to failure, learning-based testing is increasingly more efficient than iterative random testing. {\textcopyright} 2010 IFIP International Federation for Information Processing.},
author = {Meinke, Karl and Niu, Fei},
doi = {10.1007/978-3-642-16573-3_16},
file = {:Users/naubergois/Downloads/64350220.pdf:pdf},
isbn = {3642165729},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {221--235},
title = {{A learning-based approach to unit testing of numerical software}},
volume = {6435 LNCS},
year = {2010}
}


@article{Kamali2007,
abstract = {In traditional optimal control and design problems, the control gains and design parameters are usually derived to minimize a cost function reflecting the system performance and control effort. One major challenge of such approaches is the selection of weighting matrices in the cost function, which are usually determined via trial-and-error and human intuition. While various techniques have been proposed to automate the weight selection process, they either can not address complex design problems or suffer from slow convergence rate and high computational costs. We propose a layered approach based on Q-learning, a reinforcement learning technique, on top of genetic algorithms (GA) to determine the best weightings for optimal control and design problems. The layered approach allows for reuse of knowledge. Knowledge obtained via Q-learning in a design problem can be used to speed up the convergence rate of a similar design problem. Moreover, the layered approach allows for solving optimizations that cannot be solved by GA alone. To test the proposed method, we perform numerical experiments on a sample active-passive hybrid vibration control problem, namely adaptive structures with active-passive hybrid piezoelectric networks. These numerical experiments show that the proposed Q-learning scheme is a promising approach for automation of weight selection for complex design problems. (27 References).},
author = {Kamali, Kaivan and Jiang, L. J. and Yen, John and Wang, K. W.},
doi = {10.1115/1.2739502},
file = {:Users/naubergois/Downloads/kamali2007.pdf:pdf},
isbn = {0-7918-4739-X},
issn = {15309827},
journal = {Journal of Computing and Information Science in Engineering},
keywords = {genetic algorithms,optimal control,q-learning},
number = {December 2007},
pages = {302},
title = {{Using Q-Learning and Genetic Algorithms to Improve the Efficiency of Weight Adjustments for Optimal Control and Design Problems}},
volume = {7},
year = {2007}
}

	
@inproceedings{sato2015automatic,
  title={Automatic Generation of Specification-Based Test Cases by Applying Genetic Algorithms in Reinforcement Learning},
  author={Sato, Yuji and Sugihara, Taku},
  booktitle={International Workshop on Structured Object-Oriented Formal Language and Method},
  pages={59--71},
  year={2015},
  organization={Springer}
}	
	
@article{Boyan2000,
abstract = {This paper describes algorithms that learn to improve search performance on large-scale optimization tasks. The main algorithm, STAGE, works by learning an evaluation function that predicts the outcome of a local search algorithm, such as hillclimbing or Walksat, from features of states visited during search. The learned evaluation function is then used to bias future search trajectories toward better optima on the same problem. Another algorithm, X-STAGE, transfers previously learned evaluation functions to new, similar optimization problems. Empirical results are provided on seven large-scale optimization domains: bin-packing, channel routing, Bayesian network structure-finding, radiotherapy treatment planning, cartogram design, Boolean satisfiability, and Boggle board setup.},
author = {Boyan, Justin A. and Moore, Andrew W.},
file = {:Users/naubergois/Downloads/boyan00a.pdf:pdf},
issn = {1533-7928},
journal = {Journal of Machine Learning Research},
pages = {77--112},
title = {{Learning Evaluation Functions to Improve Local Search}},
url = {http://citeseer.nj.nec.com/boyan00learning.html},
volume = {1},
year = {2000}
}


@book{talbi2009metaheuristics,
  title={Metaheuristics: from design to implementation},
  author={Talbi, El-Ghazali},
  volume={74},
  year={2009},
  publisher={John Wiley \& Sons}
}

@book{Battiti2009,
abstract = {This book is about learning for problem solving. [...] Human problem solving is strongly connected to learning. Learning takes places when the problem at hand is not well known at the beginning, and its structure becomes more and more clear when more experience with the problem is available. [...] What is critical for men is critical also in many human-developed problem solving strategies. It is not surprising that many methods for solving problems in Artificial Intelligence, Operations Research and related areas, follow the search scheme [...] We aim at giving the main principles and at developing some fresh intuition for the approaches. We like mathematics but we also think that hiding the underlying motivations and sources of inspiration takes some color out of the scientific work [...]. On the other hand, pictures and hand-waving can be very dangerous in isolation and we try to avoid these pitfalls by giving also the basic equations when possible, or by at least directing the reader to the bibliographic references for deepening a topic. The point of view of the book is to look at the zoo of different optimization beasts to underline opportunities for learning and self-tuning strategies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Battiti, Roberto and Brunato, Mauro and Mascia, Franco},
booktitle = {Operations Research/ Computer Science Interfaces Series},
doi = {10.1007/978-0-387-09624-7},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/book{\_}reactive{\_}search{\_}and{\_}iIntelligent{\_} optimization.pdf:pdf},
isbn = {9780387096230},
issn = {1387666X},
pmid = {25246403},
title = {{Reactive search and intelligent optimization}},
volume = {45},
year = {2009}
}


@article{Smith2002,
author = {Smith, C.U. and Williams, L.G.},
file = {:Users/naubergois/Downloads/24fe255149e4fc0d7e1e8924c243a85dd676.pdf:pdf},
journal = {Cmg-Conference-},
pages = {797--806},
title = {{Software Performance AntiPatterns; Common Performance Problems and their Solutions}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.6968{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {2002}
}

@article{Bennett2006,
abstract = {The fields of machine learning and mathematical programming are increasingly intertwined. Optimization problems lie at the heart of most machine learning approaches. The Special Topic on Machine Learning and Large Scale Optimization examines this interplay. Machine learning researchers have embraced the advances in mathematical programming allowing new types of models to be pursued. The special topic includes models using quadratic, linear, second-order cone, semi-definite, and semi-infinite programs. We observe that the qualities of good optimization algorithms from the machine learning and optimization perspectives can be quite different. Mathematical programming puts a premium on accuracy, speed, and robustness. Since generalization is the bottom line in machine learning and training is normally done off-line, accuracy and small speed improvements are of little concern in machine learning. Machine learning prefers simpler algorithms that work in reasonable computational time for specific classes of problems. Reducing machine learning problems to well-explored mathematical programming classes with robust general purpose optimization codes allows machine learning researchers to rapidly develop new techniques. In turn, machine learning presents new challenges to mathematical programming. The special issue include papers from two primary themes: novel machine learning models and novel optimization approaches for existing models. Many papers blend both themes, making small changes in the underlying core mathematical program that enable the develop of effective new algorithms.},
archivePrefix = {arXiv},
arxivId = {math/0601771},
author = {Bennett, Kristin P},
doi = {10.1051/ps},
eprint = {0601771},
file = {:Users/naubergois/Downloads/MLOPT-intro06a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {convex optimization,machine learning,mathematical programming},
number = {November},
pages = {1265--1281},
primaryClass = {math},
title = {{The Interplay of Optimization and Machine Learning Research}},
url = {http://portal.acm.org/citation.cfm?id=1248593},
volume = {7},
year = {2006}
}


@article{Gambardella1995,
author = {Gambardella, Luca M and Dorigo, Marco},
file = {:Users/naubergois/Downloads/gambardella95-icml (1).pdf:pdf},
pages = {252--260},
title = {{Ant-Q : A Reinforcement Learning approach to the traveling salesman problem}},
volume = {5625},
year = {1995}
}

@article{Matsuura2015,
author = {Matsuura, Jackson and Bianchi, Reinaldo A C},
file = {:Users/naubergois/Downloads/sbia2815.pdf:pdf},
number = {March},
title = {{Heuristically Accelerated Q – Learning : a new approach to speed up Reinforcement Learning}},
year = {2015}
}




@article{Wang2013,
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
doi = {10.1080/02533839.2012.726028},
file = {:Users/naubergois/Downloads/wang2013.pdf:pdf},
issn = {0253-3839},
journal = {Journal of the Chinese Institute of Engineers},
keywords = {Model Based Test,Stress testing,load testing,markov chains,usage model},
number = {1},
pages = {74--86},
title = {{Model-based load testing of web applications}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02533839.2012.726028},
volume = {36},
year = {2013}
}


@article{Baars2011,
abstract = {The Future Internet will be a complex interconnection$\backslash$nof services, applications, content and media, on which$\backslash$nour society will become increasingly dependent. Time to$\backslash$nmarket is crucial in Internet applications and hence$\backslash$nrelease cycles grow ever shorter. This, coupled with$\backslash$nthe highly dynamic nature of the Future Internet will$\backslash$nplace new demands on software testing. Search-Based$\backslash$nTesting is ideally placed to address these emerging$\backslash$nchallenges. Its techniques are highly flexible and$\backslash$nrobust to only partially observable systems. This paper$\backslash$npresents an overview of Search-Based Testing and$\backslash$ndiscusses some of the open challenges remaining to make$\backslash$nsearch-based techniques applicable to the Future$\backslash$nInternet.},
author = {Baars, Arthur I and Lakhotia, Kiran and Vos, Tanja E J and Wegener, Joachim},
file = {:Users/naubergois/Downloads/fedcsis11.pdf:pdf},
isbn = {9788360810392},
journal = {Federated Conference on Computer Science and Information Systems (FedCSIS 2011)},
keywords = {Evolutionary computation,Internet,Optimisation,SBSE,Search Based Test,Search problems,Software,Testing,evolutionary testing,future Internet testing,genetic algorithms,genetic programming,search-based testing,software testing,time to market},
pages = {917--923},
title = {{Search-based testing, the underlying engine of Future Internet testing}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=6078178},
year = {2011}
}


@article{Brown2003,
author = {Brown, Matthew a and Tapolcsanyi, Eli},
file = {:Users/naubergois/Downloads/Brown-mock-objects.pdf:pdf},
journal = {Matrix},
pages = {1--17},
title = {{Mock Object Patterns}},
year = {2003}
}


@article{Hunt2002,
author = {Hunt, Editors Andy and Thomas, Dave and Pragmatic, I The and Hunt, Andy and Mackinnon, Tim and Freeman, Steve},
doi = {10.1109/MS.2004.1259177},
file = {:Users/naubergois/Downloads/may{\_}02{\_}mock.pdf:pdf},
issn = {0740-7459},
journal = {Ieee Software},
number = {June},
pages = {22--24},
title = {{Software Construction}},
year = {2002}
}

@article{Bertolino2008,
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
year = {2008}
}

@book{GendreauMichelandPotvin2010,
author = {{Gendreau, Michel and Potvin}, Jean-Yves},
doi = {10.1007/978-1-4614-1900-6},
file = {:Users/naubergois/Downloads/Artificial{\_}Immune{\_}Systems.pdf:pdf},
isbn = {9781441979605},
title = {{Handbook of Metaheuristics}},
volume = {157},
year = {2010}
}




@article{Mackinnon2001,
abstract = {Unit testing is a fundamental practice in Extreme Programming, but most non-trivial code is difficult to test in isolation. It is hard to avoid writing test suites that are complex, incomplete, and difficult to maintain and interpret. Using Mock Objects for unit testing improves both domain code and test suites. They allow unit tests to be written for everything, simplify test structure, and avoid polluting domain code with testing infrastructure.},
author = {Mackinnon, Tim and Freeman, Steve and Craig, Philip},
file = {:Users/naubergois/Downloads/mockobjects.pdf:pdf},
isbn = {0201710404},
journal = {Extreme programming examined},
keywords = {extreme programming,mock objects,stubs,unit testing},
pages = {287--301},
title = {{Endo-Testing : Unit Testing with Mock Objects}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3214{\&}rep=rep1{\&}type=pdf},
year = {2001}
}



@article{Wert2013a,
abstract = {Performance problems pose a significant risk to software vendors. If left undetected, they can lead to lost customers, increased operational costs, and damaged reputation. Despite all efforts, software engineers cannot fully prevent performance problems being introduced into an application. Detecting and resolving such problems as early as possible with minimal effort is still an open challenge in software performance engineering. In this paper, we present a novel approach for Performance Problem Diagnostics (PPD) that systematically searches for well-known performance problems (also called performance antipatterns) within an application. PPD automatically isolates the problem's root cause, hence facilitating problem solving. We applied PPD to a well established transactional web e-Commerce benchmark (TPC-W) in two deployment scenarios. PPD automatically identified four performance problems in the benchmark implementation and its deployment environment. By fixing the problems, we increased the maximum throughput of the benchmark from 1800 requests per second to more than 3500.},
author = {Wert, Alexander and Happe, Jens and Happe, Lucia},
doi = {10.1109/ICSE.2013.6606601},
file = {:Users/naubergois/Downloads/ICSE-2013-PerformanceProblemDiagnostics.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {measurement,performance,problem detection},
number = {May},
pages = {552--561},
title = {{Supporting swift reaction: Automatically uncovering performance problems by systematic experiments}},
year = {2013}
}

@article{Smith2003,
abstract = {Performance antipatterns document common software performance problems as well as their solutions. These problems are often introduced during the architectural or design phases of software development, but not detected until later in testing or deployment. Solutions usually require software changes as opposed to system tuning changes. This paper presents three new performance antipatterns and gives examples to illustrate them. These antipatterns will help developers and performance engineers avoid common perfor- mance problems. 1.0},
author = {Smith, Connie U and Williams, Lloyd G},
file = {:Users/naubergois/Downloads/moreanti.pdf:pdf},
journal = {Computer Measurement Group Conference},
pages = {717--725},
title = {{More New Software Performance AntiPatterns: EvenMore Ways to Shoot Yourself in the Foot}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.4517{\&}rep=rep1{\&}type=pdf},
year = {2003}
}



@article{Glover1986,
abstract = {Tabu Search is a meta-heuristic that guides a local heuristic search procedure to explore the solution space beyond local optimality. One of the main components of Tabu Search of Tabu Search is its use of adaptive memory, which creates a more flexible search behavior.},
author = {Glover, Fred and Mart{\'{i}}, Rafael},
file = {:Users/naubergois/Downloads/ts2.pdf:pdf},
journal = {Tabu Search},
pages = {1--16},
title = {{Tabu Search}},
year = {1986}
}

@article{Gay,
author = {Gay, Gregory},
file = {:Users/naubergois/Downloads/16mockito.pdf:pdf},
keywords = {automated unit test generation,real faults,search-based testing},
pages = {1--6},
title = {{Challenges in Using Search-Based Test Generation to Identify Real Faults in Mockito}}
}


@article{Wert2014,
abstract = {Performance problems such as high response times in software applications have a significant effect on the customer's satisfaction. In enterprise applications, performance problems are frequently manifested in inefficient or unnecessary communication patterns between software components originating from poor architectural design or implementation. Due to high manual effort, thorough performance analysis is often neglected, in practice. In order to overcome this problem, automated engineering approaches are required for the detection of performance problems. In this paper, we introduce several heuristics for measurement-based detection of well-known performance anti-patterns in inter-component communications. The detection heuristics comprise load and instrumentation descriptions for performance tests as well as corresponding detection rules. We integrate these heuristics with Dynamic Spotter, a framework for automatic detection of performance problems. We evaluate our heuristics on four evaluation scenarios based on an e-commerce benchmark (TPC-W) where the heuristics detect the expected communication performance anti-patterns and pinpoint their root causes. Copyright {\&}copy; 2014 ACM 978-1-4503-2577-6/14/06 ...{\$}15.00.},
author = {Wert, Alexander and Oehler, Marius and Heger, Christoph and Farahbod, Roozbeh},
doi = {10.1145/2602576.2602579},
file = {:Users/naubergois/Downloads/2014-qosa-messaging.pdf:pdf},
isbn = {9781450325776},
journal = {QoSA 2014 - Proceedings of the 10th International ACM SIGSOFT Conference on Quality of Software Architectures (Part of CompArch 2014)},
keywords = {Application programs;Customer satisfaction;},
pages = {3--12},
title = {{Automatic detection of performance anti-patterns in inter-component communications}},
url = {http://dx.doi.org/10.1145/2602576.2602579},
year = {2014}
}

@article{Arcelli2012,
abstract = {Identifying and removing the causes of poor performance in software systems are complex problems due to a variety of factors to take into account. Nowadays these problems are usually tackled after the software deployment only with human-based means, which frequently boil down to developer skills and previous experiences. Performance antipatterns can be used to cope with these problems since they capture typical design patterns that are known leading to performance problems, as well as refactoring actions that can be taken to remove them. The goal of this paper is to introduce an approach that allows the refactoring of architectural models, based on antipatterns, that aims at providing performance improvement. To this end, we use a Role-Based Modeling Language to represent: (i) antipattern problems as Source Role Models (SRMs), and (ii) antipattern solutions as Target Role Models (TRMs). Hence, SRM-TRM pairs represent new instruments in the hands of developers to achieve architectural model refactorings aimed at removing sources of performance problems. Model refactoring for antipattern removal can be in fact obtained by replacing an SRM with the corresponding TRM. This approach has been applied to a case study in the e-commerce domain, whose experimental results demonstrate its effectiveness. Copyright {\textcopyright} 2012 ACM.},
author = {Arcelli, Davide and Cortellessa, Vittorio and Trubiani, Catia},
doi = {10.1145/2304696.2304704},
file = {:Users/naubergois/Downloads/antipatterns-QoSA-2012.pdf:pdf},
isbn = {9781450313469},
journal = {Proceedings of the 8th international ACM SIGSOFT conference on Quality of Software Architectures (QoSA '12)},
keywords = {model refactoring,performance an-,software performance},
pages = {33--42},
title = {{Antipattern-Based Model Refactoring for Software Performance Improvement}},
url = {http://doi.acm.org/10.1145/2304696.2304704},
year = {2012}
}

@article{Cortellessa2007,
author = {Cortellessa, Vittorio and Frittella, Laurento},
file = {:Users/naubergois/Downloads/10.1007@978-3-540-75211-013.pdf:pdf},
keywords = {architectural,feedback,layered queueing networks,performance indices,software performance},
pages = {171--185},
title = {{A Framework for Automated Generation of Architectural Feedback from Software Performance Analysis}},
year = {2007}
}

@article{Smith2000,
author = {Smith, Connie U. and Williams, Lloyd G.},
doi = {10.1145/350391.350420},
file = {:Users/naubergois/Downloads/antipat.pdf:pdf},
isbn = {158113195X},
journal = {Proceedings of the second international workshop on Software and performance  - WOSP '00},
pages = {127--136},
title = {{Software performance antipatterns}},
url = {http://portal.acm.org/citation.cfm?doid=350391.350420},
year = {2000}
}



@book{Halili2008,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Halili, Emily H.},
booktitle = {PACKT Publishing},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {jmeter},
pmid = {25246403},
title = {{Apache JMeter: A practical beginner's guide to automated testing and performance measurement for your websites.}},
year = {2008}
}

@article{Aleti2016,
author = {Aleti, Aldeida and Moser, I. and Grunske, Lars},
doi = {10.1007/s10515-016-0197-7},
isbn = {1051501601},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Fitness landscape characterisation,Genetic algorithms,Test data generation},
pages = {1--19},
title = {{Analysing the fitness landscape of search-based software testing problems}},
year = {2016}
}


@book{Jaziri2008,
author = {Jaziri, Wassim},
isbn = {9783902613349},
pages = {294},
title = {{Local Search Techniques: Focus on Tabu Search}},
year = {2008}
}


@article{Blum2003,
abstract = {The emergence of metaheuristics for solving difficult combinatorial optimization problems is one of the most notable achievements of the last two decades in operations research. This paper provides an account of the most recent developments in the field and identifies some common issues and trends. Examples of applications are also reported for vehicle routing and scheduling problems.},
author = {Blum, C. and Roli, A.},
doi = {10.1007/s10479-005-3971-7},
isbn = {0254-5330},
issn = {02545330},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Metaheuristics,Unifying framework,Vehicle routing},
number = {3},
pages = {189--213},
title = {{Metaheuristics in combinatorial optimization: overview and conceptual comparison}},
volume = {35},
year = {2003}
}


@incollection{raidl2010metaheuristic,
  title={Metaheuristic hybrids},
  author={Raidl, G{\"u}nther R and Puchinger, Jakob and Blum, Christian},
  booktitle={Handbook of metaheuristics},
  pages={469--496},
  year={2010},
  publisher={Springer}
}

@article{DiAlesio2014,
	Abstract = {Real-Time Embedded Systems (RTES) in safety-critical domains, such as maritime and energy, must satisfy strict performance requirements to be deemed safe. Therefore, such systems have to be thoroughly tested to ensure their correct behavior even under the worst operating conditions. In this paper, we address the need of deriving worst case scenarios with respect to three common performance requirements, namely task deadlines, response time, and CPU usage. Specifically, we investigate whether this worst-case analysis can be effectively re-expressed as a Constrained Optimization Problem (COP) over the space of possible inputs to the system. Solving this problem means finding the sets of inputs that maximize the chance to violate performance requirements at runtime. Such inputs can in turn be used to test if the target RTES meets the expected performance even in the worst case. We develop an OPL model for IBM ILOG CP Optimizer that implements a task priority-based preemptive scheduling, and apply it to a case study from the maritime and energy domain. Our validation shows that (1) the input to our model can be provided with reasonable effort in an industrial setting, and (2) the COP effectively identifies test cases that maximize deadline misses, response time, and CPU usage.},
	Author = {{Di Alesio}, Stefano and Nejati, Shiva and Briand, Lionel and Gotlieb, Arnaud},
	Doi = {10.1007/978-3-319-10428-7{\_}58},
	Journal = {Principles and Practice of Constraint Programming},
	Pages = {813--830},
	Title = {{Worst-Case Scheduling of Software Tasks -- A Constraint Optimization Model to Support Performance Testing}},}

@article{DiAlesio2013,
	Abstract = {Safety-critical Real Time Embedded Systems (RT-ESs) are usually subject to strict timing and performance requirements that must be satisfied for the system to be deemed safe. In this paper, we use effective search strategies whose goal is finding worst case scenarios with respect to deadline misses. Such scenarios can in turn be used to test the target RTES and ensure that it satisfies its timing requirements even under worst case conditions. Specifically, we develop an approach based on Constraint Programming (CP) to automate the generation of test cases that reveal, or are likely to, task deadline misses. We evaluate it through a comparison with a state-of-the-art approach based on Genetic Algorithms (GA). In particular, we compare CP and GA in five case studies for efficiency, effectiveness, and scalability. Our experimental results show that, on the largest and more complex case studies, CP performs significantly better than GA. Furthermore, CP offers some advantages over GA, such as it guarantees a complete search when there is sufficient time, and, being deterministic, it doesn't rely on parameters that potentially have a significant effect on the search and therefore need to be tuned. Hence, we conclude that our results are encouraging and suggest this is an advantageous approach for stress testing of RTESs with respect to timing constraints.},
	Author = {{Di Alesio}, S and Nejati, S and Briand, L and Gotlieb, A},
	Doi = {10.1109/ISSRE.2013.6698915},
	File = {:Users/naubergois/Documents/10.0000@www.computer.org@generic-DD33B05EC8B4.pdf:pdf},
	Isbn = {9781479923663},
	Journal = {IEEE Xplore},
	Keywords = {constraint pro-,real-time systems,stress testing},
	Pages = {158--167},
	Title = {{Stress testing of task deadlines: A constraint programming approach}},
	Year = {2013}}

@article{Alesio2015,
	Author = {Alesio, Stefano D I and Briand, Lionel C and Nejati, Shiva and Gotlieb, Arnaud},
	File = {:Users/naubergois/Documents/a4-dialesio.pdf:pdf},
	Journal = {ACM Transactions on Software Engineering and Methodology},
	Number = {1},
	Title = {{Combining Genetic Algorithms and Constraint Programming}},
	Volume = {25},
	Year = {2015}}

@article{Raidl2006,
	Abstract = {Manifold possibilities of hybridizing individual metaheuristics with each other and/or with algorithms from other fields exist. A large number of publications documents the benefits and great success of such hybrids. This article overviews several popular hybridization approaches and classifies them based on various characteristics. In particular with respect to low-level hybrids of different metaheuristics, a unified view based on a common pool template is described. It helps in making similarities and different key components of existing metaheuristics explicit. We then consider these key components as a toolbox for building new, effective hybrid metaheuristics. This approach of thinking seems to be superior to sticking too strongly to the philosophies and historical backgrounds behind the different metaheuristic paradigms. Finally, particularly promising possibilities of combining metaheuristics with constraint programming and integer programming techniques are highlighted.},
	Author = {Raidl, R},
	Doi = {10.1007/11890584{\_}1},
	File = {:Users/naubergois/Documents/pres{\_}gunther.pdf:pdf},
	Isbn = {9783540463849},
	Issn = {03029743},
	Journal = {Hybrid Metaheuristics (LNCS 4030)},
	Pages = {1--12},
	Title = {{A Unified View on Hybrid Metaheuristics}},
	Year = {2006}}

@article{Pohlheim2005,
	Abstract = {Whereas the verification of non-safety-related embedded software typically focuses on demonstrating that the implementation fulfills its functional requirements, this is not sufficient for safety-relevant systems. In this case, the control software must also meet application- specific safety requirements.Safety requirements typically arise from the application of hazard and/or safety analysis techniques, e.g., FMEA, FTA or SHARD. During the downstream development process it must be shown that these requirements cannot be violated. This can be achieved utilizing different techniques. One way of providing evidence that violations of the safety properties identified cannot occur is to thoroughly test each of the safety requirements.This paper introduces Evolutionary Safety Testing (EST), a fully automated procedure for the safety testing of embedded control software. EST employs extended evolutionary algorithms in an optimization process which aggressively tries to find test data sequences that cause the test object to violate a given safety requirement.A compact description formalism for input sequences for safety testing is presented, which is compatible with description techniques used during other test process stages. This compact description allows 1) an efficient application of evolutionary algorithms (and other optimization techniques) and 2) the description of long test sequences necessary for the adequate stimulation of real-world systems. The objective function is designed in such a way that optimal values represent test data sequences which violate a given safety requirement. By means of repeated input sequence generation, software execution and the subsequent evaluation of the objective function each safety requirement is extensively tested.The use of EST for the safety testing of automotive control software is demonstrated using safety requirements of an adaptive cruise control (ACC) system.The EST approach can easily be integrated into an overall software test strategy which combines different test design techniques with specific test objectives.},
	Author = {Pohlheim, Hartmut and Conrad, Mirko and Griep, Arne},
	Doi = {10.4271/2005-01-0750},
	Journal = {Analysis},
	Number = {724},
	Pages = {804----814},
	Title = {{Evolutionary Safety Testing of Embedded Control Software by Automatically Generating Compact Test Data Sequences}},
	Year = {2005}}

@article{Gross2000,
	Abstract = {Software architecture design approaches typically treat architecture as an abstraction of the implemented system. However, doing so means that the concepts, languages, notations, and tools for architecture are much more closely related to those of detailed design and implementation than to those of software requirements. Thus the gap between requirements and architecture represents a paradigm shift, while that between architecture and detailed design does not. Global Analysis, which is part of the Siemens Four Views architecture design approach, is a set of activities that serves to reduce the magnitude of this gap by guiding the architecture design process, capturing design rationale, and supporting traceability between requirements and architecture. In this paper Global Analysis is re-examined in light of five years of teaching it, reflecting on it, comparing it to other approaches, and examining how it was applied in four new systems. This experience confirms the value of the Global Analysis activities and the importance of capturing its results. In some cases the benefit went beyond that envisioned, and in other cases Global Analysis was not applied as expected. Because the templates that are provided for Global Analysis results have such a strong influence on how the activities were performed, this will be the focus of future changes},
	Author = {Gross, Hg and Jones, Bryan F and Eyres, David E},
	Doi = {10.1049/ip-sen},
	File = {:Users/naubergois/Documents/gross2000.pdf:pdf},
	Isbn = {0818669101},
	Issn = {14625970},
	Journal = {Software, IEE Proceedings-},
	Number = {2},
	Pages = {25--30},
	Pmid = {18015135},
	Title = {{Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems}},
	Volume = {147},
	Year = {2000}}

@article{Smeral2014,
	Author = {\v{S}meral, Ron},
	File = {:Users/naubergois/Dropbox/dp.pdf:pdf},
	Title = {{Modern Performance Tools Applied}},
	Year = {2014}}

@article{Puchinger2005,
	Abstract = {In this survey we discuss different state-of-the-art approaches of combining exact algorithms and metaheuristics to solve combinatorial optimization problems. Some of these hybrids mainly aim at providing optimal solutions in shorter time, while others primarily focus on getting better heuristic solutions. The two main categories in which we divide the approaches are collaborative versus integrative combinations.We further classify the different techniques in a hierarchical way. Altogether, the surveyed work on combinations of exact algorithms and metaheuristics documents the usefulness and strong potential of this research direction.},
	Author = {Puchinger, Jakob and Raidl, R},
	Doi = {10.1007/11499305\_5},
	File = {:Users/naubergois/Documents/puchinger-05.pdf:pdf},
	Isbn = {9783540263197},
	Issn = {03029743},
	Journal = {Artificial Intelligence and Knowledge Engineering Applications a Bioinspired Approach},
	Pages = {41--53},
	Title = {{Combining Metaheuristics and Exact Algorithms in Combinatorial Optimization : A Survey and Classification}},
	Volume = {3562},
	Year = {2005}}

@article{Blum2012,
	Abstract = {Research in metaheuristics for combinatorial optimization problems has lately experienced a noteworthy shift towards the hybridization of metaheuristics with other techniques for optimization. At the same time, the focus of research has changed from being rather algorithm-oriented to being more problem-oriented. Nowadays the focus is on solving the problem at hand in the best way possible, rather than promoting a certain metaheuristic. This has led to an enormously fruitful cross-fertilization of different areas of optimization. This cross-fertilization is documented by a multitude of powerful hybrid algorithms that were obtained by combining components from several different optimization techniques. Hereby, hybridization is not restricted to the combination of different metaheuristics but includes, for example, the combination of exact algorithms and metaheuristics. In this work we provide a survey of some of the most important lines of hybridization. The literature review is accompanied by the presentation of illustrative examples. {\copyright} 2010 Elsevier B.V. All rights reserved.},
	Author = {Blum, Christian},
	Doi = {10.1007/978-3-642-33860-1\_1},
	File = {:Users/naubergois/Documents/blum-11.pdf:pdf},
	Isbn = {9783642338595},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Keywords = {combinatorial optimization,hybrid metaheuristics},
	Number = {6},
	Pages = {1--10},
	Publisher = {Elsevier B.V.},
	Title = {{Hybrid metaheuristics in combinatorial optimization: A tutorial}},
	Volume = {7505 LNCS},
	Year = {2012}}

@article{Wang2010,
	Author = {Wang, Xingen and Zhou, Bo and Li, Wei},
	Doi = {10.1109/ISPA.2010.24},
	File = {:Users/naubergois/Dropbox/WangXingen-ISPA2010.pdf:pdf},
	Isbn = {978-1-4244-8095-1},
	Journal = {International Symposium on Parallel and Distributed Processing with Applications},
	Keywords = {load model,load testing,markov chains,model,performance engineering,usage},
	Pages = {483--490},
	Title = {{Model Based Load Testing of Web Applications}},
	Year = {2010}}

@book{Smith:2012qr,
	Author = {Smith, J.~M. and Jones, A.~B.},
	Edition = {7th},
	Publisher = {Publisher},
	Title = {{B}ook {T}itle},
	Year = {2012}}

@article{Smith:2013jd,
	Author = {Jones, A.~B. and Smith, J.~M.},
	Journal = {{J}ournal {T}itle},
	Month = {March},
	Number = {52},
	Pages = {123-456},
	Publisher = {Publisher},
	Title = {{A}rticle {T}itle},
	Volume = {13},
	Year = {2013}}

@article{Tlili1917,
	Author = {Tlili, Marouane and Wappler, Stefan and Sthamer, Harmen},
	Isbn = {1595931864},
	Journal = {Technology},
	Keywords = {daimler-,harmen,sthamer},
	Pages = {1917--1924},
	Title = {{Improving Evolutionary Real-Time Testing}},
	Year = {1917}}

@phdthesis{Jiang2010,
	Author = {Jiang, ZM},
	Booktitle = {\ldots symposium on Software testing and analysis},
	Title = {{Automated analysis of load testing results}},
	Url = {http://dl.acm.org/citation.cfm?id=1831726},
	Year = {2010}}

@article{Jiang2009,
	Abstract = {The goal of a load test is to uncover functional and per- formance problems of a system under load. Performance problems refer to the situations where a system suffers from unexpectedly high response time or low throughput. It is difficult to detect performance problems in a load test due to the absence of formally-defined performance objectives and the large amount of data that must be examined. In this paper, we present an approach which automati- cally analyzes the execution logs of a load test for perfor- mance problems. We first derive the system's performance baseline from previous runs. Then we perform an in-depth performance comparison against the derived performance baseline. Case studies show that our approach produces few false alarms (with a precision of 77\%) and scales well to large industrial systems.},
	Author = {Jiang, ZM and Hassan, AE},
	Journal = {\ldots , 2009. ICSM 2009. IEEE \ldots},
	Title = {{Automated performance analysis of load tests}},
	Year = {2009}}

@article{Afzal2009a,
	Abstract = {Search-based software testing is the application of metaheuristic search techniques to generate software tests. The test adequacy criterion is transformed into a fitness function and a set of solutions in the search space are evaluated with respect to the fitness function using a metaheuristic search technique. The application of metaheuristic search techniques for testing is promising due to the fact that exhaustive testing is infeasible considering the size and complexity of software under test. Search-based software testing has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional) and grey-box (combination of structural and functional) testing. In addition, metaheuristic search techniques have also been applied to test non-functional properties. The overall objective of undertaking this systematic review is to examine existing work into non-functional search-based software testing (NFSBST). We are interested in types of non-functional testing targeted using metaheuristic search techniques, different fitness functions used in different types of search-based non-functional testing and challenges in the application of these techniques. The systematic review is based on a comprehensive set of 35 articles obtained after a multi-stage selection process and have been published in the time span 1996-2007. The results of the review show that metaheuristic search techniques have been applied for non-functional testing of execution time, quality of service, security, usability and safety. A variety of metaheuristic search techniques are found to be applicable for non-functional testing including simulated annealing, tabu search, genetic algorithms, ant colony methods, grammatical evolution, genetic programming (and its variants including linear genetic programming) and swarm intelligence methods. The review reports on different fitness functions used to guide the search for each of the categories of execution time, safety, usability, quality of service and security; along with a discussion of possible challenges in the application of metaheuristic search techniques. ?? 2009 Elsevier B.V. All rights reserved.},
	Author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
	Doi = {10.1016/j.infsof.2008.12.005},
	File = {:Users/naubergois/Dropbox/X12-searchbased-testing-afzal-ist09.pdf:pdf},
	Isbn = {0950-5849},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Non-functional system properties,Search-based software testing,Systematic review},
	Number = {6},
	Pages = {957--976},
	Publisher = {Elsevier B.V.},
	Title = {{A systematic review of search-based testing for non-functional system properties}},
	Volume = {51},
	Year = {2009}}

@article{Stations,
	Author = {{Wegener, Joachim and Pitschinetz, Roman and Sthamer}, Harmen},
	Journal = {Proceedings of the 1st International Workshop on Automated Program Analysis, Testing and Verification (WAPATV'00)},
	Title = {{Automated Testing of Real-Time Tasks}},
	Year = {2000}}

@article{Nevedrov2007,
	Author = {Nevedrov, Dmitri},
	Pages = {1--11},
	Title = {{Using JMeter to Performance Test Web Services}},
	Year = {2007}}

@book{Molyneaux2009,
	Abstract = {This practical book provides a step-by-step approach to testing mission-critical applications for scalability and performance before they're deployed -- a vital topic to which other books devote one chapter, if that. Businesses today live and die by network applications and web services. Because of the increasing complexity of these programs, and the pressure to deploy them quickly, many professionals don't take the time to ensure that they'll perform well and scale effectively. The Art of Application Performance Testing explains the complete life cycle of the testing process, and demonstrates best practices to help you plan, gain approval for, coordinate, and conduct performance tests on your applications. With this book, you'll learn to: Set realistic performance testing goals Implement an effective application performance testing strategy Interpret performance test results Cope with different application technologies and architectures Use automated performance testing tools Test traditional local applications, web-based applications, and web services (SOAs) Recognize and resolves issues that are often overlooked in performance tests Written by a consultant with 30 years of experience in the IT industry and over 12 years experience with performance testing, this easy-to-read book is illustrated with real-world examples and packed with practical advice. The Art of Application Performance Testing thoroughly explains the pitfalls of an inadequate testing strategy and offers you a robust, structured approach for ensuring that your applications perform well and scale effectively when the need arises. "Ian has maintained a vendor-agnostic methodology beautifully in this material. The metrics and graphs, along with background information provided in his case studies, eloquently convey to the reader, 'Methodology above all, tools at your discretion...' Ian's expertise shines through throughout the entire reading experience." -- Matt St. Onge, Enterprise Solution Architect, HCL Technologies America / Teradyne},
	Author = {Molyneaux, Ian},
	File = {:home/74397176353/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molyneaux - 2009 - The Art of Application Performance Testing(2).pdf:pdf},
	Isbn = {9780596551056},
	Keywords = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Language = {en},
	Mendeley-Tags = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Month = jan,
	Pages = {159},
	Publisher = {"O'Reilly Media, Inc."},
	Shorttitle = {The Art of Application Performance Testing},
	Title = {{The Art of Application Performance Testing: Help for Programmers and Quality Assurance}},
	Year = {2009},
	edition  = {1st}}

@article{Sullivan,
	Author = {Sullivan, Michael O and V\"{o}ssner, Siegfried and Wegener, Joachim and Ag, Daimler-benz},
	File = {:Users/naubergois/Dropbox/eurostar1998.pdf:pdf},
	Pages = {1--20},
	Title = {{Testing Temporal Correctness of Real-Time Systems --- A New Approach Using Genetic Algorithms and Cluster Analysis ---}}}

@inproceedings{Draheim2006b,
	Author = {Draheim, D. and Grundy, J. and Hosking, J. and Lutteroth, C. and Weber, G.},
	Booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
	Doi = {10.1109/CSMR.2006.43},
	Isbn = {0-7695-2536-9},
	Issn = {1052-8725},
	Title = {{Realistic load testing of Web applications}},
	Year = {2006}}


@article{Vetoio2011,
author = {Trubiani, Catia},
file = {:Users/naubergois/Downloads/PhDThesis-CatiaTrubiani.pdf:pdf},
journal = {Language},
title = {{PhD Thesis in Computer Science Automated generation of architectural feedback from software performance analysis results Catia Trubiani}},
year = {2011}
}


	
	
@book{brown1998antipatterns,
  title={AntiPatterns: refactoring software, architectures, and projects in crisis},
  author={Brown, William H and Malveau, Raphael C and McCormick, Hays W and Mowbray, Thomas J},
  year={1998},
  publisher={John Wiley \& Sons, Inc.}
}
	
@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	
	

@phdthesis{Luiz2011,
	Author = {Luiz, Artur and Freitas, Cunha and Prof, Orientadora and Vieira, Renata},
	School = {Pontif{\'\i}cia Universidade Cat{\'o}lica do Rio Grande do Sul},
	Title = {{Ontologias para Teste de Desempenho de Software}},
	Year = {2011}}

@article{Fe2004,
	Author = {F\'{e}, Iure De Sousa and dos Santos, Pedro de Alc\^{a}ntara},
	Title = {{Os custos dos Testes de Desempenho e Estresse}},
	Year = {2004}}

@article{Babbar2011,
	Author = {Babbar, C and Bajpai, N and Sarmah, Dk},
	Isbn = {9789380544007},
	Journal = {International Journal of Technology},
	Title = {{Web Application Performance Analysis based on Component Load Testing}},
	Year = {2011}}

@article{Avritzer1995,
	Author = {Avritzer, A. and Weyuker, E.J.},
	Issn = {0098-5589},
	Journal = {Software Engineering, IEEE \ldots},
	Keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Mendeley-Tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Number = {9},
	Pages = {705--716},
	Title = {{The automatic generation of load test suites and the assessment of the resulting software}},
	Volume = {21},
	Year = {1995}}

@article{Garousi2010,
	Author = {Garousi, Vahid},
	Doi = {10.1109/TSE.2010.5},
	Issn = {0098-5589},
	Journal = {IEEE Transactions on Software Engineering},
	Keywords = {empirical analysis,genetic algorithms,search-based testing,stress testing,test automation,test tools},
	Month = nov,
	Number = {6},
	Pages = {778--797},
	Title = {{A Genetic Algorithm-Based Stress Test Requirements Generator Tool and Its Empirical Evaluation}},
	Volume = {36},
	Year = {2010}}

@inproceedings{Avritzer1993d,
	Address = {New York, NY, USA},
	Annote = {From Duplicate 1 ( },
	Author = {Avritzer, Alberto and Larson, Brian},
	Booktitle = {ACM SIGSOFT Software Engineering Notes},
	Doi = {10.1145/154183.154244},
	Isbn = {0-89791-608-5},
	Pages = {82--88},
	Publisher = {ACM},
	Series = {ISSTA '93},
	Title = {{Load Testing Software Using Deterministic State Testing}},
	Year = {1993}}

@article{Avritzer1994,
	Address = {New York, New York, USA},
	Author = {Avritzer, Alberto and Weyuker, EJ},
	Doi = {10.1145/186258.186507},
	Isbn = {0897916832},
	Journal = {\ldots international symposium on Software testing \ldots},
	Pages = {44--57},
	Publisher = {ACM Press},
	Title = {{Generating test suites for software load testing}},
	Year = {1994}}

@phdthesis{Garousi2006,
author = {Garousi, Vahid},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Garousi - 2006 - Traffic-aware Stress Testing of Distributed Real-Time Systems based on UML Models using Genetic Algorithms(6).pdf:pdf},
isbn = {9780494262252},
number = {August},
title = {{Traffic-aware Stress Testing of Distributed Real-Time Systems based on UML Models using Genetic Algorithms}},
year = {2006}
}


@article{Santos2011,
	Author = {Santos, I de Sousa and Santos, AR and Neto, PA dos Santos},
	Journal = {SEKE},
	Keywords = {- software testing,data generation,experimental study,however,limitations in,non-functional,of performance and stress,requirements,scripts,scripts from functional testing,testing,tool enabled the generation},
	Title = {{Reusing Functional Testing in order to Decrease Performance and Stress Testing Costs.}},
	Year = {2011}}

@book{bernard2012foundations,
	Author = {Bernard, Pierre},
	Publisher = {Van Haren},
	Title = {Foundations of ITIL},
	Year = {2012}}

@article{Abu-nimeh2001,
	Author = {Abu-nimeh, Saeed and Nair, Suku and Marchetti, Marco},
	Keywords = {bandwidth throttle,denial of service,ramp-up time,response time,stress-testing,think,time,ttfb,ttlb},
	Title = {{Avoiding Denial of Service via Stress Testing}},
	Year = {2001}}

@article{Garousi2008,
	Author = {Garousi, Vahid},
	Doi = {10.1145/1389095.1389433},
	Isbn = {9781605581309},
	Journal = {Proceedings of the 10th annual conference on Genetic and evolutionary computation - GECCO '08},
	Keywords = {empirical analysis,genetic algorithms,stress testing},
	Pages = {1743},
	Title = {{Empirical analysis of a genetic algorithm-based stress test technique}},
	Year = {2008}}

@article{Chakravarty2010,
	Author = {Chakravarty, A},
	Journal = {Information Technology: New Generations ( \ldots},
	Title = {{Stress testing an ai based web service: A case study}},
	Year = {2010}}

@article{Acharya2009,
	Author = {Acharya, Mithun and Kommineni, Vamshidhar},
	Doi = {10.1109/ASE.2009.95},
	Isbn = {9780769538914},
	Issn = {1527-1366},
	Journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
	Pages = {409--420},
	Title = {{Mining health models for performance monitoring of services}},
	Year = {2009}}

@article{Catelani2011,
	Doi = {10.1016/j.csi.2010.06.006},
	File = {:Users/naubergois/Dropbox/1-s2.0-S092054891000084X-main.pdf:pdf},
	Isbn = {09205489 (ISSN)},
	Issn = {09205489},
	Journal = {Computer Standards and Interfaces},
	Keywords = {Mean time to overflow,Quality in use,Software automated testing,Software reliability},
	Number = {2},
	Pages = {152--158},
	Publisher = {Elsevier B.V.},
	Title = {{Software automated testing: A solution to maximize the test plan coverage and to increase software reliability and quality in use}},
	Volume = {33},
	Year = {2011}}

@article{Wegener1997,
	Abstract = {The development of real-time systems is an essential industrial activity whose importance is increasing. The most important analytical method to assure the quality of real-time systems is dynamic testing. Testing is the only method which examines the actual run-time behaviour of real-time software, based on an execution in the real application environment. Dynamic aspects like the duration of computations, the memory actually needed, or the synchronization of parallel processes are of major importance for the correct function of real-time systems and have to be tested. A comprehensive investigation of existing software test methods shows that they mostly concentrate on testing for functional correctness. They are not suited for an examination of temporal correctness which is essential to real-time systems. Very small systems show a wide range of different execution times. Therefore, existing test procedures must be supplemented by new methods, which concentrate on determining whether the system violates its specified timing constraints. In general, this means that outputs are produced too early or their computation takes too long. The task of the tester is to find the inputs with the longest or shortest execution times to check whether they produce a temporal error. If the search for such inputs is interpreted as a problem of optimization, genetic algorithms can be used to find the inputs with the longest or shortest execution times automatically. The fitness function is the execution time measured in processor cycles. Experiments using genetic algorithms on a number of programs with up to 1511 LOC and 843 integer input parameters have successfully identified new longer and shorter paths than had been found using random testing or systematic testing. Genetic algorithms are able therefore to check large programs and they show considerable promise in establishing the validity of the temporal behaviour of real-time software.},
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Doi = {10.1023/A:1018551716639},
	Issn = {0963-9314, 1573-1367},
	Journal = {Software Quality Journal},
	Keywords = {embedded systems,genetic algorithms,real time systems,temporal behaviour,testing},
	Number = {2},
	Pages = {127--135},
	Title = {{Testing real-time systems using genetic algorithms}},
	Url = {http://www.springerlink.com/index/uh26067rt3516765.pdf},
	Volume = {6},
	Year = {1997}}

@inproceedings{Alander,
	Abstract = {In this work we are studying possibilities to test software using genetic algorithm search. The idea is to produce test cases in order to find problematic situations like processing time extremes. The proposed test method comes under the heading of automated dynamic stress testing. Keywords: genetic algorithms, software engineering, dynamic stress testing 1 Introduction Real-time software is increasingly applied to products in which failure may have severe consequences, thus the requirements for correctness and reliability are getting higher, too. In very reliable sequential programs, the rate of errors should be less than 10 errors/1000 lines of code, to avoid functional failure. Achieving this level is very labourious, because the amount of program testing work grows exponentially with code size. Testing software manually is slow, expensive and demands inventiveness. Automated testing can reduce both the time and costs needed for performing tests. Exhaustive test data generation is...},
	Annote = {From Duplicate 1 ( },
	Author = {Alander, Jarmo T. JT and Mantere, Timo and Turunen, Pekka},
	Booktitle = {Neural Nets and Genetic Algorithms},
	Date-Modified = {2015-12-05 06:11:49 +0000},
	Title = {{Genetic Algorithm Based Software Testing}},
	Year = {1998}}

@article{Barros2007,
	Author = {Barros, Marcelo De and Shiau, Jing},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barros, Shiau - 2007 - Web services wind tunnel On performance testing large-scale stateful web services.pdf:pdf},
	Journal = {\ldots and Networks, 2007. \ldots},
	Title = {{Web services wind tunnel: On performance testing large-scale stateful web services}},
	Year = {2007}}

@article{Weyuker2000,
	Abstract = {An approach to software performance testing is discussed. A case study describing the experience of using this approach for testing the performance of a system used as a gateway in a large industrial client/server transaction processing application is presented.},
	Author = {Weyuker, EJ and Vokolos, FI},
	Doi = {10.1109/32.888628},
	Issn = {0098-5589},
	Journal = {IEEE transactions on software engineering},
	Keywords = {Software performance testing,performance testing.,program testing,software testing},
	Mendeley-Tags = {Software performance testing,performance testing.,program testing,software testing},
	Number = {12},
	Pages = {1147--1156},
	Shorttitle = {Experience with Performance Testing of Software Sy},
	Title = {{Experience with performance testing of software systems: issues, an approach, and case study}},
	Volume = {26},
	Year = {2000}}

@article{Raiha2010,
	Abstract = {This survey investigates search-based approaches to software design. The basics of the most popular meta-heuristic algorithms are presented as background to the search-based viewpoint. Software design is considered from a wide viewpoint, including topics that can also be categorized as software maintenance or re-engineering. Search-based approaches have been used in research from the high architecture design level to software clustering and finally software refactoring. Enhancing and predicting software quality with search-based methods is also taken into account as a part of the design process. The background for the underlying software engineering problems is discussed, after which search-based approaches are presented. Summarizing remarks and tables collecting the fundamental issues of approaches for each type of problem are given. The choices regarding critical decisions, such as representation and fitness function, when used in meta-heuristic search algorithms, are emphasized and discussed in detail. Ideas for future research directions are also given. {\copyright} 2010 Elsevier Inc.},
	Author = {R\"{a}ih\"{a}, Outi},
	Doi = {10.1016/j.cosrev.2010.06.001},
	Isbn = {15740137},
	Issn = {15740137},
	Journal = {Computer Science Review},
	Keywords = {Search algorithms,Search-based software engineering,Software design,Software quality},
	Number = {4},
	Pages = {203--249},
	Publisher = {Elsevier Inc.},
	Title = {{A survey on search-based software design}},
	Volume = {4},
	Year = {2010}}

@article{Mohamed2012,
	Abstract = {With the recent rapid development of mobile devices in terms of processing power, memory and storage capabilities coupled with the advancements of wireless technology in terms of higher data transmission rates such as 3G and 4G, it has now become feasible to host Web services on mobile devices. In this paper we propose a lightweight framework for hosting Web services on mobile devices. We further evaluate and provide a comparative analysis for hosting RESTful Web services versus SOAP-based Web services on our framework. Our experimental results and analysis indicate that RESTful Web services are less resource-consuming and more efficient for the implementation and provisioning of Web services from resource-constrained mobile devices. ?? 2012 Published by Elsevier Ltd.},
	Author = {Mohamed, KamalEldin and Wijesekera, Duminda},
	Doi = {10.1016/j.procs.2012.06.095},
	Isbn = {1877-0509},
	Issn = {18770509},
	Journal = {Procedia Computer Science},
	Keywords = {Lightweight framework,Mobile web server,REST,SOAP,Web services},
	Pages = {744--751},
	Publisher = {Duminda Wijesekera},
	Title = {{Performance analysis of web services on mobile devices}},
	Volume = {10},
	Year = {2012}}

@book{reeves1993modern,
	Author = {Reeves, Colin R},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {Modern heuristic techniques for combinatorial problems},
	Year = {1993}}

@article{Sandler2004,
	Abstract = {The classic, landmark work on software testingThe hardware and software of computing have changed markedly in the three decades since the first edition of The Art of Software Testing, but this book's powerful underlying analysis has stood the test of time. Whereas most books on software testing target particular development techniques, languages, or testing methods, The Art of Software Testing, Third Edition provides a brief but powerful and comprehensive presentation of time-proven software testing approaches. If your software development project is mission critical, this book is an investment that will pay for itself with the first bug you find.The new Third Edition explains how to apply the book's classic principles to today's hot topics including:Testing apps for iPhones, iPads, BlackBerrys, Androids, and other mobile devicesCollaborative (user) programming and testingTesting for Internet applications, e-commerce, and agile programming environmentsWhether you're a student looking for a testing guide you'll use for the rest of your career, or an IT manager overseeing a software development team, The Art of Software Testing, Third Edition is an expensive book that will pay for itself many times over.},
	Author = {Sandler, Corey and Badgett, Tom and Thomas, TM},
	File = {:Users/naubergois/Downloads/The Art of Software Testing, 3rd Edition.pdf:pdf},
	Isbn = {9781118133156},
	Keywords = {Business \& Economics / Reference,Computers / Information Technology},
	Language = {en},
	Mendeley-Tags = {Business \& Economics / Reference,Computers / Information Technology},
	Month = sep,
	Pages = {200},
	Publisher = {John Wiley \& Sons},
	Title = {{The Art of Software Testing}},
	Year = {2004}}

@book{Erinle2013,
	Author = {Erinle, Bayo},
	File = {:Users/naubergois/Dropbox/OPR/papers/performance-testing-with-jmeter-2-9.pdf:pdf},
	Isbn = {9781782165842},
	Title = {{Performance Testing With JMeter 2.9}},
	Year = {2013}}

@misc{Corporation2007,
	Abstract = {Performance Testing Guidance for Web Applications provides an end-to-end approach for implementing performance testing. Whether you are new to performance testing or looking for ways to improve your current performance-testing approach, you will gain insights that you can tailor to your specific scenarios.},
	Address = {United States?},
	Author = {Corporation, Microsoft},
	Edition = {1 edition},
	Isbn = {9780735625709},
	Language = {English},
	Month = nov,
	Pages = {288},
	Publisher = {Microsoft Press},
	Title = {{Performance Testing Guidance for Web Applications}},
	Url = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700 http://msdn.microsoft.com/en-us/library/bb924375.aspx},
	Year = {2007},
	Bdsk-Url-1 = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700%20http://msdn.microsoft.com/en-us/library/bb924375.aspx}}

@article{Snellman,
	Author = {Snellman, Niclas and Ashraf, Adnan and Porres, Ivan},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Snellman, Ashraf, Porres - Unknown - Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud(2).pdf:pdf},
	Keywords = {-performance testing,a flat performance curve,application should ideally maintain,cloud computing,intended maximum load level,rich in-,scalability testing,ternet applications,until it reaches its},
	Title = {{Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud}}}

@article{Cohen2004,
	Abstract = {This paper studies the use of statistical induction techniques as a basis for automated performance diagnosis and performance management. The goal of the work is to develop and evaluate tools for offline and online analysis of system metrics gathered from instrumentation in Internet server platforms. We use a promising class of probabilistic models (Tree-Augmented Bayesian Networks or TANs) to identify combinations of system-level metrics and threshold values that correlate with high-level with Service Level Objectives (SLOs) for average-case response timein a three-tier Web service under a variety of conditions. Experimental results from a testbed show that TAN models involving small subsets of metrics capture patterns of performance behavior in a way that is accurate and yields insights into the causes of observed performance effects. TANs are extremely efficient to represent and evaluate, and they have interpretability properties that make them excellent candidates for automated diagnosis and control. We explore the use of TAN models for offline forensic diagnosis, and in a limited online setting for performance forecasting with stable workloads.},
	Author = {Cohen, Ira and Goldszmidt, Moises and Kelly, Terence and Symons, Julie and Chase, Jeffrey S},
	File = {:Users/naubergois/Dropbox/HPL-2004-183.pdf:pdf},
	Journal = {Small},
	Number = {December},
	Pages = {6--8},
	Title = {{Correlating instrumentation data to system states : A building block for automated diagnosis and control performance forecasting automated performance diagnosis and performance management . The goal of the work is to develop and evaluate tools for offline}},
	Year = {2004}}

@article{Biolchini2005,
	Author = {Biolchini, Jorge and Mian, Paula Gomes and Candida, Ana and Natali, Cruz},
	Doi = {10.1007/978-3-540-70621-2},
	Isbn = {9783540706199},
	Issn = {18650929},
	Journal = {System Engineering and Computer Science Department COPPE/UFRJ, Technical Report ES},
	Number = {May},
	Pages = {165--176},
	Title = {{Systematic Review in Software Engineering}},
	Volume = {679},
	Year = {2005}}

@article{Goncalves2014,
	Author = {Gon\c{c}alves, Marcelo Can\'{a}rio},
	Title = {{Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplica\c{c}\~{o}es na Nuvem Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplica\c{c}\~{o}es na Nuvem}},
	Year = {2014}}

@book{Feitelson2013,
	Author = {Feitelson, Dror G},
	File = {:Users/naubergois/Dropbox/wlmod.pdf:pdf},
	Publisher = {Cambridge University Press},
	Title = {{Workload Modeling for Computer Systems Performance Evaluation}},
	Year = {2013}}

@article{Malik2010b,
	Author = {Malik, Haroon},
	Doi = {10.1145/1810295.1810408},
	File = {:Users/naubergois/Downloads/icse2010\_malik.pdf:pdf},
	Institution = {Queen's University, Kingston, ON, Canada},
	Isbn = {978-1-60558-719-6},
	Issn = {0270-5257},
	Journal = {Software Engineering, 2010 ACM/IEEE 32nd \ldots},
	Keywords = {automation,counters,load test,performance counters,principal component analysis},
	Pages = {421--424},
	Publisher = {IEEE},
	Title = {{A methodology to support load test analysis}},
	Volume = {2},
	Year = {2010}}

@article{Kuhn1997,
	Abstract = {What makes a distributed system reliable? A study of failures in
the US public switched telephone network (PSTN) shows that human
intervention is one key to this large system's reliability. Software is
not the weak link in the PSTN system's dependability. Extensive use of
built-in self-test and recovery mechanisms in major system components
(switches) contributed to software dependability and are significant
design features in the PSTN. The network's high dependability indicates
that the trade-off between dependability gains and complexity introduced
by built-in self-test and recovery mechanisms can be positive. Likewise,
the tradeoff between complex interactions and the loose coupling of
system components has been positive, permitting quick human intervention
in most system failures and resulting in an extremely reliable system
},
	Author = {Kuhn, D. Richard},
	Doi = {10.1109/2.585151},
	File = {:Users/naubergois/Dropbox/kuhn-97-pstn-failures.pdf:pdf},
	Issn = {00189162},
	Journal = {Computer},
	Number = {4},
	Pages = {31--36},
	Pmid = {150},
	Title = {{Sources of failure in the public switched telephone network}},
	Volume = {30},
	Year = {1997}}

@article{McMinn2004,
	Author = {McMinn, Philip and Court, Regent and Testing, Software and Street, Portobello},
	Doi = {10.1002/stvr.294},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/McMinn - 2004 - Search-based software test data generation a survey.pdf:pdf},
	Isbn = {1099-1689},
	Issn = {09600833},
	Journal = {Software testing, Verification and reliability},
	Keywords = {Automated software test data generation,Evolutionary algorithms,Evolutionary testing,Metaheuristic search,Search-based software engineering,Simulated annealing,algorithms,automated software test,automated software test data generation,data generation,evolutionary,evolutionary algorithms,evolutionary testing,metaheuristic search,search-based software engineering,simulated annealing},
	Pages = {1--58},
	Title = {{Search-based software test data generation: a survey}},
	Volume = {14},
	Year = {2004}}

@article{DiLucca2006,
	Author = {{Di Lucca}, Giuseppe a. and Fasolino, Anna Rita},
	Doi = {10.1016/j.infsof.2006.06.006},
	Isbn = {0-7695-2413-3},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Software testing,Web application testing,Web engineering},
	Pages = {1172--1186},
	Title = {{Testing Web-based applications: The state of the art and future trends}},
	Volume = {48},
	Year = {2006}}
	
@article{Harman2015,
abstract = {Search Based Software Testing (SBST) formulates testing as an optimisation problem, which can be attacked using computational search techniques from the field of Search Based Software Engineering (SBSE). We present an analysis of the SBST research agenda1, focusing on the open problems and chal- lenges of testing non-functional properties, in particular a topic we call ‘Search Based Energy Testing' (SBET), Multi-objective SBST and SBST for Test Strategy Identification. We conclude with a vision of FIFIVERIFY tools, which would automatically find faults, fix them and verify the fixes. We explain why we think such FIFIVERIFY tools constitute an exciting challenge for the SBSE community that already could be within its reach.},
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
isbn = {9781479971251},
journal = {8th IEEE International Conference on Software Testing, Verification and Validation (ICST)},
number = {Icst},
title = {{Achievements , open problems and challenges for search based software testing}},
url = {http://www0.cs.ucl.ac.uk/staff/mharman/icst15.pdf},
year = {2015}
}
	

@article{Anand2013,
	Author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
	Doi = {10.1016/j.jss.2013.02.061},
	Issn = {01641212},
	Journal = {Journal of Systems and Software},
	Keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
	Pages = {1978--2001},
	Title = {{An orchestrated survey of methodologies for automated software test case generation}},
	Volume = {86},
	Year = {2013}}

@inproceedings{Penta2007,
	Author = {Penta, Massimiliano Di and Canfora, Gerardo and Esposito, Gianpiero},
	Booktitle = {Proceedings of the 9th annual conference on Genetic and evolutionary computation},
	Isbn = {9781595936974},
	Keywords = {quality of,search-based testing,service level agreement},
	Pages = {1090--1097},
	Title = {{Search-based testing of service level agreements}},
	Year = {2007}}

@article{Barber1999,
	Author = {Barber, Scott},
	File = {:Users/naubergois/Dropbox/ucml\_1.1.pdf:pdf},
	Pages = {1--9},
	Title = {{User Community Modeling Language ( UCML {\texttrademark} ) v1 . 1 for Performance Test Workloads UCML {\texttrademark} Overview}},
	Year = {1999}}

@article{Silveira2011,
	Author = {da Silveira, MB and Rodrigues, EM and Zorzo, AF},
	Journal = {SEKE},
	Keywords = {- model-based testing,performance testing,software product line},
	Title = {{Generation of Scripts for Performance Testing Based on UML Models.}},
	Year = {2011}}

@article{Grechanik2012,
	Author = {Grechanik, Mark and Fu, Chen and Xie, Qing},
	Doi = {10.1109/ICSE.2012.6227197},
	Isbn = {978-1-4673-1067-3},
	Journal = {2012 34th International Conference on Software Engineering (ICSE)},
	Month = jun,
	Pages = {156--166},
	Publisher = {Ieee},
	Title = {{Automatically finding performance problems with feedback-directed learning software testing}},
	Year = {2012}}

@article{Barna2011,
	Author = {Barna, Cornel and Litoiu, M and Ghanbari, H},
	Isbn = {9781450306072},
	Journal = {International conference on Autonomi},
	Keywords = {autonomic system,performance,performance testing},
	Pages = {91--100},
	Title = {{Autonomic load-testing framework}},
	Year = {2011}}

@book{Everett2007,
	Author = {Everett, Gerald D and Jr., Raymond McLeod},
	Isbn = {9780471793717},
	Title = {{Software Testing: Testing Across the Entire Software Development Life Cycle}},
	Year = {2007}}

@article{Chen,
	Author = {Chen, Feifei},
	File = {:Users/naubergois/Downloads/13113010195260.pdf:pdf},
	Journal = {chinacloud.cn},
	Keywords = {as it requires,cloud computing,cost,effectiveness before the deployment,energy,however,of cloud systems,performance engineering,this is not a,trade-off analysis,trivial task},
	Title = {{Generating a Performance Test-bed for Cloud Computing Systems}}}
	
@misc{dean2003managing,
  title={Managing Software Requirements: A Use Case Approach},
  author={Dean, Leffingwell and Don, Widrig},
  year={2003},
  publisher={Addison Wesley}
}	

@article{Alba2008,
abstract = {In this paper we analyze the application of parallel and sequential evolutionary algorithms (EAs) to the automatic test data generation problem. The problem consists of automatically creating a set of input data to test a program. This is a fundamental step in software development and a time consuming task in existing software companies. Canonical sequential EAs have been used in the past for this task. We explore here the use of parallel EAs. Evidence of greater efficiency, larger diversity maintenance, additional availability of memory/CPU, and multi-solution capabilities of the parallel approach, reinforce the importance of the advances in research with these algorithms. We describe in this work how canonical genetic algorithms (GAs) and evolutionary strategies (ESs) can help in software testing, and what the advantages are (if any) of using decentralized populations in these techniques. In addition, we study the influence of some parameters of the proposed test data generator in the results. For the experiments we use a large benchmark composed of twelve programs that includes fundamental algorithms in computer science. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Alba, Enrique and Chicano, Francisco},
doi = {10.1016/j.cor.2007.01.016},
file = {:Users/naubergois/Downloads/testing-cor-sbse.pdf:pdf},
isbn = {0305-0548},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Evolutionary algorithms,Evolutionary testing,Parallel evolutionary algorithms,Software testing},
number = {10},
pages = {3161--3183},
title = {{Observations in using parallel and sequential evolutionary algorithms for automatic software testing}},
volume = {35},
year = {2008}
}

@article{Harman2010,
abstract = {Search-based optimization techniques have been applied to structural software test data generation since 1992, with a recent upsurge in interest and activity within this area. However, despite the large number of recent studies on the applicability of different search-based optimization approaches, there has been very little theoretical analysis of the types of testing problem for which these techniques are well suited. There are also few empirical studies that present results for larger programs. This paper presents a theoretical exploration of the most widely studied approach, the global search technique embodied by Genetic Algorithms. It also presents results from a large empirical study that compares the behavior of both global and local search-based optimization on real-world programs. The results of this study reveal that cases exist of test data generation problem that suit each algorithm, thereby suggesting that a hybrid global-local search (a Memetic Algorithm) may be appropriate. The paper presents a Memetic Algorithm along with further empirical results studying its performance.},
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/naubergois/Downloads/Software engineering IEEE.Vol.36.Iss.2.A.6.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Artificial intelligence,Automated test data generation,Evolutionary testing,Genetic algorithms,Hill climbing,Problem solving,Royal road,Schema theory,Search-based software engineering,Search-based testing,Testing and debugging,Testing tools},
number = {2},
pages = {226--247},
title = {{A theoretical and empirical study of search-based testing: Local, global, and hybrid search}},
volume = {36},
year = {2010}
}

@book{MohammadS.Obaidat,
author = {{Mohammad S. Obaidat}, Petros Nicopolitidis and Faouzi Zarai},
file = {:Users/naubergois/Downloads/Mohammad S. Obaidat, Faouzi Zarai, Petros Nicopolitidis-Modeling and Simulation of Computer Networks and Systems{\_} Methodologies and Applications-Morgan Kaufmann (2015).pdf:pdf},
isbn = {9780128008874},
title = {{Modeling and Simulation of Computer Networks and Systems Methodologies and Applications}}
}

@book{Tobergte2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Raidl, Gunther R and Puchinger, Jakob and Blum}, Christian},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid Metaheuristics{\_} An Emerging Approach to Optimization.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Hybrid Metaheuristics An Emerging Approach}},
volume = {53},
year = {2013}
}

@book{Talbi2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Metaheuristics.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Metaheuristics: From Design to Implementation}},
volume = {53},
year = {2013}
}

@article{Greenwald2003,
abstract = {Bowling named two desiderata for multiagent learning algorithms: rationality and convergence. This paper introduces co{\~{}}elated-Q learning, a natural generaliza- tion of Nash-Q NashoQ converge. FF-Q satisfies convergence, but in general it is not rational. Correlated-Q satisfies rationality by construction. This papers demonstrates the empirical convergence of correlated-Q on a standard testbed of general-sum Markov games. satisfies rationality, but in general it does not and FF-Q that satisfies these criteria.},
author = {Greenwald, Amy and Hall, Keith and Serrano, R},
file = {:Users/naubergois/Downloads/SS02-02-012.pdf:pdf},
journal = {Icml},
number = {3},
pages = {84--89},
title = {{Correlated Q-learning}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-02/SS02-02-012.pdf},
year = {2003}
}

@article{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@article{Hierons2009,
abstract = {Formal methods and testing are two important approaches that assist in the development of high-quality software.While traditionally these approaches have been seen as rivals, in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.},
author = {Hierons, Robert M and Bogdanov, Kirill and Bowen, Jonathan P and Cleaveland, Rance and Derrick, John and Dick, Jeremy and Gheorghe, Marian and Harman, Mark and Kapoor, Kalpesh and Krause, Paul and L{\"{u}}ttgen, Gerald and Simons, Anthony J H and Vilkomir, Sergiy and Woodward, Martin R and Zedan, Hussein},
doi = {http://doi.acm.org/10.1145/1459352.1459354},
file = {:Users/naubergois/Downloads/hierons2009.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
number = {2},
pages = {1--76},
title = {{Using formal specifications to support testing}},
volume = {41},
year = {2009}
}

@phdthesis{shousha2003performance,
  title={Performance Stress Testing of Real-Time Systems Using Genetic Algorithms},
  author={Shousha, Marwa},
  year={2003},
  school={Carleton University Ottawa}
}

@article{hong2000simultaneously,
  title={Simultaneously applying multiple mutation operators in genetic algorithms},
  author={Hong, Tzung-Pei and Wang, Hong-Shung and Chen, Wei-Chou},
  journal={Journal of heuristics},
  volume={6},
  number={4},
  pages={439--455},
  year={2000},
  publisher={Springer}
}

@article{Vogele2016,
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.},
author = {Vogele, Christian and van Hoorn, Andr{\'{e}} and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
doi = {10.1007/s10270-016-0566-5},
file = {:Users/naubergois/Downloads/VoegelevanHoornSchulzHasselbringKrcmar2016WESSBAS-SoSyM.pdf:pdf},
issn = {16191374},
journal = {Software and Systems Modeling},
keywords = {Load testing,Performance models,Performance prediction,Workload specifications},
number = {October},
pages = {1--35},
publisher = {Springer Berlin Heidelberg},
title = {{WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction???a model-driven approach for session-based application systems}},
url = {"http://dx.doi.org/10.1007/s10270-016-0566-5},
year = {2016}
}


@article{Menasce2002a,
author = {Menasc{\'{e}}, Daniel A and Mason, George},
file = {:Users/naubergois/Downloads/10.1.1.468.8603.pdf:pdf},
number = {June},
pages = {1--6},
title = {{TPC-W : A Benchmark for E-commerce}},
year = {2002}
}


@article{Sutton2012,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, Richard S. and Barto, Andrew G.},
doi = {10.1109/MED.2013.6608833},
eprint = {1603.02199},
file = {:Users/naubergois/Downloads/SuttonBook.pdf:pdf},
isbn = {0262193981},
issn = {18726240},
journal = {Learning},
number = {9},
pages = {322},
pmid = {18255791},
title = {{Reinforcement learning}},
url = {https://books.google.com/books?id=CAFR6IBF4xYC{\&}pgis=1$\backslash$nhttp://incompleteideas.net/sutton/book/the-book.html$\backslash$nhttps://www.dropbox.com/s/f4tnuhipchpkgoj/book2012.pdf},
volume = {3},
year = {2012}
}

@article{Szepesvari2010,
abstract = {Reinforcement learning is a learning paradigm concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective.What distin- guishes reinforcement learning from supervised learning is that only partial feedback is given to the learner about the learner's predictions. Further, the predictions may have long term effects through influencing the future state of the controlled system. Thus, time plays a special role. The goal in reinforcement learning is to develop efficient learning algorithms, as well as to understand the al- gorithms' merits and limitations. Reinforcement learning is of great interest because of the large number of practical applications that it can be used to address, ranging from problems in artificial intelligence to operations research or control engineering. In this book,we focus on those algorithms of reinforcement learning that build on the powerful theory of dynamic programming.We give a fairly comprehensive catalog of learning problems, describe the core ideas, note a large number of state of the art algorithms, followed by the discussion of their theoretical properties and limitations.},
author = {Szepesv{\'{a}}ri, Csaba and Bartok, Gabor},
doi = {10.2200/S00268ED1V01Y201005AIM009},
file = {:Users/naubergois/Downloads/RLAlgsInMDPs-lecture.pdf:pdf},
isbn = {9781608454921},
issn = {1939-4608},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
number = {x},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
volume = {4},
year = {2010}
}



@article{Bertolino2008,
abstract = {A Web Service is commonly not an independent software entity, but plays a role in some business process. Hence, it depends on the services provided by external Web Services, to provide its own service. While developing and testing a Web Service, such external services are not always available, or their usage comes along with unwanted side effects like, e.g., utilization fees or database modifications. We present a model-based approach to generate stubs for Web Services which respect both an extra-functional contract expressed via a Service Level Agree- ment (SLA), and a functional contract modeled via a state machine. These stubs allow a developer to set up a testbed over the target plat- form, in which the extra-functional and functional behavior of a Web Service under development can be tested before its publication.},
author = {Bertolino, Antonia and Angelis, Guglielmo De},
doi = {10.1007/978-3-540-68524-1_19},
file = {:Users/naubergois/Downloads/BAFP08.pdf:pdf},
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-68524-1{\_}19},
year = {2008}
}

@article{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@article{Trent1995,
author = {Trent, G and Sake, M},
file = {:Users/naubergois/Downloads/WebSTONE{\_}The{\_}First{\_}Generation{\_}in{\_}HTTP{\_}Se.pdf:pdf},
journal = {WWW Conference'95},
title = {{WebSTONE: The first generation in {\{}HTTP{\}} server benchmarking}},
year = {1995}
}

@article{Luo2015,
abstract = {A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster in order to automatically find performance bottlenecks in applications. We propose FOREPOST, a novel solution, for automatically finding performance bottlenecks in applications using black-box software testing. Our solution is an adaptive, feedback-directed learning testing system that learns rules from execution traces of applications. Theses rules are then used to automatically select test input data for performance testing. We hypothesize that FOREPOST can find more performance bottlenecks as compared to random testing. We have implemented our solution and applied it to a medium-size industrial application at a major insurance company and to two open-source applications. Performance bottlenecks were found automatically and confirmed by experienced testers and developers. We also thoroughly studied the factors (or independent variables) that impact the results of FOREPOST. {\&}copy; 2015 Springer Science+Business Media New York},
author = {Luo, Qi and Nair, Aswathy and Grechanik, Mark and Poshyvanyk, Denys},
doi = {10.1007/s10664-015-9413-5},
file = {:Users/naubergois/Downloads/10.1.1.699.7944.pdf:pdf},
isbn = {1066401594},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Feedback-directed learning system,Performance testing},
pages = {1--51},
title = {{FOREPOST: finding performance problems automatically with feedback-directed learning software testing}},
year = {2015}
}



@book{Talbi2012,
abstract = {The main goal of this book is to provide a state of the art of hybrid metaheuristics. The book provides a complete background that enables readers to design and implement hybrid metaheuristics to solve complex optimization problems (continuous/discrete, mono-objective/multi-objective, optimization under uncertainty) in a diverse range of application domains. Readers learn to solve large scale problems quickly and efficiently combining metaheuristics with complementary metaheuristics, mathematical programming, constraint programming and machine learning. Numerous real-world examples of problems and solutions demonstrate how hybrid metaheuristics are applied in such fields as networks, logistics and transportation, bio-medical, engineering design, scheduling.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
doi = {10.1007/978-3-642-30671-6},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid{\_}Metaheuristics{\_}An{\_}Introduction.pdf:pdf},
isbn = {9783642306709},
issn = {1098-6596},
keywords = {learning,neighborhood search,online and offline tuning,project scheduling,stochastic local search},
number = {December 2016},
pages = {19--35},
pmid = {25246403},
title = {{Hybrid Metaheuristics}},
volume = {2},
year = {2012}
}




@article{Mendoza2005a,
	Author = {Mendoza, Valerie and Novick, Dg},
	Doi = {10.1145/1085313.1085348},
	Isbn = {9157475725},
	Journal = {SIGDOC '05 Proceedings of the 23rd annual international conference on Design of communication: documenting \& designing for pervasive information},
	Keywords = {training,usability},
	Pages = {151--158},
	Title = {{Usability over time}},
	Year = {2005}}

@article{Glover1989,
	Abstract = {This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programming problems are then described, providing connections also to certain nonlinear programming applications. Finally, the paper concludes with a brief survey of new applications of tabu search that have occurred since the developments reported in Part I. Together with additional comparisons with other methods on a wide body of problems, these include results of parallel processing implementations and the use of tabu search in settings ranging from telecommunications to neural networks.},
	Author = {Glover, Fred},
	Doi = {10.1287/ijoc.2.1.4},
	Isbn = {079239965X},
	Issn = {0899-1499},
	Journal = {ORSA journal on Computing},
	Number = {3},
	Pages = {4--32},
	Pmid = {2758},
	Title = {{Tabu Search - Part II}},
	Volume = {2 1},
	Year = {1989}}

@article{Kirkpatrick2007,
	Author = {Kirkpatrick},
	Doi = {10.1126/science.220.4598.671},
	Issn = {0036-8075},
	Number = {4598},
	Pages = {671--680},
	Pmid = {17813860},
	Title = {{Optimization by SA}},
	Volume = {220},
	Year = {2007}}

@article{Goffe1994,
	Abstract = {Many statistical methods rely on numerical optimization to estimate a model's parameters. Unfortunately, conventional algorithms sometimes fail. Even when they do converge, there is no assurance that they have found the global, rather than a local, optimum. We test a new optimization algorithm, simulated annealing, on four econometric problems and compare it to three common conventional algorithms. Not only can simulated annealing find the global optimum, it is also less likely to fail on difficult functions because it is a very robust algorithm. The promise of simulated annealing is demonstrated on the four econometric problems.},
	Author = {Goffe, William L. and Ferrier, Gary D. and Rogers, John},
	Doi = {10.1016/0304-4076(94)90038-8},
	Isbn = {0304-4076},
	Issn = {03044076},
	Journal = {Journal of Econometrics},
	Keywords = {simulated},
	Number = {1-2},
	Pages = {65--99},
	Title = {{Global optimization of statistical functions with simulated annealing}},
	Volume = {60},
	Year = {1994}}

@phdthesis{tracey2000search,
	Author = {Tracey, Nigel James},
	School = {Citeseer},
	Title = {A search-based automated test-data generation framework for safety-critical software},
	Year = {2000}}

@article{alander1996ga,
	Author = {Alander, Jarmo T and Mantere, Pekka Turunen and Virolainen, Jari},
	Publisher = {Citeseer},
	Title = {GA in program testing},
	Year = {1996}}

@article{Tracey1998,
	Abstract = {One of the major costs in a software project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. The framework can incorporate a number of testing criteria, for both functional and non-functional properties. Application of the optimisation framework to testing specification failures and exception conditions is illustrated. The results of a number of small case studies are presented and show the efficiency and effectiveness of this dynamic optimisation-based approach to generating test-data},
	Author = {Tracey, N J and Clark, J a and Mander, K C},
	Keywords = {QA 76 Software, computer programming,},
	Title = {{Automated Programme Flaw Finding using Simulated Annealing}},
	Year = {1998}}

@article{Wegener1999,
	Abstract = {For real-time systems, correct system functionality depends on
logical as well as on temporal correctness. Static analysis alone is not
sufficient to verify the temporal behavior of real-time systems. Since
existing test methods are not specialized for the verification of
temporal correctness, we have developed a new testing method, namely
evolutionary testing. This paper illustrates results of the first
industrial application of the evolutionary test},
	Author = {Wegener, J. and Sthamer, H. and Pohlheim, H.},
	Doi = {10.1109/REAL.1999.818852},
	Isbn = {0-7695-0475-2},
	Issn = {1052-8725},
	Journal = {Proceedings 20th IEEE Real-Time Systems Symposium (Cat. No.99CB37054)},
	Title = {{Testing the temporal behavior of real-time tasks using extended evolutionary algorithms}},
	Year = {1999}}

@article{Mueller1998,
	Abstract = {The paper contrasts two methods to verify timing constraints of
real-time applications. The method of static analysis predicts the
worst-case and best-case execution times of a task's code by analyzing
execution paths and simulating processor characteristics without ever
executing the program or requiring the program's input. Evolutionary
testing is an iterative testing procedure, which approximates the
extreme execution times within several generations. By executing the
test object dynamically and measuring the execution times the inputs are
guided yielding gradually tighter predictions of the extreme execution
times. The authors examined both approaches on a number of real world
examples. The results show that static analysis and evolutionary testing
are complementary methods, which together provide upper and lower bounds
for both worst-case and best-case execution times},
	Author = {Mueller, F. and Wegener, J.},
	Doi = {10.1109/RTTAS.1998.683198},
	File = {:Users/naubergois/Dropbox/rtas98.pdf:pdf},
	Isbn = {0-8186-8569-7},
	Journal = {Proceedings. Fourth IEEE Real-Time Technology and Applications Symposium (Cat. No.98TB100245)},
	Title = {{A comparison of static analysis and evolutionary testing for the verification of timing constraints}},
	Year = {1998}}

@article{Puschner1998,
	Abstract = {Analytically derived worst case execution time (WCET) bounds are
prone to errors, because they often rely on information provided by the
user. The paper presents a method for testing the results of static WCET
analysis. The proposed test method is a blackbox test method that uses a
genetic algorithm (GA) for test case generation. Important properties of
the method are: (a) that it requires minimal information about possible
impact data from the user and (b) that the GA guides data generation
into directions that have a good chance to yield the real WCET of the
program under test. Experimental results show that GA based testing
produces results of high quality},
	Author = {Puschner, P. and Nossal, R.},
	Doi = {10.1109/REAL.1998.739738},
	Isbn = {0-8186-9212-X},
	Issn = {1052-8725},
	Journal = {Proceedings 19th IEEE Real-Time Systems Symposium (Cat. No.98CB36279)},
	Title = {{Testing the results of static worst-case execution-time analysis}},
	Year = {1998}}

@article{J.WegenerK.GrimmM.GrochtmannH.Sthamer1996,
	Author = {{J. Wegener, K. Grimm, M. Grochtmann, H. Sthamer}, B. Jones},
	File = {:Users/naubergois/Dropbox/eurostar1996.pdf:pdf},
	Journal = {EuroSTAR'96: Proceedings of the Fourth International Conference on Software Testing Analysis and Review},
	Title = {{Systematic testing of real-time systems}},
	Year = {1996}}

@article{Gro,
	Author = {Gro, Hans-Gerhard},
	Publisher = {Citeseer},
	Title = {A prediction system for dynamic optimisation-based execution time analysis},
	Year = {2001}}

@misc{Gross2003,
	Author = {Gross, Hg},
	Booktitle = {Proceedings of the International Conference on Information Technology: Prospects and Challenges in the 21st Century},
	File = {:Users/naubergois/Dropbox/grossITPC03\_RealTime.pdf:pdf},
	Title = {{An evaluation of dynamic, optimisation-based worst-case execution time analysis}},
	Year = {2003}}

@article{Briand2005,
	Author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
	Doi = {10.1145/1068009.1068183},
	Isbn = {1595930108},
	Journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
	Keywords = {genetic algorithms,schedulability theory},
	Pages = {1021},
	Title = {{Stress testing real-time systems with genetic algorithms}},
	Year = {2005}}

@article{Canfora,
	Author = {Canfora, Gerardo and Penta, Massimiliano Di and Esposito, Raffaele and Villani, Maria Luisa},
	Isbn = {1595930108},
	Keywords = {aware composi-,oriented software engineering,qos,service},
	Title = {{2005., Canfora, G., An approach for QoS-aware service composition based on genetic algorithms}}}

@article{gross2000structural,
	Author = {Gross, H-G and Jones, Bryan F and Eyres, David E},
	Journal = {IEE Proceedings-Software},
	Number = {2},
	Pages = {25--30},
	Publisher = {IET},
	Title = {Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems},
	Volume = {147},
	Year = {2000}}

@article{goldberg1989messy,
	Author = {Goldberg, David E and Korb, Bradley and Deb, Kalyanmoy},
	Journal = {Complex systems},
	Number = {5},
	Pages = {493--530},
	Publisher = {Complex Systems Publications, Champaign, IL, USA},
	Title = {Messy genetic algorithms: Motivation, analysis, and first results},
	Volume = {3},
	Year = {1989}}

@article{wegener1998verifying,
	Author = {Wegener, Joachim and Grochtmann, Matthias},
	Journal = {Real-Time Systems},
	Number = {3},
	Pages = {275--298},
	Publisher = {Springer},
	Title = {Verifying timing constraints of real-time systems by means of evolutionary testing},
	Volume = {15},
	Year = {1998}}

@article{alander1998searching,
	Author = {Alander, Jarmo T and Mantere, Timo and Moghadampour, Ghodrat and Matila, Jukka},
	Journal = {Electric Power Systems Research},
	Number = {3},
	Pages = {229--233},
	Publisher = {Elsevier},
	Title = {Searching protection relay response time extremes using genetic algorithm---software quality by optimization},
	Volume = {46},
	Year = {1998}}

@article{Wegener1998,
	Abstract = {Many industrial products are based on the use of embedded computer systems. Usually, these systems have to fulfil real-time requirements, and correct system functionality depends on their logical correctness as well as on their temporal correctness. in order to verify the temporal behavior of real-time systems, previous scientific work has, to a large extent, concentrated on static analysis techniques. Although these techniques offer the possibility of providing safe estimates of temporal behavior for certain cases, there are a number of cases in practice for which static analysis can not be easily applied. Furthermore, no commercial tools for timing analysis of real-world programs are available. Therefore, the developed systems have to be thoroughly tested in order to detect existing deficiencies in temporal behavior, as well as to strengthen the confidence in temporal correctness. An investigation of existing test methods shows that they mostly concentrate on testing for logical correctness. They are nor specialised in the examination of temporal correctness which is also essential to real-rime systems. For this reason, existing test procedures must be supplemented by new methods which concentrate on determining whether the system violates its specified timing constraints. Normally, a violation means that outputs are produced too early, or their computation takes too long. The task of the tester therefore is to find the input situations with the longest or shortest execution limes, in order to check whether they produce a temporal error. If the starch for such inputs is interpreted as a problem of optimization, evolutionary computation can be used to automatically find the inputs with the longest or shortest execution rimes. This automatic search for accurate test data by means of evolutionary computation is called evolutionary testing. Experiments using evolutionary testing on a number of programs with up to 1511 LOC and 5000 input parameters have successfully identified new longer and shorter execution times than had been found using other testing techniques. Evolutionary testing, therefore, seems to be a promising approach for the verification of timing constraints. A combination of evolutionary testing and systematic testing offers further opportunities to improve the test quality, and could lead to an effective test strategy for real-time systems.},
	Author = {Wegener, J and Grochtmann, M},
	Doi = {Doi 10.1023/A:1008096431840},
	Isbn = {0922-6443},
	Issn = {0922-6443},
	Journal = {Real-Time Systems},
	Keywords = {evolutionary algorithm,evolutionary optimization,evolutionary testing,genetic algorithms,real-time systems,temporal behavior,temporal correctness,test strategy,testing,validation,verification},
	Number = {3},
	Pages = {275--298},
	Title = {{Verifying timing constraints of real-time systems by means of evolutionary testing}},
	Volume = {15},
	Year = {1998}}

@book{Halili2008,
	Abstract = {"This book introduces you to JMeter (version 2.3) and test automation, providing a step-by-step guide to testing with JMeter. You will learn how to measure the performance of a website using JMeter. While it discusses test automation generally, the bulk of this book gives specific, vivid, and easy-to-understand walkthroughs of JMeter's testing tools showing what they can do, and when and how to use them. Learn to load-test your website, test its functional behaviour, and measure its performance by implementing the features of Jmeter"--Resource description p.},
	Author = {Halili, Emily H},
	Isbn = {9786611737528 6611737529 9781847192967 1847192963 1847192955 9781847192950},
	Title = {{Apache JMeter a practical beginner's guide to automated testing and performance measurement for your websites}},
	Year = {2008}}

@article{wegener1997testing,
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Journal = {Software Quality Journal},
	Number = {2},
	Pages = {127--135},
	Publisher = {Springer},
	Title = {Testing real-time systems using genetic algorithms},
	Volume = {6},
	Year = {1997}}
	
	@book{Lewis2005,
abstract = {It is often assumed that software testing is based on clearly defined requirements and software development standards. However, testing is typically performed against changing, and sometimes inaccurate, requirements. The third edition of a bestseller, Software Testing and Continuous Quality Improvement, Third Edition provides a continuous quality framework for the software testing process within traditionally structured and unstructured environments. This framework aids in creating meaningful test cases for systems with evolving requirements. This completely revised reference provides a comprehensive look at software testing as part of the project management process, emphasizing testing and quality goals early on in development. Building on the success of previous editions, the text explains testing in a Service Orientated Architecture (SOA) environment, the building blocks of a Testing Center of Excellence (COE), and how to test in an agile development. Fully updated, the sections on test effort estimation provide greater emphasis on testing metrics. The book also examines all aspects of functional testing and looks at the relation between changing business strategies and changes to applications in development. Includes New Chapters on Process, Application, and Organizational Metrics All IT organizations face software testing issues, but most are unprepared to manage them. Software Testing and Continuous Quality Improvement, Third Editionis enhanced with an up-to-date listing of free software tools and a question-and-answer checklist for choosing the best tools for your organization. It equips you with everything you need to effectively address testing issues in the most beneficial way for your business.},
author = {Lewis, William E. and Dobbs, David and Veerapillai, Gunasekaran},
file = {:Users/naubergois/Downloads/2005 Software.Testing.and.Continuous.Quality.Improvement.2nd.Ed{\_}bagus.pdf:pdf},
isbn = {1420080733},
pages = {688},
title = {{Software testing and continuous quality improvement}},
url = {http://books.google.com/books?id=fgaBDd0TfT8C{\&}pgis=1},
year = {2005}
}



